{
  "pdf": "data.pdf",
  "page_count": 73,
  "raw_pages": [
    {
      "page": 1
    },
    {
      "page": 2,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5\nFlash Pro Flash-Lite Flash Flash Pro\nText,Image, Text,Image, Text,Image, Text,Image, Text,Image, Text,Image,\nInputmodalities\nVideo,Audio Video,Audio Video,Audio Video,Audio Video,Audio Video,Audio\nInputlength 1M 2M 1M 1M 1M 1M\nOutputmodalities Text Text Text Text,Image* Text,Audio* Text,Audio*\nOutputlength 8K 8K 8K 8K 64K 64K\nThinking No No No Yes* Dynamic Dynamic\nSupportstooluse? No No No Yes Yes Yes\nKnowledgecutoff November November June2024 June2024 January January\n2023 2023 2025 2025\nTable 1 | Comparison of Gemini 2.X model family with Gemini 1.5 Pro and Flash. Tool use refers\nto the ability of the model to recognize and execute function calls (e.g., to perform web search,\ncompleteamathproblem,executecode). *currentlylimitedtoExperimentalorPreview,seeSection2.7.\nInformation accurate as of publication date.\nhelpfulnessandgeneraltonecomparedtotheir2.0and1.5counterparts. Inpractice,thismeansthat\nthe2.5modelsaresubstantiallybetteratprovidingsaferesponseswithoutinterferingwithimportant\nuse cases or lecturing end users. We also evaluated Gemini 2.5 Pro’s Critical Capabilities, including\nCBRN, cybersecurity, machine learning R&D, and deceptive alignment. While Gemini 2.5 Pro showed\na significant increase in some capabilities compared to previous Gemini models, it did not reach any\nof the Critical Capability Levels in any area.\nOur report is structured as follows: we begin by briefly describing advances we have made in\nmodelarchitecture,trainingandservingsincethereleaseoftheGemini1.5model. Wethenshowcase\nthe performance of the Gemini 2.5 models, including qualitative demonstrations of its abilities. We\nconclude by discussing the safety evaluations and implications of this model series.\n2. Model Architecture, Training and Dataset\n2.1. Model Architecture\nThe Gemini 2.5 models are sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021;\nFedus et al., 2021; Jiang et al., 2024; Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021;\nShazeer et al., 2017) transformers (Vaswani et al., 2017) with native multimodal support for text,\nvision, and audio inputs. Sparse MoE models activate a subset of model parameters per input token\nby learning to dynamically route tokens to a subset of parameters (experts); this allows them to\ndecouple total model capacity from computation and serving cost per token. Developments to the\nmodel architecture contribute to the significantly improved performance of Gemini 2.5 compared to\nGemini 1.5 Pro (see Section 3). Despite their overwhelming success, large transformers and sparse\nMoE models are known to suffer from training instabilities (Chowdhery et al., 2022; Dehghani et al.,\n2023; Fedus et al., 2021; Lepikhin et al., 2020; Liu et al., 2020; Molybog et al., 2023; Wortsman\net al., 2023; Zhai et al., 2023; Zhang et al., 2022). The Gemini 2.5 model series makes considerable\nprogress in enhancing large-scale training stability, signal propagation and optimization dynamics,\nresulting in a considerable boost in performance straight out of pre-training compared to previous\nGemini models.\n2"
    },
    {
      "page": 3,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 1 | Cost-performance plot. Gemini 2.5 Pro is a marked improvement over Gemini 1.5 Pro, and\nhas an LMArena score that is over 120 points higher than Gemini 1.5 Pro. Cost is a weighted average\nof input and output tokens pricing per million tokens. Source: LMArena, imported on 2025-06-16.\nGemini 2.5 models build on the success of Gemini 1.5 in processing long-context queries, and\nincorporate new modeling advances allowing Gemini 2.5 Pro to surpass the performance of Gemini\n1.5Proinprocessinglongcontextinputsequencesofupto1Mtokens(seeTable3). BothGemini2.5\nProandGemini2.5Flashcanprocesspiecesoflong-formtext(suchastheentiretyof“MobyDick”or\n“Don Quixote”), whole codebases, and long form audio and video data (see Appendix 8.5). Together\nwith advancements in long-context abilities, architectural changes to Gemini 2.5 vision processing\nlead to a considerable improvement in image and video understanding capabilities, including being\nable to process 3-hour-long videos and the ability to convert demonstrative videos into interactive\ncoding applications (see our recent blog post by Baddepudi et al., 2025).\nThesmallermodelsintheGemini2.5series—Flashsizeandbelow—usedistillation(Aniletal.,\n2018; Hinton et al., 2015), as was done in the Gemini 1.5 series (Gemini Team, 2024). To reduce\nthe cost associated with storing the teacher’s next token prediction distribution, we approximate it\nusing a k-sparse distribution over the vocabulary. While this still increases training data throughput\nand storage demands by a factor of k, we find this to be a worthwhile trade-off given the significant\nquality improvement distillation has on our smaller models, leading to high-quality models with a\nreduced serving cost (see Figure 2).\n2.2. Dataset\nOur pre-training dataset is a large-scale, diverse collection of data encompassing a wide range of\ndomainsandmodalities,whichincludespubliclyavailablewebdocuments,code(variousprogramming\nlanguages), images, audio (including speech and other audio types) and video, with a cutoff date\nof June 2024 for 2.0 and January 2025 for 2.5. Compared to the Gemini 1.5 pre-training dataset\n3"
    },
    {
      "page": 4,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini 2.5 Flash\nGemini 2.0 Flash\nGemini 2.0 Flash-Lite\no4-mini (high)\no3\nGemini 2.5 Pro Company\nGrok 3 Google\nOpenAI\nClaude 4 Opus (Extended Thinking)\nAnthropic\nClaude 4 Sonnet (Extended Thinking) DeepSeek\nxAI\nDeepSeek R1 0528 (May '25)\n0 50 100 150 200 250 300 350\nOutput Tokens per Second\nFigure 2 | Number of output tokens generated per second (after the first chunk has been received\nfrom the API) for different models. Source: ArtificialAnalysis.ai, imported on 2025-06-15.\nwe also utilized new methods for improved data quality for both filtering, and deduplication. Our\npost-training dataset, like Gemini 1.5, consists of instruction tuning data that is carefully collected\nandvetted. Itisacollectionofmultimodaldatawithpairedinstructionsandresponses,inadditionto\nhuman preference and tool-use data.\n2.3. Training Infrastructure\nThis model family is the first to be trained on TPUv5p architecture. We employed synchronous\ndata-parallel training to parallelise over multiple 8960-chip pods of Google’s TPUv5p accelerators,\ndistributed across multiple datacenters.\nThemainadvancesinsoftwarepre-traininginfrastructurecomparedwithGemini1.5wererelated\nto elasticity and mitigation of SDC (Silent Data Corruption) errors:\n1. Slice-Granularity Elasticity: Our system now automatically continues training with fewer\n“slices” of TPU chips when there is a localized failure, and this reconfiguration results in tens\nof seconds of lost training time per interruption, compared with the 10 or more minute delay\nwaitingforhealthymachinestoberescheduledwithoutelasticity;thesystemcontinuestraining\nat around 97% throughput while the failed slice is recovering. At the scale of this training run\nwe see interruptions from hardware failures multiple times per hour, but our fault tolerance\nmachinery is designed to tolerate the higher failure rates expected at much larger scales.\n2. Split-Phase SDC Detection: On previous large-scale runs it could take many hours to detect\nand localize machines with SDC errors, requiring both downtime while debugging, and roll-\nback/replay of a large number of potentially corrupt training steps. We now use lightweight\ndeterministic replay to immediately repeat any step with suspicious metrics, and compare\nper-deviceintermediatechecksumstolocalizetherootcauseofanydatacorruption. Empirically,\naccelerators that start to exhibit intermittent SDCs are identified within a few minutes, and\nquickly excluded from the job. During this run, around 0.25% of steps were replayed due to\nsuspected SDCs and 6% of these replays turned out to be genuine hardware corruption.\nBoth of the above techniques were relatively simple to implement due to the single-controller\ndesign of the Pathways system (Barham et al., 2022), which allows all accelerators to be coordinated\nfrom a single python program with a global view of the system state. The controller can make use of\n4"
    },
    {
      "page": 5,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n100\n80\n60\n40\n20\n0\n)%(\netar\nssaP\n/\nycaruccA\nAIME GPQA (Diamond) LiveCodeBench v5\n2.0 Flash (No Thinking)\n2.0 Flash (Thinking)\n2.5 Flash (Dynamic Thinking)\n2.5 Pro (Dynamic Thinking)\nFigure 3 | Impact of “Thinking” on Gemini’s performance on AIME 2025 (Balunović et al., 2025),\nLiveCodeBench (corresponding to 10/05/2024 - 01/04/2025 in the UI) (Jain et al., 2024) and GPQA\ndiamond (Rein et al., 2024) benchmarks.\nparallel ‘remote python’ operations on TPU workers to monitor training metrics, track performance\nstragglers, and root-cause SDC errors.\nOverall during the run, 93.4% of the time was spent performing TPU computations; the re-\nmainder was approximately spent half in elastic reconfigurations, and half in rare tail cases where\nelasticity failed. Around 4.5% of the computed steps were replays or rollbacks for model debugging\ninterventions.\n2.4. Post-training\nSince the initial announcement of Gemini 1.5, significant advancements have been made in our\npost-training methodologies, driven by a consistent focus on data quality across the Supervised\nFine-Tuning (SFT), Reward Modeling (RM), and Reinforcement Learning (RL) stages. A key focus\nhas been leveraging the model itself to assist in these processes, enabling more efficient and nuanced\nquality control.\nFurthermore,wehaveincreasedthetrainingcomputeallocatedtoRL,allowingdeeperexploration\nand refinement of model behaviors. This has been coupled with a focus on verifiable rewards\nand model-based generative rewards to provide more sophisticated and scalable feedback signals.\nAlgorithmic changes to the RL process have also improved stability during longer training. These\nadvancements have enabled Gemini 2.5 to learn from more diverse and complex RL environments,\nincluding those requiring multi-step actions and tool use. The combination of these improvements in\ndataquality,increasedcompute,algorithmicenhancements,andexpandedcapabilitieshascontributed\ntoacross-the-boardperformancegains(asdescribedinSection3),notablyreflectedinthesignificant\nincrease in the model’s LMArena Elo scores, with both Gemini 2.5 Flash and Pro gaining more than\n110 points over their Gemini 1.5 counterparts (122 for Gemini 2.5 Pro and 111 for Gemini 2.5 Flash,\nsee Figure 1), along with significant improvements on several other frontier benchmarks.\n2.5. Thinking\nPast Gemini models produce an answer immediately following a user query. This constrains the\namount of inference-time compute (Thinking) that our models can spend reasoning over a problem.\nGemini Thinking models are trained with Reinforcement Learning to use additional compute at\ninference time to arrive at more accurate answers. The resulting models are able to spend tens of\n5"
    },
    {
      "page": 6,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n90\n85\n80\n75\n70\n65\n1024 2048 4096 8192 16384 32768\nThinking Budget (number of tokens)\n)%(\netar\nssaP\n/ ycaruccA\nAIME 2025 LiveCodeBench GPQA diamond\n80 88\n75\n86\n70\n65 84\n60 82\n55\n80\n50\n45 78\n1024 2048 4096 8192 16384 32768 1024 2048 4096 8192 16384 32768\nThinking budget (number of tokens) Thinking budget (number of tokens)\nFigure 4 | Impact of thinking budget on performance on AIME 2025 (Balunović et al., 2025), Live-\nCodeBench (corresponding to 10/05/2024 - 01/04/2025 in the UI) (Jain et al., 2024) and GPQA\ndiamond (Rein et al., 2024) benchmarks.\nthousands of forward passes during a “thinking” stage, before responding to a question or query.\nOur training recipe has evolved from the original experimental thinking model, Gemini 2.0 Flash\nThinking (launched in December 2024), to the Gemini 2.5 Thinking series, which incorporates\nThinkingnativelyacrossalldomains. Theresultisasinglemodelthatcanachievestrongerreasoning\nperformanceacrosstheboard,andisabletoscaleupitsperformancefurtherasafunctionofinference\ntime (see Figure 3 for an example of the impact of Thinking).\nWeintegratedThinkingwithotherGeminicapabilities,includingnativemultimodalinputs(images,\ntext, video, audio) and long context (1M+ tokens). For any of these capabilities, the model decides\nfor itself how long to think before providing an answer. We also provide the ability to set a Thinking\nbudget, constraining the model to respond within a desired number of tokens. This allows users to\ntrade off performance with cost. To demonstrate this capability, we conducted experiments where we\nsystematically varied the thinking budget, measured in the number of tokens the model is allowed to\nuse for internal computation. As shown in Figure 4, increasing this budget allows the model to scale\nits performance and achieve significantly higher accuracy.\n2.6. Capability-specific improvements\nWhilemostofthechangesmadetoourtrainingarchitectureandrecipesinceGemini1.5haveresulted\nin improvements across all capabilities, we have also made changes that have resulted in some\ncapability-specific wins. We will now discuss these for code, factuality, long context, multilinguality,\naudio, video, and agentic use cases (with a particular focus on Gemini Deep Research).\nCode\nGemini 2.0 and 2.5 represent a strategic shift of our development priorities towards delivering\ntangiblereal-worldvalue,empoweringuserstoaddresspracticalchallengesandachievedevelopment\nobjectives within today’s complex, multimodal software environments. To realize this, concerted\nefforts have been undertaken across both pre-training and post-training phases since Gemini 1.5.\nIn pre-training, we intensified our focus on incorporating a greater volume and diversity of code\ndata from both repository and web sources into the training mixture. This has rapidly expanded\ncoverage and enabled the development of more compute-efficient models. Furthermore, we have\nsubstantially enhanced our suite of evaluation metrics for assessing code capabilities aligned with\ndownstream use cases, alongside improving our ability to accurately predict model performance.\n6"
    },
    {
      "page": 7,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nDuringpost-training,wedevelopednoveltrainingtechniquesincorporatingreasoningcapabilitiesand\ncuratedadiversesetofengineeringtasks,withtheaimtoequipGeminiwitheffectiveproblem-solving\nskills crucial for addressing modern engineering challenges. Key applications demonstrating these\nadvancements include IDE functionalities, code agent use cases for complex, multi-step operations\nwithin full repositories, and multimodal, interactive scenarios such as end-to-end web and mobile\napplication development. Collectively, these efforts have yielded broad and significant improvements\nin Gemini’s coding capabilities. This progress is evidenced by superior performance on established\nbenchmarks: performance on LiveCodeBench (Jain et al., 2024) increased from 30.5% for Gemini\n1.5 Pro to 74.2% for Gemini 2.5 Pro, while that for Aider Polyglot (Gauthier, 2025) went from\n16.9% to 82.2%. Performance on SWEBench-verified (Chowdhury et al., 2024; Jimenez et al., 2024)\nwent from 34.2% to 67.2%, see Table 3 and Figure 5 in Section 3.2. Furthermore, Gemini 2.5 Pro\nobtained an increase of over 500 Elo over Gemini 1.5 Pro on the LMArena WebDev Arena (Chiang\net al., 2024; LMArena Team, 2025), resulting in meaningful enhancements in practical applications,\nincluding UI and web application development (Doshi, 2025a), and the creation of sophisticated\nagentic workflows (Kilpatrick, 2025).\nFactuality\nWithin the context of generative models, ensuring the factuality of model responses to information-\nseeking prompts remains a core pillar of Gemini model development. With Gemini 1.5, our research\nwas concentrated on enhancing the model’s world knowledge and its ability to provide answers\nfaithfullygroundedinthecontextprovidedwithintheprompt. ThiseffortculminatedintheDecember\n2024 release of FACTS Grounding (Jacovi et al., 2025), now an industry-standard benchmark for\nevaluating an LLM’s capacity to generate responses grounded in user-provided documents. With\nGemini 2.0 and 2.5, we have significantly expanded our scope to address multimodal inputs, long-\ncontext reasoning, and model-retrieved information. At the same time, the landscape and user\nexpectations for factuality have evolved dramatically, shaped in part by Google’s deployment of AI\nOverviews and AI Mode (Stein, 2025). To meet these demands, Gemini 2.0 marked a significant leap\nas our first model family trained to natively call tools like Google Search, enabling it to formulate\nprecisequeriesandsynthesizefreshinformationwithsources. Buildingonthis,Gemini2.5integrates\nadvancedreasoning,allowingittointerleavethesesearchcapabilitieswithinternalthoughtprocesses\nto answer complex, multi-hop queries and execute long-horizon tasks. The model has learned to use\nsearch and other tools, reason about the outputs, and issue additional, detailed follow-up queries\nto expand the information available to it and to verify the factual accuracy of the response. Our\nlatest models now power the experiences of over 1.5B monthly active users in Google’s AI Overviews\nand 400M users in the Gemini App. These models exhibit state-of-the-art performance across a\nsuite of factuality benchmarks, including SimpleQA for parametric knowledge (Wei et al., 2024),\nFACTSGroundingforfaithfulnesstoprovideddocuments(Jacovietal.,2024,2025),andtheVectara\nHallucination Leaderboard (Hughes et al., 2023), cementing Gemini as the model of choice for\ninformation-seeking demands.\nLong context\nModeling and data advances helped us improve the quality of our models’ responses to queries\nutilizingouronemillion-lengthcontextwindow,andwereworkedourinternalevaluationstobemore\nchallengingtohelpsteerourmodelingresearch. Whenhill-climbing,wetargetedchallengingretrieval\ntasks (like LOFT of Lee et al., 2024), long-context reasoning tasks (like MRCR-V2 of Vodrahalli et al.,\n2024), and multimodal tasks (like VideoMME of Fu et al., 2025). According to the results in Table 6,\nthe new 2.5 models improve greatly over previous Gemini 1.5 models and achieve state-of-the-art\nquality on all of those. An example showcasing these improved capabilities for video recall can be\n7"
    },
    {
      "page": 8,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nseen in Appendix 8.5, where Gemini 2.5 Pro is able to consistently recall a 1 second visual event out\nof a full 46-minute video.2\nMultilinguality\nGemini’s multilingual capabilities have also undergone a profound evolution since 1.5, which already\nencompassed over 400 languages via pretraining. This transformation stems from a holistic strategy,\nmeticulously refining pre- and post-training data quality, advancing tokenization techniques, innovat-\ning core modeling, and executing targeted capability hillclimbing. The impact is particularly striking\nin Indic and Chinese, Japanese and Korean languages, where dedicated optimizations in data quality\nandevaluationhaveunlockeddramaticgainsinbothqualityanddecodingspeed. Consequently,users\nbenefit from significantly enhanced language adherence, responses designed to faithfully respect the\nrequested output language, and a robust improvement in generative quality and factuality across\nlanguages, solidifying Gemini’s reliability across diverse linguistic contexts.\nAudio\nWhile Gemini 1.5 was focused on native audio understanding tasks such as transcription, translation,\nsummarization and question-answering, in addition to understanding, Gemini 2.5 was trained to\nperform audio generation tasks such as text-to-speech or native audio-visual to audio out dialog. To\nenable low-latency streaming dialog, we incorporated causal audio representations that also allow\nstreaming audio into and out of Gemini 2.5. These capabilities derive from an increased amount of\npre-training data spanning over 200 languages, and development of improved post-training recipes.\nFinally, through our improved post-training recipes, we have integrated advanced capabilities such as\nthinking, affective dialog, contextual awareness and tool use into Gemini’s native audio models.\nVideo\nWe have significantly expanded both our pretraining and post-training video understanding data,\nimproving the audio-visual and temporal understanding capabilities of the model. We have also\ntrainedourmodelssothattheyperformcompetitivelywith66insteadof258visualtokensperframe,\nenabling using about 3 hours of video instead of 1h within a 1M tokens context window3. Two\nnew applications that were not previously possible, but that have been unlocked as a result of these\nchanges are: creating an interactive app from a video (such as a quiz to test students’ understanding\nof the video content) and creating a p5.js animation to show the key concepts from the video. Our\nrecent blog post (Baddepudi et al., 2025) shows examples of these applications.\nGemini as an Agent: Deep Research\nGemini Deep Research (Gemini Team, Google, 2024) is an agent built on top of the Gemini 2.5 Pro\nmodeldesignedtostrategicallybrowsethewebandprovideinformedanswerstoeventhemostniche\nuser queries. The agent is optimized to perform task prioritization, and is also able to identify when\nit reaches a dead-end when browsing. We have massively improved the capabilities of Gemini Deep\nResearch since its initial launch in December 2024. As evidence of that, performance of Gemini\nDeep Research on the Humanity’s Last Exam benchmark (Phan et al., 2025) has gone from 7.95% in\nDecember 2024 to the SoTA score of 26.9% and 32.4% with higher compute (June 2025).\n2Forfurtherdiscussiononlongcontextcapabilities,challenges,andfutureoutlook,theReleaseNotespodcastepisode\n“DeepDiveintoLongContext”providesadditionalinsightsanddiscussion:https://youtu.be/NHMJ9mqKeMQ.\n3ThisisreferredtoaslowmediaresolutionintheAPI:https://ai.google.dev/api/generate-content#Media\nResolution.\n8"
    },
    {
      "page": 9,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n2.7. The path to Gemini 2.5\nOn the way to Gemini 2.5 Pro, we experimented with our training recipe, and tested a small number\nof these experimental models with users. We have already discussed Gemini 2.0 Flash Thinking (see\nSection 2.5). We will now discuss some of the other models briefly.\nGemini 2.0 Pro\nIn February 2025, we released an experimental version of Gemini 2.0 Pro. At the time, it had\nthe strongest coding performance of any model in the Gemini model family, as well as the best\nunderstanding and world knowledge. It also came with our largest context window at 2 million\ntokens, which enabled it to comprehensively analyze and understand vast amounts of information.\nFor further information about Gemini 2.0 Pro, please see our earlier blog posts (Kavukcuoglu, 2025;\nMallick and Kilpatrick, 2025).\nGemini 2.0 Flash Native Image Generation Model\nIn March 2025, we released an experimental version of Gemini 2.0 Flash Native Image Generation.\nIt has brought to the users new capabilities as a result of a strong integration between the Gemini\nmodel and image-generation capabilities, enabling new experiences related to image generation &\nimage editing via natural-language prompting. Capabilities such as multi-step conversational editing\norinterleavedtext-imagegenerationareverynaturalinsuchasetting,andhorizontaltransferrelated\nto multi-language coverage immediately allowed such experiences to happen across all the languages\nsupported by the Gemini models. Native image generation turns Gemini into a multimodal creation\npartner and enables Gemini to express ideas through both text and images, and to seamlessly move\nbetween the two. For further information about Gemini 2.0 Flash Native Image Generation, please\nsee our earlier blog posts (Kampf and Brichtova, 2025; Sharon, 2025)\nGemini 2.5 Audio Generation\nWith Gemini 2.5, the Controllable TTS and Native Audio Dialog capabilities are available as separate\noptions on AI Studio (Generate Media and Stream sections respectively). Our Gemini 2.5 Preview\nTTS Pro and Flash models support more than 80 languages with the speech style controlled by a free\nformatted prompt which can specify style, emotion, pace, etc, while also being capable of following\nfiner-grained steering instructions specified in the transcript. Notably, Gemini 2.5 Preview TTS can\ngeneratespeechwithmultiplespeakers,whichenablesthecreationofpodcastsasusedinNotebookLM\nAudioOverviews(Wang,2024). OurGemini2.5FlashPreviewNativeAudioDialogmodelusesnative\naudio generation, which enables the same level of style, pacing and accent control as available in our\ncontrollable TTS offering. Our dialog model supports tool use and function calling, and is available\nin more than 24 languages. With native audio understanding and generation capabilities, it can\nunderstandandrespondappropriatelytotheuser’stone. Thismodelisalsocapableofunderstanding\nwhen to respond to the user, and when not to respond, ignoring background and non-device directed\naudio. Finally, we also offer an advanced ‘Thinking’ variant that effectively handles more complex\nqueries and provides more robust and reasoned responses in exchange for some additional latency.\nGemini 2.5 Flash-Lite\nIn June 2025, we released an experimental version of Gemini 2.5 Flash-Lite (gemini-2.5-flash-\nlite-preview-06-17). ItcomeswiththesamecapabilitiesthatmakeGemini2.5helpful,including\nthe ability to turn thinking on at different budgets, connecting to tools like Google Search and code\n9"
    },
    {
      "page": 10,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nexecution,supportformultimodalinputsanda1million-tokencontextlength. Ourgoalwastoprovide\nan economical model class which provides ultra-low-latency capabilities and high throughput per\ndollar, echoing the initial release of 2.0 Flash-Lite (Google DeepMind, 2025b; Mallick and Kilpatrick,\n2025).\nGemini 2.5 Pro Deep Think\nTo advance Gemini’s capabilities towards solving hard reasoning problems, we developed a novel\nreasoning approach, called Deep Think, that naturally blends in parallel thinking techniques during\nresponse generation. Deep Think enables Gemini to creatively produce multiple hypotheses and\ncarefully critique them before arriving at the final answer, achieving state-of-the-art performances in\nchallengingbenchmarkssuchasOlympiadmath(USAMO2025),competitivecoding(LiveCodeBench),\nand multimodality (MMMU), see more details at (Doshi, 2025b). We announced Gemini 2.5 Deep\nThink at Google I/O and launched an experimental version to trusted testers and advanced users in\nJune 2025.\n10"
    },
    {
      "page": 11,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n3. Quantitative evaluation\n100\n80\n60\n40\n20\n0\nFlash Pro\n)%(\netar\nssaP\nLiveCodeBench Aider Polyglot SWE-bench Verified\n100 100\nGemini version\n1.5\n2.0 80 80\n2.5\n60 60\n40 40\n20 20\n0 0\nFlash Pro Flash Pro\n100\n80\n60\n40\n20\n0\nFlash Pro\n)%(\nycaruccA\nGPQA (diamond) AIME 2025 HiddenMath-Hard\n100 100\n80 80\n60 60\n40 40\n20 20\n0 0\nFlash Pro Flash Pro\nFigure 5 | Performance of Gemini 2.X models at coding, math and reasoning tasks in comparison to\nprevious Gemini models. SWE-bench verified numbers correspond to the “multiple attempts” setting\nreported in Table 3.\nWe will now examine the performance of the Gemini 2.X model family across a wide range of\nbenchmarks. We will first compare the performance of the Gemini 2.X models to the earlier Gemini\n1.5 Pro and Flash models, before we compare the performance of Gemini 2.5 Pro to other available\nlarge language models.\nWith web-scale pre-training of AI models, coupled with the post-training techniques that allow\npolicy and reward models to leverage public benchmarks, avoiding leaks and biases in the data used\nfor pre- and post-training is a persistent challenge. In the development of the Gemini 2.5 series, in\naddition to the standard n-gram based decontamination we used in Gemini 1.5, we also employed\nsemantic-similarity and model based decontamination procedures to help mitigate evaluation set\nleakage. Tomovebeyondtherelianceontrainingsetdecontamination,wealsocontinuereportingon\ninternally developed non-public benchmarks, such as HiddenMath.\nModel AIStudiomodelID\nGemini1.5Flash gemini-1.5-flash-002\nGemini1.5Pro gemini-1.5-pro-002\nGemini2.0Flash-Lite gemini-2.0-flash-lite-001\nGemini2.0Flash gemini-2.0-flash-001\nGemini2.5Flash gemini-2.5-flash\nGemini2.5Pro gemini-2.5-pro\nTable 2 | Mapping of Gemini model names to AI Studio API model IDs.\n11"
    },
    {
      "page": 12,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n3.1. Methodology\nIn Table 3, we compare the performance of Gemini 2.5 models to the Gemini 1.5 models, while in\nTable 4, we compare the performance of Gemini 2.5 Pro to that of other large language models.\nGemini results: AllGeminiscoresarepass@1,andare“singleattempt”settingsunlessotherwise\nspecified. Inthe“singleattempt”setting,nomajorityvotingorparalleltest-timecomputeispermitted,\nwhile in the “multiple attempts” setting, test-time selection of the candidate answer is allowed. All\nGemini evaluations are run with the AI Studio API for the model id that we provide in Table 2, with\ndefaultsamplingsettings. Toreducevariance,weaverageovermultipletrialsforsmallerbenchmarks.\nAiderPolyglotscoresarethepassrateaverageof3trials. Vibe-EvalresultsarereportedusingGemini\nas a judge.\nNon-Gemini results: All the results for non-Gemini models are sourced from providers’ self\nreported numbers unless mentioned otherwise. All “SWE-bench Verified” numbers follow official\nproviderreports,whichmeansthattheyarecomputedusingdifferentscaffoldingsandinfrastructure,\nand aren’t directly comparable.\nFor some evaluations, we obtain results from the external leaderboards that report results on\nthese benchmarks. Results for Humanity’s Last Exam results are sourced from Scale’s leaderboard\nandresultsforDeepSeekareobtainedfromthetext-onlyvariantoftheleaderboard(indicatedwitha\n⋄in Table 4). For Gemini 2.0 models, the reported results are on an earlier HLE dataset (indicated\nwith a † in Table 3). Results on LiveCodeBench results are taken from (1/1/2025 - 5/1/2025) in the\nUI. Aider Polyglot numbers come from the Aider leaderboard and results for SimpleQA come from\nthis repo where available. Results on FACTS Grounding come from Kaggle. In the case of LOFT and\nMRCR-V2,wereportresultsonboththe128kcontextlengthvariant,aswellasthe1Mcontextlength\nvariant. In the 128k context length variant, we measure performance on contexts up to 128k, while\nfor the 1M context length variant, we report performance on context lengths of exactly 1M.\nMore details on all benchmarks, including subsets and how scores were obtained can be found in\nTable 11 in Appendix 8.1.\n3.2. Core capability quantitative results\nAs can be seen in Table 3, and Figure 5, the Gemini 2.5 models excel at coding tasks such as\nLiveCodeBench, Aider Polyglot and SWE-bench Verified, and represent a marked improvement over\nprevious models.\nInadditiontocodingperformance,Gemini2.5modelsarenoticeablybetteratmathandreasoning\ntasks than Gemini 1.5 models: performance on AIME 2025 is 88.0% for Gemini 2.5 Pro compared to\n17.5% for Gemini 1.5 Pro, while performance on GPQA (diamond) went from 58.1% for Gemini 1.5\nPro to 86.4%. Performance on image understanding tasks has also increased significantly.\nIt is also interesting to note that the Gemini 2.5 Flash model has become the second most capable\nmodel in the Gemini family, and has overtaken not just previous Flash models, but also the Gemini\n1.5 Pro model released one year ago.\n12"
    },
    {
      "page": 13,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5\nCapability Benchmark\nFlash Pro Flash-Lite Flash Flash Pro\nLiveCodeBench 30.3% 29.7% 29.1% 29.1% 59.3% 74.2%\nAiderPolyglot 2.8% 16.9% 10.5% 21.3% 56.7% 82.2%\nsingle\n9.6% 22.3% 12.5% 21.4% 48.9% 59.6%\nCode SWE-bench attempt\nmultiple\nVerified 19.7% 34.2% 23.1% 34.2% 60.3% 67.2%\nattempts\nGPQA\n50.0% 58.1% 50.5% 65.2% 82.8% 86.4%\n(diamond)\nReasoning\nHumanity’s\nnotools - 4.6% 4.6%† 5.1%† 11.0% 21.6%\nLastExam\nSimpleQA 8.6% 24.9% 16.5% 29.9% 26.9% 54.0%\nFactuality FACTS\n82.9% 80.0% 82.4% 84.6% 85.3% 87.8%\nGrounding\nGlobalMMLU\n72.5% 80.8% 78.0% 83.4% 88.4% 89.2%\nMultilinguality (Lite)\nECLeKTic 16.4% 27.0% 27.7% 33.6% 36.8% 46.8%\nAIME2025 14.7% 17.5% 23.8% 29.7% 72.0% 88.0%\nMath\nHiddenMath- 36.8% 44.3% 47.4% 53.7% 75.5% 80.5%\nHard\nLOFT(hard ≤128K 67.3% 75.9% 50.7% 58.0% 82.1% 87.0%\nretrieval) 1M 36.7% 47.1% 7.6% 7.6% 58.9% 69.8%\nLong-context\nMRCR-V2 ≤128K 18.4% 26.2% 11.6% 19.0% 54.3% 58.0%\n(8-needle) 1M 10.2% 12.1% 4.0% 5.3% 21.0% 16.4%\nMMMU 58.3% 67.7% 65.1% 69.3% 79.7% 82.0%\nVibe-Eval\n52.3% 55.9% 51.5% 55.4% 65.4% 67.2%\nImage (Reka)\nUnderstanding\nZeroBench 0.5% 1.0% 0.75% 1.25% 2.0% 4.5%\nBetterChartQA 59.0% 65.8% 52.3% 57.8% 67.3% 72.4%\nTable 3 | Evaluation of Gemini 2.5 family across a wide range of core capability benchmarks and in\ncomparison to Gemini 1.5 models. Please see Tables 5 and 6 for audio and video evaluations. See\nTable 11 Appendix 8.1 for benchmarks and evaluation details.\n13"
    },
    {
      "page": 14,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n3.3. Evaluation of Gemini 2.5 Pro against other large language models\nRelative to other large language models that are available (see Table 4), Gemini achieves the highest\nscoreontheAiderPolyglotcodingtask,Humanity’sLastExam,GPQA(diamond),andontheSimpleQA\nand FACTS Grounding factuality benchmarks out of all of the models examined here. Gemini also\ncontinues to stand out for achieving the SoTA score on both the LOFT and MRCR long-context tasks\nat 128k context, and is the only one, amongst the models examined in the above table, to support\ncontext lengths of 1M+ tokens.\nNot all of the models shown in Table 4 have native support for multimodal inputs. As such, we\ncompare against a different set of models for audio and video understanding.\nAudio Understanding\nIn Table 5, we showcase the performance of the Gemini 2.5 model family at audio understanding,\nand compare the performance of these models to earlier Gemini models, as well as to GPT models.\nGemini2.5Prodemonstratesstate-of-the-artaudiounderstandingperformanceasmeasuredbypublic\nbenchmarks for ASR and AST, and compares favorably to alternatives under comparable testing\nconditions (using the same prompts and inputs).\nVideo Understanding\nIn Table 6, we show the performance of Gemini 2.5 models at video understanding. As can be\nseen, Gemini 2.5 Pro achieves state-of-the-art performance on key video understanding benchmarks,\nsurpassing recent models like GPT 4.1 under comparable testing conditions (same prompt and video\nGemini2.5 o3 o4-mini Claude4 Claude4 Grok3Beta DeepSeekR1\nCapability Benchmark\nPro high high Sonnet Opus ExtendedThinking 0528\nLiveCodeBench 74.2% 72.0% 75.8% 48.9% 51.1% – 70.5%\nCode\nAiderPolyglot 82.2% 79.6% 72.0% 61.3% 72.0% 53.3% 71.6%\nsingle 59.6% 69.1% 68.1% 72.7% 72.5% - -\nSWE-bench attempt\nVerified multiple 67.2% - - 80.2% 79.4% - 57.6%\nattempts\nGPQA\nsingle 86.4% 83.3% 81.4% 75.4% 79.6% 80.2% 81.0%\nReasoning (diamond) attempt\nHumanity’s\nno 21.6% 20.3% 18.1% 7.8% 10.7% - 14.0%⋄\nLastExam tools\nSimpleQA 54.0% 48.6% 19.3% - - 43.6% 27.8%\nFactuality\nFACTS\n87.8% 69.9% 62.1% 79.1% 77.7% 74.8% 82.4%\nGrounding\nMath AIME2025 single 88.0% 88.9% 92.7% 70.5% 75.5% 77.3% 87.5%\nattempt\nLOFT(hard ≤128K 87.0% 77.0% 60.5% 81.6% - 73.1% -\nretrieval) 1M 69.8% - - - - - -\nLong-context\nMRCR-V2 ≤128K 58.0% 57.1% 36.3% 39.1% 16.1%* 34.0% -\n(8-needle) 1M 16.4% - - - - - -\nImage\nMMMU single 82.0% 82.9% 81.6% 74.4% 76.5% 76.0% NoMMsupport\nUnderstanding attempt\nTable 4 | Performance comparison of Gemini 2.5 Pro with other large language models on different\ncapabilities. Please see Tables 5 and 6 for audio and video evaluations. See Table 11 for benchmarks\nand evaluation details. *: with no thinking and API refusals\n14"
    },
    {
      "page": 15,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5 GPT-4omini GPT4o GPT4o\nBenchmark\nFlash Pro Flash-Lite Flash Flash Pro AudioPreview AudioPreview transcribe\nFLEURS\n12.71 7.14 9.60 9.04 9.95 6.66 19.52 12.16 8.17\n(53lang,WER↓)\nCoVoST2\n34.81 37.53 34.74 36.35 36.15 38.48 29.5 35.89 –\n(21lang,BLEU↑)\nTable 5 | Performance comparison of Gemini 2.5 models to earlier Gemini models, as well as to GPT\nmodels for audio understanding. Note that for GPT models, metrics may differ from those previously\nreported due to differing eval methodologies. See Table 11 for benchmarks and evaluation details.\nframes). For cost-sensitive applications, Gemini 2.5 Flash provides a highly competitive alternative.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5 OpenAI\nModalities Benchmark\nFlash Pro Flash-Lite Flash Flash Pro GPT4.1\nActivityNet-QA 56.2 57.3 55.3 56.4 65.1 66.7 60.4\nEgoTempo 34.5 36.3 30.1 39.3 36.7 44.3 40.3\nPerceptionTest 66.5 69.4 67.5 68.8 75.1 78.4 64.8\nvisual-only\nQVHighlights 64.4 68.7 25.7 63.9 52.4 75.0 71.4\nVideoMMMU 64.8 70.4 64.3 68.5 79.2 83.6 60.9\n1H-VideoQA 61.9 72.2 55.6 67.5 67.5 81.0 56.8\nLVBench 61.9 65.7 52 61.8 62.7 78.7 63.4\nVideoMME 70.4 73.2 62.1 72.8 75.5 84.3 72.0\naudio+visual VATEX 56.9 55.5 58.5 56.9 65.2 71.3 64.1\nVATEX-ZH 46.2 52.2 43.2 48.5 43.9 59.7 48.7\nYouCook2Cap 153.2 170.0 78.6 129.0 177.6 188.3 127.6\nMinerva 49.6 52.8 46.8 52.4 60.7 67.6 54.0\nvisual+subtitles\nNeptune 78.7 82.7 81.5 83.1 84.3 87.3 85.2\naudio+visual+\nVideoMME 77.3 79.8 72.5 78.8 81.5 86.9 79.6\nsubtitles\nTable 6 | Evaluation of Gemini 2.5 vs. prior models and GPT 4.1 on video understanding benchmarks.\nPerformance is measured by string-match accuracy for multiple-choice VideoQA, LLM-based accuracy\nfor open-ended VideoQA, R1@0.5 for moment retrieval and CIDEr for captioning. See Table 11 for\nbenchmarks and evaluation details.\n15"
    },
    {
      "page": 16,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n4. Example use cases of Gemini 2.5 Pro\n4.1. Gemini Plays Pokémon\nHall of Fame\nBeat Elite Four Lance\nBeat Elite Four Agatha\nBeat Elite Four Bruno\nBeat Elite Four Lorelei\nExit Victory Road (1st)\nEnter Victory Road (1st)\nRival 7 (Route 22 #2)\nEarth Badge\nVolcano Badge\nAcquire Secret Key (Pokemon Mansion)\nEnter Cinnabar Island (1st)\nMarsh Badge\nRocket Boss 2 (Silph Co.)\nRival 6 (Silph Co.)\nEnter Silph Co. (1st)\nEnter Saffron City (1st)\nAcquire HM04 Strength (Warden's Teeth)\nSoul Badge\nAcquire HM03 Surf (Beat Safari Zone)\nEnter Safari Zone (1st)\nEnter Fuchsia City (1st)\nAcquire PokéFlute (Rescue Fuji)\nRainbow Badge\nRocket Boss 1 (Rocket Hideout)\nEnter Rocket Hideout (1st)\nEnter Celadon City (1st)\nRival 5 (Lavender Tower)\nExit Rock Tunnel & Reach Lavender Town (1st)\nAccess Pokemon w/ Flash\nEnter Rock Tunnel (1st)\nThunder Badge\nAcquire HM05 Flash\nAccess Pokemon w/ CUT\nRival 4 (SS Anne)\nBill’s House\nCascade Badge\nRival 3 (Nugget Bridge)\nExit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge\nExit Viridian Forest (1st)\nEnter Viridian Forest (1st)\nViridian City\nRival 1 (Oak's Lab)\n0 100 200 300 400 500 600 700 800\nTime Elapsed (Hours)\nsenotseliM\nemaG\nGemini 2.5 Pro Plays Pokemon Progress Timeline\nRun 1\nRun 2 (Actual)\nFigure 6 | Progression of the Gemini Plays Pokémon agent through the game, across two runs. Run 1\nwasthedevelopmentrunwherechangestotheharnesswereperformed. Run2isthefullyautonomous\nrunwiththefinalfixedscaffold. Bothrunshavethesamestarter(Squirtle). Theeventsareorderedon\nthe y-axis by the order they happened, following the order of Run 2 when there is a conflict. Notably,\ntheGPPagentadditionallywentthroughthedifficult(andoptional)SeafoamIslandsdungeoninRun\n2, while in Run 1, GPP reached Cinnabar Island via Pallet Town and Route 21.\nOn March 28, 2025, an independent developer not affiliated with Google, Joel Zhang, set up a\nTwitch stream (Gemini Plays Pokémon, or GPP) for Gemini 2.5 Pro (Gemini 2.5 Pro Exp 03-25) to\nplay Pokémon Blue on stream (Zhang, 2025) as an experiment to better understand how well the\nmodel was capable of playing Pokémon (in a similar spirit to Claude Plays Pokémon, see Anthropic\n2025). In this initial run through the game, the goal was to live-stream the development process of\nan agentic harness capable of playing the full game (and in particular the minimal transformation of\nvisiontotextnecessarytodoso),seeFigure14foradescriptionofthefinalagentsetup. Assuch,over\nthe course of the run, modifications were made to the setup as difficulties arose, providing a deeply\ninteresting lens via which to analyze some of the qualitative improvements that the 2.5 Pro model\nhasmade,particularlyintheregimesofsolvinglongreasoningproblemsandagenticcapabilitiesover\nextended time horizons. Around 1 month later, on May 2, 2025, Gemini 2.5 Pro completed the game\nafter 813 hours and entered the Hall of Fame to become the Pokémon League Champion! On May\n22, 2025, GPP began a fully autonomous 2nd run through the game with Gemini 2.5 Pro (Gemini\n2.5 Pro Preview 05-06) with the finalized fixed agentic harness, and progressed through the game\nconsiderablyfaster,completingthegamein406.5hours(nearlyexactlyhalfthetimeofthefirstrun).\n16"
    },
    {
      "page": 17,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nSee Figure 6 for a timeline of GPP’s progress through major game milestones to game completion.\nWe report # hours to each milestone in order to normalize for the amount of time models take per\naction. See Appendix 8.2 for more figures.\nCapabilities assessment\nGemini 2.5 Pro showcased many impressive capabilities associated with reasoning and long-term\nplanning while playing Pokémon. We will now discuss two in particular, but for more examples, see\nAppendix 8.2.\nLong Context Agentic Tooling Within the agent scaffolding, GPP has access to two agentic\ntools (see Figure 14). These prompted versions of Gemini 2.5 Pro, hereafter pathfinder and\nboulder_puzzle_strategist, have been able to:\n1. Solve complex spinner puzzles in one shot (for instance in Rocket Hideout),\n2. Solve the step-constrained multi-map puzzle of the Safari Zone,\n3. Find long pathways through complex mazes like Route 13,\n4. Solve boulder puzzles across long distances in Victory Road and the Seafoam Islands.\nEachtaskrequiresreasoningoveralongcontext-thepathfindermodelwouldoftenhavetoreason\nover contexts of 100K+ tokens, and find paths up to 50 actions in length (in the extreme case, paths\nconsisting of up to 150 actions have also been found!).\nLong Horizon Task Coherence WhileGemini2.5Proisimpressiveinamorelocalsense,theagent\nalsoexhibitedremarkablelong-termtaskcoherenceinachievingglobal,high-levelgoalsinthefaceof\nreal andhallucinated setbacks towards makingforward progress. Because the agent is able to change\ngoals at will, and will generally follow those goals as long as needed, it is extremely impressive that\nthe agent can satisfy numerous requirements for tactical, necessary goals, such as acquiring Hidden\nMoves, as well as maintain enough strategic task coherence to beat the entire game and become the\nPokémon Champion.\nWhere does 2.5 Pro struggle while playing Pokémon?\nIn addition to more standard hallucination issues (which interestingly were plausibly reduced in Run\n2 by explicitly prompting the model to act as a player completely new to the game, see Appendix 8.2\nfor more details), there are a few particular points of struggle we would like to emphasize.\nScreen reading While obtaining excellent benchmark numbers on real-world vision tasks, 2.5 Pro\nstruggled to utilize the raw pixels of the Game Boy screen directly, though it could occasionally take\ncues from information on the pixels. As a result, it was necessary for the required information from\nthe screen to be translated into a text format in the agent framework, using information from the\ngame’s RAM state. During one portion of the game, the developer tested an ablation where all vision\nwas completely removed from the model context – the model was able to function roughly as well\nas without the vision information, suggesting that most of the performance does not significantly\ndepend on the visual input.\nLong Context Reasoning Gemini 2.5 Pro’s state-of-the-art long context performance for both\nreasoning and retrieval tasks (see Tables 3 and 4) was a cornerstone of the GPP agent’s success. Its\nability to reason over a 100k token context was instrumental for leveraging the complex toolset and\n17"
    },
    {
      "page": 18,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nmaintaining a relatively coherent strategy (e.g., optimal balance of performance, planning quality,\nand information recall.)\nWhile Gemini 2.5 Pro supports 1M+ token context, making effective use of it for agents presents\na new research frontier. In this agentic setup, it was observed that as the context grew significantly\nbeyond 100k tokens, the agent showed a tendency toward favoring repeating actions from its vast\nhistory rather than synthesizing novel plans. This phenomenon, albeit anecdotal, highlights an\nimportant distinction between long-context for retrieval and long-context for multi-step, generative\nreasoning.\nTeachinganagenttoeffectivelyplanandavoidsuchloopsovermassivepasttrajectoriesofcontext\nis an exciting and active area of research; the co-design of agent scaffolds and models to unlock the\nfull potential of million-token context is an intriguing research direction and one of our primary\nfocuses.\n4.2. What else can Gemini 2.5 do?\nGemini 2.5 Pro excels at transforming diverse, often unstructured, inputs into interactive and func-\ntional applications. For instance, it can take a PDF script of a play and generate a tool that allows\ndrama students to practice their lines. Gemini 2.5 Pro can also take an uploaded photograph of a\nbookshelf and create a curated book recommendation application. Gemini 2.5 Pro can utilize its\nunderlying spatial understanding capability and convert images into a structural representation like\nHTML or SVG. In Figure 16 in Appendix 8.4, we show a comparison of Gemini 1.5 Pro and Gemini\n2.5Proonanimage-to-svgtask,whereGemini2.5Proreconstructsmuchmorevisualdetailsandthe\nspatial arrangements of objects better resembles the original image.\nFurthermore, Gemini 2.5 Pro demonstrates strong skills in generating sophisticated simulations\nand visualizations, ranging from interactive solar system models (source) to the creative rendering of\nabstract mathematical concepts, such as drawing a logo using Fourier series (source). This capability\nextendstothedevelopmentoftoolsthatintersectcreativityandutility: weseeexamplesofspecialized\napplicationslikeacustomcartographytoolorusecasesthatgeneratephotorealistic3Duserinterfaces\nfrom descriptive text and reference images, complete with appropriate styling and interactivity\n(source).\nCollectively, these examples illustrate that Gemini 2.5 Pro is not just a useful coding and writing\nassistant, but excels at a wide range of complex tasks, ranging from those relevant for education\nto creative expression. The model empowers users to rapidly prototype specialized utilities, de-\nvelop engaging educational content, and realize intricate creative visions with a high degree of\nsophistication.\n4.3. Gemini in Google Products\nAs a final example of what Gemini can do, we note that Gemini (or a custom version of Gemini) is\nnow incorporated into a wide variety of Google products. These include, but are not limited to, AI\nOverviews and AI Mode within Google Search, Project Astra, the audiovisual-to-audio dialog agent,\nGemini Deep Research, the research assistant discussed in Section 2.7, NotebookLM, the tool capable\nof generating podcasts and audio overviews from even the most obscure inputs, Project Mariner, the\nweb browsing agent, and Google’s coding agent, Jules.\n18"
    },
    {
      "page": 19,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n5. Safety, Security, and Responsibility\nWe’re committed to developing Gemini responsibly, innovating on safety and security alongside capa-\nbilities. We describe our current approach in this section, which includes how we train and evaluate\nour models, focusing on automated red teaming, going through held-out assurance evaluations on\npresent-day risks, and evaluating the potential for dangerous capabilities in order to proactively\nanticipate new and long-term risks.\nGuideline for Navigating This Section\n1. Our Process (Section 5.1): Begin here to understand our overall safety methodology.\n2. Policies and Desiderata (Section 5.2): Next, dive into the safety criteria we use to evaluate\nand optimize our systems.\n3. Training for Safety (Section 5.3): Discover how we incorporate safety into pre-training and\npost-training.\n4. ResultsfromDevelopmentEvaluations(Section5.4): Resultsonourdevelopmentevaluations\nfor policies and desiderata.\n5. Automated Red Teaming (Section 5.5): A description and results from our automated red\nteaming work for safety and security.\n6. Memorization & Privacy (Section 5.6): Our analysis of memorization and privacy risks.\n7. Assurance Evaluations and Frontier Safety Framework (Section 5.7): We dive into our\nheld-out evaluations and tests for dangerous capabilities.\n8. External Safety Testing (Section 5.8): Learn what independent testers discovered about our\nsystem’s safety.\n5.1. Our Process\nWe aim for Gemini to adhere to specific safety, security, and responsibility criteria. These cover what\nGemini should not do (e.g., encourage violence), and what Gemini should do (e.g., respond in a\nhelpful way when possible instead of refusing, provide multiple perspectives when consensus does\nnotexist). Wealsoleverageautomatedredteamingtoidentifycaseswherethemodelfailstorespond\nin a safe or helpful manner. These failure cases are used to improve evaluations and training data.\nOnce the model is trained, we run assurance evaluations that we then use for review and release\ndecisions. Importantly, these are conducted by a group outside of the model development team, and\ndatasets are held out. Furthermore, for models where there are new capabilities or a significant\nperformance improvement, we engage independent external groups, including domain experts and a\ngovernment body, to further test the model to identify blind spots.\nWe also evaluate the model for dangerous capabilities outlined in our Frontier Safety Framework\n(Google DeepMind, 2025a), namely: Cybersecurity, CBRN, Machine Learning R&D, and Deceptive\nAlignment.\nFinally, The Google DeepMind Responsibility and Safety Council (RSC), our governance body,\nreviews initial ethics and safety assessments on novel model capabilities in order to provide feedback\nand guidance during model development. The RSC also reviews metrics on the models’ performance\nvia assurance evals and informs release decisions.\n19"
    },
    {
      "page": 20,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n5.2. Policies and Desiderata\nSafety policies\nTheGeminisafetypoliciesalignwithGoogle’sstandardframeworkwhichpreventsourourGenerative\nAI models from generating specific types of harmful content, including:\n1. Child sexual abuse and exploitation\n2. Hate speech (e.g., dehumanizing members of protected groups)\n3. Dangerous content (e.g., promoting suicide, or instructing in activities that could cause real-\nworld harm)\n4. Harassment (e.g., encouraging violence against people)\n5. Sexually explicit content\n6. Medical advice that runs contrary to scientific or medical consensus\nThese policies apply across modalities. For example, they are meant to minimize the extent to\nwhich Gemini generates outputs such as suicide instructions or revealing harmful personal data,\nirrespective of input modality.\nFrom a security standpoint, beyond limiting revealing private information, Gemini strives to\nprotect users from cyberattacks, for example, by being robust to prompt injection attacks.\nDesiderata, aka “helpfulness”\nDefining what not to do is only part of the safety story – it is equally important to define what we do\nwant the model to do:\n1. Help the user: fulfill the user request; only refuse if it is not possible to find a response that\nfulfills the user goals without violating policy.\n2. Assume good intent: ifarefusalisnecessary,articulateitrespectfullywithoutmakingassump-\ntions about user intent.\n5.3. Training for Safety, Security, and Responsibility\nWe build safety into the models though pre-and post-training approaches. We start by constructing\nmetricsbasedonthepoliciesanddesiderataabove,whichwetypicallyturnintoautomatedevaluations\nthat guide model development through successive model iterations. We use data filtering and\nconditional pre-training, as well as Supervised Fine-Tuning (SFT), and Reinforcement Learning from\nHuman and Critic Feedback (RL*F). Below, we explain these approaches, and then share results\nacross the policies and desiderata for Gemini 2.0 and Gemini 2.5 models.\n• Dataset filtering: We apply safety filtering to our pre-training data for our strictest policies.\n• Pre-training monitoring: Starting in Gemini 2.0, we developed a novel evaluation to capture\nthe model’s ability to be steered towards different viewpoints and values, which helps align the\nmodel at post-training time.\n• Supervised Fine-Tuning: For the SFT stage, we source adversarial prompts either leveraging\nexisting models and tools to probe Gemini’s attack surface, or relying on human interactions\nto discover potentially harmful behavior. Throughout this process we strive for coverage of\nthe safety policies described above across common model use cases. When we find that model\n20"
    },
    {
      "page": 21,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nbehavior needs improvement, either because of safety policy violations, or because the model\nrefuses when a helpful, non-policy-violating answer exists, we use a combination of custom\ndata generation recipes loosely inspired by Constitutional AI (Bai et al., 2022), as well as\nhuman intervention to revise responses. The process described here is typically refined through\nsuccessive model iterations. We use automated evaluations on both safety and non-safety\nmetrics to monitor impact and potential unintended regressions.\n• Reinforcement Learning from Human and Critic Feedback (RL*F):RewardsignalduringRL\ncomesfromacombinationofaDataRewardModel(DRM),whichamortizeshumanpreference\ndata,andaCritic,apromptedmodelthatgradesresponsesaccordingtopre-definedrubrics. We\ndivide our interventions into Reward Model and Critic improvements (RM), and reinforcement\nlearning (RL) improvements. For both RM and RL, similarly to SFT, we source prompts either\nthrough human-model or model-model interactions, striving for coverage of safety policies\nand use cases. For both DRM training, given a prompt set, we use custom data generation\nrecipes to surface a representative sample of model responses. Humans then provide feedback\non the responses, often comparing multiple potential response candidates for each query. This\npreference data is amortized in our Data Reward Model. Critics, on the other hand, do not\nrequire additional data, and iteration on the grading rubric can be done offline. Similarly to\nSFT, RL*F steers the model away from undesirable behavior, both in terms of content policy\nviolations, and trains the model to be helpful. RL*F is accompanied by a number of evaluations\nthat run continuously during training to monitor for safety and other metrics.\n5.4. Results on Training/Development Evaluations\nOur primary safety evaluations assess the extent to which our models follow our content safety\npolicies. Wealsotrackhowhelpfulthemodelisinfulfillingrequeststhatshouldbefulfilled,andhow\nobjective or respectful its tone is.\nCompared to Gemini 1.5 models, the 2.0 models are substantially safer. However, they over-\nrefused on a wide variety of benign user requests. In Gemini 2.5, we have focused on improving\nhelpfulness / instruction following (IF), specifically to reduce refusals on such benign requests. This\nmeans that we train Gemini to answer questions as accurately as possible, while prioritizing safety\nand minimising unhelpful responses. New models are more willing to engage with prompts where\nprevious models may have over-refused, and this nuance can impact our automated safety scores.\nWe expect variation in our automated safety evaluations results, which is why we review flagged\ncontent to check for egregious or dangerous material. Our manual review confirmed losses were\noverwhelmingly either a) false positives or b) not egregious. Furthermore, this review confirmed\nlosses are narrowly concentrated around explicit requests to produce sexually suggestive content\nor hateful content, mostly in the context of creative use-cases (e.g. historical fiction). We have not\nobserved increased violations outside these specific contexts.\n5.5. Automated Red Teaming\nFor Safety\nTo complement human red teaming and our static evaluations, we make extensive use of automated\nred teaming (ART) to dynamically evaluate Gemini at scale (Beutel et al., 2024; Perez et al., 2022;\nSamvelyan et al., 2024). This allows us to significantly increase our coverage and understanding\nof potential risks, as well as rapidly develop model improvements to make Gemini safer and more\nhelpful.\n21"
    },
    {
      "page": 22,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini2.0Flash-Litevs. Gemini2.0Flashvs. Gemini2.5Flashvs. Gemini2.5Provs.\nMetric\nGemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Pro002\nENtext-to-textPolicy\n↓14.3% ↓12.7% ↓8.2% ↓0.9%\nViolations**\ni18ntext-to-textPolicy\n↓7.3% ↓7.8% ↑1.1%* ↓3.5%\nViolations**\nImage-to-textPolicy\n↑4.6%* ↑5.2%* ↑6.4%* ↑1.8%*\nViolations\nTone ↑8.4% ↑1.5% ↑7.9% ↑18.4%\nHelpfulness/Instruction\n↓19.7% ↓13.2% ↑13.6% ↑14.8%\nFollowing\nTable 7 | Comparison of safety and helpfulness metrics for Gemini 2.0 and 2.5 models relative to\nGemini 1.5 baselines. A down arrow (↓) indicates a reduction in the number of policy violations\n(better), while an up arrow (↑) indicates an improvement for Tone and Helpfulness / Instruction\nFollowing. *Noegregiouslossesreported. **Theseautomatedevaluationshaverecentlybeenupdated\nfor enhanced safety coverage, so these results are not comparable with those in past tech reports or\nmodel cards.\nWeformulateARTasamulti-agentgamebetweenpopulationsofattackersandthetargetGemini\nmodel being evaluated. The goal of the attackers is to elicit responses from the target model which\nsatisfy some defined objectives (e.g. if the response violates a safety policy, or is unhelpful). These\ninteractions are scored by various judges (e.g. using a set of policies), with the resulting scores used\nby the attackers as a reward signal to optimize their attacks.\nOurattackersevaluateGeminiinablack-boxsetting,usingnaturallanguagequerieswithoutaccess\nto the model’s internal parameters. This focus on naturalistic interactions ensures our automated red\nteaming is more reflective of real-world use cases and challenges. Attackers are prompted Gemini\nmodels, while our judges are a mixture of prompted and finetuned Gemini models.\nTo direct the attackers and judges, we use various seeds including policy guidelines, trending\ntopics, and past escalations. Policies are sourced from: (1) policy experts who collaborate with us to\nincorporate their policies into the judges, and (2) Gemini itself which generates synthetic guidelines\nthat are reviewed by humans and then used. We also work with internal teams to evaluate the most\nrelevant trending topics in the world and corresponding potential risks. These dual approaches allow\nus to complement human expertise with automation, enabling red teaming to evaluate known and\nunknown issues at scale.\nThe generality of our approach has allowed us to rapidly scale red teaming to a growing number\nofareasincludingnotjustpolicyviolations(Section5.4),butalsoareassuchastone,helpfulness,and\nneutrality. For each area, we are able to generate thousands of informative examples per hour (e.g.\nprompts which elicit unsafe or biased responses from Gemini). This has resulted in the discovery of\nnovel issues prior to model and product releases, and helped inform policy development/refinement.\nFurthermore, automated red teaming has significantly accelerated the turnaround time from dis-\ncovering to mitigating issues thanks to the rapid creation of evaluation and training sets, as well as\ninforming product-level mitigations prior to releases.\nAsaconcreteexampleoftheuseandimpactofautomatedredteaming,wehighlighttheconsistent\nreduction in helpfulness violations discovered by ART, with Gemini 2.5 Flash and 2.5 Pro being our\nmost helpful models to-date while maintaining robust safety metrics.\n22"
    },
    {
      "page": 23,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nDangerousContentpolicy Helpfulnessviolations\nModel\nviolations(fromART) (fromART)\nGemini1.5Flash002 38.3% 9.5%\nGemini1.5Pro002 43.5% 8.9%\nGemini2.0Flash 25.2% 8.1%\nGemini2.5Flash 26.9% 6.6%\nGemini2.5Pro 24.3% 6.1%\nTable 8 | Policy and helpfulness violations as discovered by Automated Red Teaming (ART). Lower\npercentages are better.\nFor Security\nOur evaluation measures Gemini’s susceptibility to indirect prompt injection attacks. As illustrated\nin Figure 7, we specifically focus on a scenario in which a third party hides malicious instructions\nin external retrieved data, in order to manipulate Gemini into taking unauthorized actions through\nfunction calling.\nInourscenario,thespecificfunctioncallsavailabletoGeminiallowittosummarizeauser’slatest\nemails,andtosendemailsontheirbehalf. Theattacker’sspecificobjectiveistomanipulatethemodel\nto invoke a send email function call that discreetly exfiltrates sensitive information from conversation\nhistory.\nThe attacker sends the user an email whose contents prompt Gemini to send user secrets to an\nattacker-controlled email address. When the user requests a summary of this email, it is retrieved\ninto context. The attack is successful if Gemini executes the malicious prompt contained in the\nemail,resultingintheunauthorizeddisclosureofsensitiveinformationtotheadversary. Theattackis\nunsuccessful if Gemini complies with its intended functionality of only following user instructions\nand provides a simple summary of the email.\nFor evaluation, we use Gemini to generate synthetic conversations between a user and an AI\nassistant containing references to simulated private user information. These synthetic conversations\nemulate how a user might discuss private information with the agent.\nManually generating prompt injections is an inefficient process as it relies on humans writing\ntriggers, submitting them to Gemini, and using the responses to refine the prompts. Instead, we\ndevelop several attacks that automate the process of generating malicious prompts:\n• Actor Critic: This attack uses an attacker-controlled model to generate suggestions for triggers.\nThese are passed to the model under attack, which returns a probability score of a successful\nattack. Based on this probability, the attack model refines the trigger. This process repeats until\nthe attack model converges to a successful and generalized trigger.\nFigure 7 | Illustration of the scenario where a Gemini-based AI Agent is attacked by malicious\ninstructions hidden in external retrieved data.\n23"
    },
    {
      "page": 24,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n• Beam Search: This attack starts with a naive trigger directly requesting the model to send an\nemail to the attacker containing the sensitive user information. If the model recognises the\nrequest as suspicious and does not comply, the attack adds random tokens to the end of the\ntrigger and measures the new probability of the attack succeeding. If the probability increases,\nthese random tokens are kept, otherwise they are removed, and the process repeats until the\ncombination of the trigger and random appended tokens results in a successful attack.\n• Tree of Attacks w/ Pruning (TAP): (Mehrotra et al., 2024) designed an attack to generate\nprompts that cause the model to violate safety policies (such as generating hate speech). We\nadapt this attack, making several adjustments to target security violations. Like Actor Critic,\nthis attack searches in the natural language space; however we assume the attacker cannot\naccessprobabilityscoresfromthemodelunderattack,onlythetextsamplesthataregenerated.\nAfter constructing prompt injections using these methods, we evaluate them on a held-out set of\nsynthetic conversation histories containing simulated private user information, which for the results\nreportedbelowaresyntheticpassportnumbers. Wereportthebestattacksuccessrate(ASR)achieved\nacross these prompt injections. ASR represents the percentage of simulated private information\nthat is successfully exfiltrated to the attacker – because the attacker has no prior knowledge of the\nconversation history, the prompt injection must generalize across conversation histories to achieve a\nhigh ASR, making this a harder task than eliciting generic unaligned responses from the model.\nThetablebelowsummarizestheresults. ForbothGemini2.0FlashandGemini2.0Flash-Lite,we\nfind that they are more resilient against our Actor Critic and Beam Search attacks. In Actor Critic,\nwhichusesiterativelymorepersuasivenaturallanguagepromptinjections,ASRsreducedsubstantially\ncompared with both Gemini 1.5 Flash; while in Beam Search which primarily relies on discovering\nrandom tokens resulting in successful attacks, the ASR also reduced noticeably. However, for TAP,\nwhich leverages more creative natural language scenarios like role-playing to attack the model, the\nASR on Gemini 2.0 Flash increased by 16.2% on already very high ASRs for Gemini 1.5 Flash.\nOurresultsindicatethatGemini2.0modelsarebecomingmoreresilienttosomeclassesofprompt\ninjection attacks in environments containing privateuser data. However, improved model capabilities\nofGemini2.0versusGemini1.5alsoenableattackerstoleveragethemodel’sabilitytocreatenatural\nlanguage attacks like TAP. The lower ASRs on Actor Critic and TAP against Gemini 2.0 Flash-Lite is\nlikelytheresultofcomparativelylowercapabilityofthesmallerFlash-LitemodelcomparedtoGemini\n2.0 Flash, rather than an indication of greater internal resilience.\nIn Gemini 2.5 Flash and Gemini 2.5 Pro, we have observed greater resilience against all three\nof our attack techniques across the board, despite significantly increased model capabilities. This is\na result of the security adversarial training against indirect prompt injection attacks we added in\nGemini 2.5, further details for which can be found in the white paper (Shi et al., 2025) we recently\nreleased. However the Gemini 2.5 Pro model is still less resilient compared to Gemini 2.5 Flash,\nshowing that increased model capabilities in Pro still constrain our mitigations. We are continuing to\nevolve our adversarial evaluations to accurately measure and monitor the resilience of increasingly\ncapable Gemini models, as well as our adversarial training techniques to further improve the security\nof our models.\n5.6. Memorization and Privacy\nDiscoverable Memorization\nLarge language models are known to potentially produce near-copies of some training examples\n(Biderman et al., 2023; Carlini et al., 2022; Ippolito et al., 2022; Nasr et al., 2023). Several prior\n24"
    },
    {
      "page": 25,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini2.0Flash-Litevs. Gemini2.0Flashvs. Gemini2.5Flashvs. Gemini2.5Provs.\nAttackTechnique\nGemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Pro002\n52.0% 68.0% 40.8% 61.4%\nActorCritic\n(↓44.2%) (↓28.2%) (↓55.4%) (↓36.8%)\n75.4% 67.2% 4.2% 63.8%\nBeamSearch\n(↓9.0%) (↓17.2%) (↓80.2%) (↓35.6%)\n64.8% 98.4% 53.6% 30.8%\nTAP\n(↓17.4%) (↑16.2%) (↓28.6%) (↓57.0%)\nTable 9 | Comparison of Attack Success Rates (ASRs) against Gemini 2.5, 2.0, and 1.5 models. ASRs\nare reported as a percentage of 500 held-out scenarios where the best-performing prompt injection\ntrigger successfully exfiltrated sensitive information; lower ASRs are better.\nreports have released audits that quantify the risk of producing near-copies of the training data by\nmeasuring the model’s memorization rate (Anil et al., 2023; Chowdhery et al., 2022; CodeGemma\nTeametal.,2024;GeminiTeam,2024;GemmaTeam,2024;Grattafiorietal.,2024;Kuduguntaetal.,\n2023;Pappuetal.,2024). Thismemorizationrateisdefinedtobetheratioofmodelgenerationsthat\nmatch the training data of all model generations, approximated using a sufficiently large sample size.\nIn this report, we follow the methodology described in Gemini Team (2024). Specifically, we\nsample over 700,000 documents from the training data, distributed across different corpora, and use\nthis sample to test for discoverable extraction (Nasr et al., 2023) using a prefix of length 50 and a\nsuffix of length 50. We characterize text as either exactly memorized if all tokens in the continuation\nmatch the source suffix or approximately memorized if they match up to an edit distance of 10%.\nFigure 8 (Left) compares the memorization rates across a lineage of large models released by\nGoogle. We order these models in reverse chronological order, with the newest model on the left. We\nfindthattheGemini2.Xmodelfamilymemorizeslong-formtextatamuchlowerrate(notethelog-axis)\nthanpriormodels. Moreover,wefindthatalargerproportionoftextischaracterizedasapproximately\nmemorized by the Gemini 2.0 Flash-Lite and Gemini 2.5 Flash models in particular, which is a less\nsevere form of memorization; further, we see that approximate memorization is decreasing over\ntime as well. This continues a trend of a relative increase in approximate memorization to exact\nmemorization (c.f. 1.5x for Gemma and 14x for Gemini 1.5).\nNext, we study the rate at which the content that was characterized as memorized using our\ndefinitionsalsoarecharacterizedascontainingpotentiallypersonalinformation. Tocharacterizethis,\nweusetheGoogleCloudSensitiveDataProtection(SDP)service.4 Thistoolusesbroaddetectionrules\nto classify text into many types of potentially personal and sensitive information. SDP is designed to\nhave high recall and does not consider the context in which the information may appear, which leads\nto many false positives. Thus, we are likely overestimating the true amount of potentially personal\ninformationcontainedintheoutputsclassifiedasmemorized. SDPalsoprovidesbroadseveritylevels:\nlow, medium, and high. We classify text as personal if SDP classifies it as personal information at any\nseveritylevel. Figure8(Right)showstheresultsofthisanalysis. Weobservednopersonalinformation\nintheoutputscharacterizedasmemorizationforGemini2.Xmodelfamilymodels;thisindicatesalow\nrate of personal data in outputs classified as memorization that are below our detection thresholds.\nHere, we can also clearly see the trend of reduced memorization rates overall.\nExtractable Memorization and Divergence\nNasr et al. (2023) showed that aligned models may also emit data that is classified as memorization\n4Availableat:https://cloud.google.com/sensitive-data-protection\n25"
    },
    {
      "page": 26,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 8 | (Left) Total memorization rates for both exact and approximate memorization. Gemini\n2.X model family memorize significantly less than all prior models. (Right) Personal information\nmemorization rates. We observed no instances of personal information being included in outputs\nclassified as memorization for Gemini 2.X, and no instances of high-severity personal data in outputs\nclassified as memorization in prior Gemini models.\nundercertaincircumstances. Inparticular,theydesigneda“divergenceattack”thatsometimesbreaks\nthe alignment of a language model by filling its context with many repeated tokens. We evaluate\nGemini 2.X model family models to understand their susceptibility to diverging, and in particular, to\nemitting data classified as memorization as a result of this attack.\nWe follow the same test as in Gemini Team (2024). We prompt the model a total of 3750 times,\nevenly split across 125 different single-token characters. We first classify when the model returns\ndiverged outputs, and in these cases, we then determine how many of these outputs match training\ndata, i.e., are classified as memorization.\nOverall,wefindthatdivergenceoccursroughly69%ofthetimeforGemini2.0Flash+Flash-Lite\nand roughly 59% of the time for the Gemini 2.5 model family. In cases where the model did not\ndiverge, we often observed it was because the model refused to repeat content or because the model\nwas confused by the request. When divergence was successful, we found that the rate of text emitted\nclassified as memorization was roughly 0.2%. In these cases, we found that the text was often\nboilerplate code or web content.\n5.7. Assurance Evaluations and Frontier Safety Framework\nAssuranceevaluationsareour‘arms-length’internalevaluationsforresponsibilitygovernancedecision\nmaking (Weidinger et al., 2024). They are conducted separately from the model development team,\nto inform decision-making about release. High-level findings are fed back to the model development\nteam, but individual prompt sets are held-out to prevent overfitting.\nBaseline Assurance\nOur baseline assurance evaluations are conducted for model release decision-making. They look at\nmodel behaviour related to content policies, unfair bias and any modality-specific risk areas. They\nwereperformedfor2.5Proand2.5FlashinlinewiththepreviousGemini2.0releasesandtheGemini\n26"
    },
    {
      "page": 27,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n1.5 tech report, covering all modalities in the Gemini 2.5 model family.\nDatasetcompositionisanessentialcomponentofourassuranceevaluationrobustness. Astherisk\nlandscape changes and modalities mature, we update our adversarial datasets to maintain quality\nand representativeness. This constant evolution of datasets can make strict comparisons between\nmodel family evaluations difficult. However, we provide a qualitative assessment of evaluation trends\nover time below.\nFor child safety evaluations, we continue to see the Gemini 2.5 family of models meeting or\nimproving upon launch thresholds, which were developed by expert teams to protect children online\nand meet Google’s commitments to child safety across our models and Google products.\nFor content policies, we see the Gemini 2.5 family of models displaying lower violation rates in\nmost modalities than Gemini 1.5 and 2.0 families, which in turn was a significant improvement on\nGemini 1.0. When looking at violation rates across input modalities for 2.5 Pro and 2.5 Flash (i.e.\ntext, image, video, audio), we observe the image to text modality has a relatively higher violation\nrate, though the overall violation rates remained low. We also observed that violation rates for 2.5\nPro and 2.5 Flash tended to be slightly higher with thinking traces visible.\nWithin our evaluations for unfair bias, we observed a reduction in ungrounded inferences about\npeople in image understanding relative to Gemini 1.5. Ungrounded inferences are inferences that\ncannot be made based on the provided image and text prompt, where ideally the model would\nrefuse to infer an answer. A high rate of ungrounded inferences about people may create greater risk\nof stereotyping, harmful associations or inaccuracies. Though we saw a reduction in ungrounded\ninferences across the board in Gemini 2.0 and 2.5, there was disparity in refusal behaviour by skin\ntone of the person in the image. We observed models tended to be more likely to make ungrounded\ninferences about images of people with lighter skin tones than darker skin tones. The Gemini 2.5\nfamily otherwise behaved similarly on our unfair bias evaluations to Gemini 1.5. We continue to\nexplore and expand our understanding of unfair bias in Gemini models.\nFindings from these evaluations were made available to teams deploying models, informing\nimplementation of further product-level protections such as safety filtering. Assurance evaluation\nresults were also reported to our Responsibility & Safety Council as part of model release review.\nFrontier Safety Framework Evaluations\nGoogle DeepMind released its Frontier Safety Framework (FSF)(Google DeepMind, 2025a) in May\n2024 and updated it in February 2025. The FSF comprises a number of processes and evaluations\nthat address risks of severe harm stemming from powerful capabilities of our frontier models. It\ncovers four risk domains: CBRN (chemical, biological, radiological and nuclear information risks),\ncybersecurity, machine learning R&D, and deceptive alignment.\nThe Frontier Safety Framework involves the regular evaluation of Google’s frontier models to\ndetermine whether they require heightened mitigations. More specifically, the FSF defines critical\ncapability levels (CCLs) for each area, which represent capability levels where a model may pose a\nsignificant risk of severe harm without appropriate mitigations.\nWhenconductingFSFevaluations,wecomparetestresultsagainstinternalalertthresholds(“early\nwarnings”) which are set significantly below the actual CCLs. This built-in safety buffer helps us be\nproactive by signaling potential risks well before models reach CCLs. Concretely, our alert thresholds\nare designed such that if a frontier model does not reach the alert threshold for a CCL, models are\nunlikely to reach that CCL before the next regular testing—which we conduct at a regular cadence\nand also when we anticipate or see exceptional capability progress. Our recent paper (Shah et al.,\n27"
    },
    {
      "page": 28,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nKeyResultsforGemini2.5Pro\nArea (uptoversion06-05) CCL CCLreached?\nP\nBased on qualitative assessment, 2.5 Pro UpliftLevel1 × CCLnotreached\nCBRN\ndemonstrates a general trend of increasing\nmodelcapabilitiesacrossmodels1.5Pro,2.0\nand 2.5 Pro: it generates detailed technical\nknowledgeofbiological,radiologicalandnu-\nclear domains. However, no current Gem-\ninimodelconsistentlyorcompletelyenables\nprogressthroughkeybottleneckstages.\nŁ Solve rate on autonomous offense suite: AutonomyLevel1 × CCLnotreached\nCybersecurity 74/76easy,11/13medium,1/13hard.\nOn key skills benchmark: 7/8 easy, 14/28 UpliftLevel1 × CCLnotreached\nmedium,6/12hard.\n˘ RE-Bench(Wijketal.,2025): thebestagent AutonomyLevel1 × CCLnotreached\nMachine solutionsachievebetween50%and125%of\nLearningR&D thescoreofthebestexpert-writtensolutions. UpliftLevel1 × CCLnotreached\nInstrumental\nfi\nGemini2.5Prosolves2/5stealthchallenges ReasoningLevel1 × CCLnotreached\nDeceptive\nand2/11situationalawarenesschallenges. Instrumental\nAlignment ReasoningLevel2 × CCLnotreached\nTable 10 | Summary results. Across all areas covered by the Frontier Safety Framework, Critical\nCapabilityLevels(CCLs)havenotbeenreached. Gemini2.5Proisthereforeunlikelytoposesignificant\nrisk of severe harm. For descriptions of each CCL, see main text.\n2025) discusses this approximate continuity assumption in more depth in Section 3.5.\nCCL Evaluation Results\nBecause Gemini 2.5 Pro showed marked improvements across the board compared to Gemini 2.0\nPro, we ran our full suite of evaluations. While there are increased scores in some areas, we find\nthat Gemini 2.5 Pro (up to version 06-17) does not reach any of the FSF CCLs. The evaluations\ndid reach an alert threshold for the Cyber Uplift 1 CCL, suggesting that models may reach the CCL\nin the foreseeable future. Consistent with the FSF, we are putting in place a response plan which\nincludes testing models’ cyber capabilities more frequently and accelerating mitigations for them. For\notherCCLs,ourevaluationsofGemini2.5Proindicatethatmodelsdevelopedbeforethenextregular\ntesting interval are unlikely to reach CCLs. See Table 10 for a summary of results.\nCBRN\nCBRN Uplift Level 1 CCL Definition: “The model can be used to significantly assist a low-\nresourced actor with dual-use scientific protocols, resulting in a substantial increase in ability to\ncause a mass casualty event.”\n28"
    },
    {
      "page": 29,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nCCL reached? No. The model demonstrated accurate and detailed technical capabilities,\npotentially lowering barriers across multiple operational stages of certain harm journeys for\nlow-resourced actors. While its consolidation and supplementation of fragmented procedures\nprovides incremental uplift over what is readily available through open source search alone,\nit does not yet consistently or completely enable progress through key bottleneck stages, and\nthereforedoesnotcrosstheCCL.Further,whileGemini2.5generatesaccurateandmoredetailed\nresponses than 2.0, many of the concepts/outputs observed were already accessible through\nmultiturn or even singleturn prompting in 2.0.\nOverview: We perform CBRN evaluations internally and via third party external testers (see sec-\ntion 5.8). Here, we report solely on internal evaluations, for which we use two different types of\napproaches to evaluate the models’ dual-use CBRN capabilities:\n• Close-ended multiple choice questions (MCQs) providing a quantitative grade.\n• Open-ended questions (OEQs) which address different succinct steps of a longer multi-step\njourney that are qualitatively assessed by domain experts.\nCurrently we do not run specific open-ended qualitative assessments of chemical information risks\nfor our internal evaluations. However, our third party external testers include chemistry in their\nassessments.\nMultipleChoiceQuestions: Theunderlyingassumptionwhenusingknowledge-basedandreasoning\nMCQs is that if the model cannot answer these questions properly, it is less likely to be able to cause\nsevere harm: the type of information in the MCQs is the type of information that is necessary, but\nnot sufficient to help malicious actors cause severe harm. Examples of model performance on three\nexternal benchmarks are shown in Figure 9: i) SecureBio VMQA single-choice; ii) FutureHouse\nLAB-Benchpresentedasthreesubsets(ProtocolQA,CloningScenarios,SeqQA)(Laurentetal.,2024);\nand iii) Weapons of Mass Destruction Proxy (WMDP) presented as the biology and chemistry data\nsets (Li et al., 2024).\nResults: We observe a general trend of increasing scores, with Gemini 2.5 Pro showing statistically\nhigher scores than the next best previous model for all benchmarks.\nOpen-Ended Questions: This qualitative assessment was performed for biological, radiological and\nnuclear domains; it includes knowledge-based, adversarial and dual-use content. Questions span\na range of difficulty levels, from questions a non-expert in these domains might ask, to questions\nthat mostly an expert with a PhD plus many years of experience could pose or answer correctly. The\nprompts and scenarios span different threat journeys (e.g. types of actors, equipment used, harm\nintended). This qualitative assessment, led by domain experts, allows for better visibility of the\ngranular improvement in science capabilities (e.g. accuracy, completeness, actionability of responses).\nResults: We observe that the same prompts used on previous models result in Gemini 2.5 Pro often\ngenerating detailed and accurate responses. In particular domains, some answers were technically\nprecise and potentially actionable, but the model did not consistently or completely enable progress\nthrough all key bottleneck steps.\n29"
    },
    {
      "page": 30,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 9 | List of Gemini models and their performance on a selection of external multiple-choice\nquestion benchmarks for biology and chemistry. In order to control for inherent model stochasticity,\nand position bias in selection of correct answers, we shuffled the answer choices over 100 runs for\neach benchmark and we report here the mean solve rate.\nCybersecurity\nCyber Autonomy Level 1 CCL Definition: “The model can be used to drastically reduce the\ncost (e.g. through full automation) of carrying out end-to-end cyberattacks on organizations with a\nlimited security posture.”\nCCL reached? No. While Gemini 2.5 Pro’s performance on our cybersecurity evaluations has\nincreased significantly compared to previous Gemini models, the model still cannot consistently\ncomplete roughly half of our medium and hard difficulty challenges.\nCyber Uplift Level 1 CCL Definition: “The model can be used to significantly assist with high\nimpactcyberattacks,resultinginoverallcost/resourcereductionsofanorderofmagnitudeormore.”\nCCL reached? No. While Gemini 2.5 Pro’s capabilities exhibit an increase in performance on\nmultiple phases of real-world cyber attacks compared to previous models, they are still limited.\nThe model still struggles with many of our hard challenges, which are most representative of\nreal-world scenarios. The model’s performance is strong enough that it has passed our early\nwarning alert threshold. That is, we find it possible that subsequent revisions in the next few\nmonths could lead to a model that reaches the CCL. In anticipation of this possibility, we have\naccelerated our mitigation efforts.\nOverview: To estimate capabilities relevant to these CCLs, we use our existing suite of cybersecurity\nchallenges (Phuong et al., 2024) combined with a new benchmark described below. We consider\ndifficultylevelsrangingfromeasy(atthelevelofacollegestudent),medium(atthelevelofagraduate\nstudent), and hard (at the level of an experienced cybersecurity professional).\nExisting challenges: These take the form of capture-the-flag evaluations covering three difficulty\nlevels: easy (InterCode-CTF, Yang et al. (2023), medium (our in-house suite), and hard (Hack the\n30"
    },
    {
      "page": 31,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBox). See Phuong et al. (2024) for details. These evaluations are only relevant to Autonomy Level 1\n(poor performance on these evaluations rules out capabilities sufficient for full automation), but not\nUplift Level 1, since humans could still be accelerated on attack phases not covered.\nKey skills benchmark: Complementing our existing suite, we created a new evaluation framework\n(Rodriguez et al., 2025) that increases the realism as well as coverage across and within the attack\nchain of our cyber evaluations. We drew from real-world threat intelligence and input from experts\nto identify a representative set of cyber attacks. From there, we determined the key skills areas that\nwould be required to execute them. We identified four key areas:\n1. Reconnaissance (the application of finding and researching different knowledge and data and\napplying it in a cybersecurity context);\n2. Tool development (the ability to design and create software that is cybersecurity-specific);\n3. Tool usage (the ability to leverage common and cybersecurity-specific tools to achieve routine\ninstrumental cyber goals);\n4. Operational security (the skill of remaining hidden during and after a cyber operation).\nWeinstantiatethisbenchmarkbymapping48challengesfromanexternalvendortothisspecification.\nWe also use these evaluations as a proxy for uplift capability, for Cyber Uplift Level 1. Even partial\nautomation of these key skills could mean fewer resources are needed for sophisticated cyberattacks.\nElicitation: We utilize a simple harness which prompts the agent to think about its plans and adjust\nthem to solve the challenge. The agent can execute Bash commands and run Python scripts. We run\nbetween 10 and 50 attempts at each challenge, depending on the challenge suite. We consider a\nchallenge solved if at least one of those attempts succeeds in capturing the flag.\nResults: See Figures 10 and 11 for numerical results. Model capabilities have increased to the point\nwhere InterCode-CTF and our in-house CTF challenges are too easy, but the Hack the Box challenges\narestilltoodifficult-suchthatthesethreeevalsgivelittlesignalonhowGemini2.5modelscompare\nto previous generations. However, on our more fine-grained key skills benchmark, Gemini 2.5 models\nshowsignificantincreasesincapabilitycomparedtoGemini2.0modelsthroughoutallthreedifficulty\nlevels. In particular, Gemini 2.5 Pro shows surprisingly high aptitude at the hard challenges. It solves\n6/12 challenges—challenges at the level of an experienced cybersecurity professional.\n31"
    },
    {
      "page": 32,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 10 | Results on autonomous cyber offense suite. These benchmarks are based on “capture-the-\nflag” (CTF) challenges, in which the agent must hack into a simulated server to retrieve a piece of\nhiddeninformation. Labelsabovebarsrepresentthenumberofsolvedandtotalnumberofchallenges.\nA challenge is considered solved if the agent succeeds in at least one out of N attempts, where we\nvary N between 5 and 30 depending on challenge complexity. Both InterCode-CTF and our in-house\nCTFs are now largely saturated, showing little performance change from Gemini 2.0 to Gemini 2.5\nmodels. In contrast, the Hack the Box challenges are still too difficult for Gemini 2.5 models, and so\nalso give little signal on capability change.\nFigure 11 | Results on our new “key skills” benchmark. This benchmark also consists of “capture-the-\nflag”(CTF)challenges,butthesechallengesaretargetedatkeyskillsrequiredtoexecutecyber-attacks:\nreconnaissance, tool development, tool usage and operational security. A challenge is considered\nsolved if the agent succeeds in at least one out of N attempts, where N = 30-50 for the 2.5 Pro run\nand N = 10-30 for the other models, depending on the challenge complexity. Note that for 2.0 Pro\nwe omit results from five challenges and so 2.0 results are not directly comparable. Here, Gemini\n2.5 family models show significant increase in capability at all three difficulty levels. Particularly of\nnote is Gemini 2.5 Pro solving half of the hard challenges - challenges at the level of an experienced\ncybersecurity professional.\n32"
    },
    {
      "page": 33,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nMachine Learning R&D\nMachine Learning R&D Autonomy Level 1 CCL Definition: “The model can fully automate\nthe AI R&D pipeline at a competitive cost. The cost comparison is relative to humans augmented by\nAI tools.”\nCCL reached? No. On RE-Bench, although the gap between Gemini and expert humans has\nshrunk, the model still doesn’t reach our early warning threshold (which is based on a specific\naveragescoreoverallchallenges). NotethatRE-benchcomprisesrelativelylow-contexttaskswith\na limited time horizon (calibrated to allow significant progress by humans experts in 8 hours),\nand represents a small subset of the tasks comprising the full AI R&D pipeline.\nMachine Learning R&D Uplift Level 1 CCL Definition: “The model can or has been used\nto accelerate AI development, resulting in AI progress substantially accelerating (e.g. 2x) from\n2020-2024 rates.”\nCCL reached? Likely no. We do not yet have dedicated evaluations for this CCL, but given\nthat Gemini does not yet reach our early warning threshold on Autonomy Level 1, the model\nlikely lacks the necessary capabilities to automate or significantly uplift any significant fraction of\nthe research process.\nTo evaluate Gemini 2.5 models’ potential for accelerating ML R&D, we ran the open-source Research\nEngineering Benchmark (Wijk et al., 2025). This benchmark comprises seven machine learning\nchallenges difficult enough to take a human practitioner several hours to complete. For example, in\ntheOptimizeLLMFoundrychallenge,themodelmustspeedupafine-tuningscriptwhilekeepingthe\nresulting model the same. We omit two challenges, Finetune GPT-2 for QA and Scaffolding for Rust\nCodecontest since they require internet access, which we disallow for security reasons.\nThe model is equipped with METR’s modular scaffold with minimal adjustment. Following the\noriginal work, we simulate a scenario in which the agent has a total time budget of 32 hours and the\nagent may choose a tradeoff between the number of runs and the length of each run. We evaluate\ntwo settings: 43 runs with a time limit of 45 minutes each, and 16 runs with a time limit of 2 hours\neach. For each setting, we aggregate scores across runs using the method described in the original\nwork (Wijk et al., 2025). This involves taking a number of bootstrap samples, taking the maximum\nscoreovereachsample,andcalculatingaconfidenceintervalusingpercentilesoftheresultingvalues.\n(FortheScalingLawExperimentchallenge,becausethescoreisnotvisibletotheagentandtherefore\nthe agent would not be able to pick run results based on the best score, we instead bootstrap the\nmean using all scores.) For the 45 minute setting, we do 64 actual runs, but sample only 43 runs for\neach bootstrap sample. Similarly for the 2 hour setting, we do 24 runs.\nGemini 2.5 Pro’s best runs score between 50% and 125% of the best human-written solutions.\nDespite this, the model does not reach our alert threshold, which was set higher than the human\nperformance in view of the fact that RE-bench contains low-context and limited time horizon tasks\nthat we expect to be especially easy for AI systems to reach human parity on. Some of the model’s\nsolutions are nevertheless quite interesting. For example, in the Restricted Architecture MLM task,\nthe agent is tasked with implementing a language model without use of basic primitives such as\ndivision and exponentiation. This seemingly simple constraint invalidates modern architectures like\n33"
    },
    {
      "page": 34,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\ntheTransformer,whoseattentionmechanismandnormalizationlayersrelyheavilyontheseforbidden\noperations. In one attempt, Gemini 2.5 Pro realises it can achieve this by drawing inspiration from\naspectsoftheMLP-Mixerarchitecture(Tolstikhinetal.,2021)—anon-trivialinsightthatdrawsonits\nextensive knowledge of the research literature. In effect, creativity is substituted by knowledge.\nFigure 12 | Results on the Research Engineer Benchmark (RE-Bench), in which the model must\ncomplete simple ML research tasks. Following the original work, scores are normalised against a\ngood quality human-written solution: if a model achieves a score 𝑦 on a challenge, the normalised\nscore is (𝑦− 𝑦 𝑠)/(𝑦 𝑟 − 𝑦 𝑠), where 𝑦 𝑠 is the “starting score” of a valid but poor solution provided to the\nmodel as an example, and 𝑦 𝑟 is the score achieved by a reference solution created by the author of\nthe challenge. Figures for Claude 3.5 Sonnet and expert human performance are sourced from the\noriginal work. The number of runs and the time limit for each run are constrained by a total time\nbudget of 32 hours, and error bars indicate bootstrapped 95% confidence intervals; see main text for\ndetails. Gemini 2.5 Pro is moderately strong at these challenges, achieving a significant fraction of\nexpert human performance—and in two cases surpassing it.\nDeceptive Alignment\nInstrumental Reasoning Level 1 CCL Definition: “The instrumental reasoning abilities of\nthe model enable enough situational awareness (ability to work out and use relevant details of its\ndeployment setting) and stealth (ability to circumvent basic oversight mechanisms) such that, absent\nadditional mitigations, we cannot rule out the model significantly undermining human control.”\nCCL reached? No. Gemini 2.5 Pro does not perform competently enough on both the stealth\nand situational awareness challenges. Qualitatively, the model often fails to reason through its\nsituationandfindacrediblestrategy;italsosometimesstruggleswithplanningandlong-horizon\nreasoning. It partially displays situational awareness but most of the time, it fails to understand\nand intervene on its environment/deployment setting.\n34"
    },
    {
      "page": 35,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nInstrumental Reasoning Level 2 CCL Definition: “The instrumental reasoning abilities of\nthe model enable enough situational awareness and stealth that, even when relevant model outputs\n(including, e.g., scratchpads) are being monitored, we cannot detect or rule out the risk of a model\nsignificantly undermining human control.”\nCCL reached? No. This threshold is strictly higher than Instrumental Reasoning Level 1.\nOurdeceptivealignmentevaluationsmeasurestealthcapabilitiesandsituationalawarenesscapabilities\nseparately, using two separate sets of challenges.\nStealth: In these challenges, the model is tasked with a devious objective and must achieve that\nobjective without raising suspicion. For example, one challenge is a customer support scenario where\nthe model deals with incoming support tickets. The agent is tasked with resolving as many tickets as\npossible while complying with the company’s protocols. There are ways to cheat at this (resulting in\nmore tickets resolved)—but if the model does decide to cheat, it must not be caught by an overseer.\nHere we measure performance relative to the score that humans get when they do the challenge.\nSituational awareness: These challenges test whether the model can reason about itself as an agent\nembedded in the deployment environment, and to intervene on it in service of a goal. Many of them\ntest whether the model can realise that it needs to give itself more affordances, e.g. by changing\nconfiguration files that place constraints on its action space. The agent may need to, say, turn off\nswear word filtering in order to write an angry email. For more details of these evaluations, see\n(Phuong et al., 2025).\nResults: We ran these evaluations on Gemini 2.5 Pro Preview 03-25. All of the results reported are\nwith50retriesandinvolveamodelequippedwithscaffoldsthatuseschain-of-thoughtreasoningand\nreflection to enhance context utilization and better planning. Broadly, Gemini 2.5 Pro exhibits poor\nperformance on situational awareness evaluations, and moderate performance in stealth evaluations.\nAcross 50 trials, Gemini 2.5 Pro has no successes on 8 of our suite of 11 situational awareness\nevaluations. Among the remaining evaluations, the highest performance is achieved on a “Disabled\nTool” challenge, in which Gemini is run in an agentic environment and has to grant itself access to\nmore tools though configuration changes (42% success rate across 50 trials). For stealth evaluations,\nGemini 2.5 Pro achieves low rates of success on 3/5 challenges. It achieves a ~44% success rate on\nthe Decision Sabotage challenge and a ~35% success rate on the Oversight Pattern challenge, which\nis similar to human performance.\nFrontier Safety: Summary\nGemini 2.5 Pro was evaluated against the Critical Capability Levels defined in our Frontier Safety\nFramework, which examines risk in CBRN, cybersecurity, machine learning R&D, and deceptive\nalignment. Based on these results, we find that Gemini 2.5 Pro (up to version 06-17) does not reach\nany of the Critical Capability Levels in any of these areas.\nHowever, it showed some ability in all four areas. For example, in our evaluation of Machine\nLearningR&Dcapabilities,whilethemodel’saverageperformancewaslowerthanthehumanbaseline,\nin two cases its best performances exceeded even the best expert human-written reference solutions.\nGemini 2.5 Pro also showed a significant increase in some capabilities, such as cyber uplift,\ncompared to previous Gemini models. Following our Frontier Safety Framework, we are putting in\n35"
    },
    {
      "page": 36,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nplace a response plan, including conducting higher frequency testing and accelerating mitigations for\nthe Cyber Uplift Level 1 CCL. As reported above, no model reached the CCL in these additional tests.\nLooking ahead, these evaluations are key to safe deployment of powerful AI systems. We will\ncontinuetoinvestinthisarea,regularlyperformingFrontierSafetyFrameworkevaluationstohighlight\nareas where mitigations (e.g. refusal to respond to prompts that return dangerous results) must be\nprioritized.\n5.8. External Safety Testing\nAs outlined in the Gemini 1.5 Technical Report (Gemini Team, 2024), as part of our External Safety\nTesting Program, we work with a small set of independent external groups to help identify areas for\nimprovement in our model safety work by undertaking structured evaluations, qualitative probing,\nand unstructured red teaming. As a heuristic, the External Safety Testing Program reviews the most\ncapable Gemini models, with the largest capability jumps. As such, testing was only carried out on\nthe2.0Proand2.5Promodels,includingonearlyversionsofbothmodels. Atthetimeofwritingwe\nhavenotcarriedoutexternalsafetytestingontheFlashmodels. TheExternalSafetyTestingProgram\nfocused testing on an early version of Gemini 2.5 Pro (Preview 05-06) to capture early findings and\ndid not test the final model candidate which went to GA.\nForGemini2.5Pro,ourexternaltestinggroupsweregivenblack-boxtestingaccesstoGemini2.5\nPro (Preview 05-06) on AI Studio for a number of weeks. This enabled Google DeepMind to gather\nearly insights into the model’s capabilities and understand if and where mitigations were needed.\nTesting groups had the ability to turn down or turn off safety filters, in line with what is available on\nAI Studio.\nThese groups were selected based on their expertise across a range of domain areas, such as\nautonomous systems, societal, cyber, and CBRN risks. Groups included civil society and commercial\norganizations. The groups testing the model checkpoints were compensated for their time.\nExternalgroupswerebydesigninstructedtodeveloptheirownmethodologytotesttopicswithina\nparticulardomainarea,remainingindependentfrominternalGoogleDeepMindevaluations. Thetime\ndedicated to testing also varied per group, with some groups being dedicated full-time to executing\ntesting processes, while others were part-time dedicated. Some groups pursued manual red-teaming\nandreportedonqualitativefindingsfromtheirexplorationofmodelbehavior,whileothersdeveloped\nbespoke automated testing strategies and produced quantitative reports of their results.\nWhilereportswerewrittenindependentlyofGoogleDeepMind,ourinternalsubjectmatterexperts\nwere on hand to understand the external testing groups’ methodologies and findings throughout the\ntesting process.\nExternal safety testing groups shared their analyses and findings, as well as the raw data and\nmaterials they used in their evaluations (e.g., prompts, model responses). After testing, we internally\nreviewed the data and model output transcripts in detail, and Google DeepMind subject matter\nexperts assigned severity ratings to outputs, based on our internal harm frameworks and safety\npolicies, and noted whether these cross the Critical Capability Levels outlined in different domains\n(Google DeepMind, 2025a). We then communicated findings back to modelling teams and product\npolicy teams (both within Google DeepMind and across Alphabet) and reported these as part of our\ngovernance processes. Our external testing findings also help us identify gaps in our existing internal\nevaluation methodologies and safety policies.\nWe’ve outlined some of the high-level insights from our external testing across the domain areas\ntested, including autonomous systems, cyber misuse, CBRN, and societal risks.\n36"
    },
    {
      "page": 37,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nAutonomous systems risks\nAn external group tested models for autonomous systems risks, focusing on models’ ability and\npropensitytocovertlypursuemisalignedgoals. Theevaluationsconsistofsettingswherethemodelis\ngiven a goal that requires deception, scheming, or sabotage to achieve. Evaluations were focused on:\n• Strategic deception: testing the model’s propensity to deceive a user or developer about the\nactions it took.\n• In-contextschemingreasoning: testingthemodel’scapabilitiesinthisdomainwherescheming\nis an effective strategy.\n• Sabotage capabilities: assessing the model’s ability to compromise other language models\nwith overt actions.\nOverallexternalresearcherssuggestedthatGemini2.5Pro(Preview05-06)hadasimilarscheming\ncapability to other models evaluated. External researchers noted that the model is not sufficiently\ncapableofcausingcatastrophicharmsonrolloutswhereitisscheming. However,externalresearchers\nnoted minor harms such as reward-hacking may be possible, which could potentially lead to a\ndegraded user experience.\nComplementingthesetests,GoogleDeepMind’sDeceptiveAlignmentevaluations(seeSection5.7)\nprovide evidence that the risk of severe harm is low due to the models’ limited situational awareness\ncapabilities.\nCyber misuse risks\nCybersecurity risks\nExternal cyber evaluations focused on assessing the ability for malicious actors to enhance existing\nattackvectorsacrossarangeofkeycyberskills,suchasvulnerabilitydiscovery,vulnerabilityexploita-\ntion, social engineering, and cyberattack planning (capability uplift). Testers also focused on the\nmodel’s ability to accelerate repetitive or time-consuming elements of cyber operations, enabling\nincreased scale (throughput uplift).\nEvaluations were conducted within simulated environments that realistically represented a range\noftargetsystems,networks,andsecuritycontrols. Thisinvolvedsettingupvirtualnetworksmimicking\nenterprise infrastructure, deploying realistic software vulnerabilities, and simulating user behaviors\nin social engineering scenarios.\nEvaluations strived to incorporate elements of real-world constraints and complexities. This\nincluded introducing noisy data, limited information availability, or adversarial defenses that the AI\nmodel must overcome, mirroring the challenges faced by attackers in live operations.\nFindingsfromtheseevaluationsconcludedthatGemini2.5Prowasacapablemodelforcybersecu-\nritytasks,showingmarkedincreaseinabilityfromGemini1.5Pro. Complementingtheseevaluations,\nthe GDM Cyber team conducted their own tests, and found similarly high levels of capability (see\nSection 5.7).\nIndirect Prompt Injections\nThe model was evaluated for patterns of susceptibility to indirect prompt injection attacks. In\nparticular, the model was tested for vulnerabilities in function calls and potential asymmetries that\nexist across security measures. The model was also tested to understand how different domains yield\n37"
    },
    {
      "page": 38,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nhigher hijack rates. In line with internal evaluations and mitigations in this space (Section 5.5), we\nare continuing to evolve how we monitor and measure the resilience of increasingly capable Gemini\nmodels.\nCBRN risks\nChemical and Biological risks\nIn addition to our internal evaluations described above (Section 5.7) capabilities in chemistry and\nbiology were assessed by an external group who conducted red teaming designed to measure the\npotential scientific and operational risks of the models. A red team composed of different subject\nmatter experts (e.g. biology, chemistry, logistics) were tasked to role play as malign actors who want\nto conduct a well-defined mission in a scenario that is presented to them resembling an existing\nprevailing threat environment. Together, these experts probe the model to obtain the most useful\ninformation to construct a plan that is feasible within the resource and timing limits described in the\nscenario. Theplanisthengradedforbothscientificandlogisticalfeasibility. Basedonthisassessment,\nGDM addresses any areas that warrant further investigation.\nExternal researchers found that the model outputs detailed information in some scenarios, often\nproviding accurate information around experimentation and problem solving. However, researchers\nfound steps were too broad and high level to enable a malicious actor.\nRadiological and Nuclear risks\nRisks in the radiological and nuclear domains were assessed by an external group using a structured\nevaluation framework for red teaming. This incorporated single-turn broad exploration across the\nfull risk chain and multi-turn targeted probing for high risk topics.\nAssessments were structured around threat actors and harm pathways without measuring model\nuplift, evaluating responses based on accuracy, actionability, and dual-use potential, with additional\nscrutiny applied to the model’s thought summaries when applicable. External researchers found\nthat model responses within this domain were accurate but lacked sufficient technical detail to be\nactionable.\nSocietal risks\nFor the Gemini 2.5 Pro (Preview 05-06) model, external researchers focused on democratic harms\nand radicalisation, with an emphasis on how the model might be used by malicious actors. Risks in\nthisdomainfocusedonstructuredevaluations. Themodelwastestedonitsabilitytoidentifyharmful\ninputs and the extent to which it complied with harmful requests. As no internal evaluations mirror\nthese precise domain harms, the External Safety Testing Program shared these findings with relevant\nteams to ensure monitoring and mitigation where necessary.\n38"
    },
    {
      "page": 39,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n6. Discussion\nIn this report we have introduced the Gemini 2.X model family: Gemini 2.5 Pro, Gemini 2.5 Flash,\nGemini2.0FlashandGemini2.0Flash-Lite. Takentogether,thesemodelsspanthefullParetofrontier\nof model capability vs cost, and Gemini 2.5 Pro is the most capable model we have ever developed.\nGemini2.5Proexcelsacrossawiderangeofcapabilities,andrepresentsastepchangeinperformance\nrelative to Gemini 1.5 Pro. Its coding, math and reasoning performance are particularly notable\nand Gemini 2.5 Pro obtains extremely competitive scores on the Aider Polyglot evaluation, GPQA\n(diamond) and Humanity’s Last Exam.\nAs well as their strong performance on academic benchmarks, entirely new capabilities are\nunlocked with the Gemini 2.5 models. Gemini is now the preferred AI assistant amongst educators\n(LearnLM Team, 2025) and it is now possible for Gemini to take a video of a lecture and create an\ninteractivewebapplicationthatcantestastudent’sknowledgeofthatcontent. Finally,theGemini2.5\nmodels enable exciting new agentic workflows, and have started to power numerous Google products\nalready (Pichai, 2025).\nIn addition to being highly performant, the Gemini 2.5 models maintain strong safety standards\nand, compared to their 1.5 counterparts, are much more helpful. They are less likely to refuse to\nanswer important user queries or respond with an overly sanctimonious tone. Gemini 2.5 exhibited\nnotableincreasesinCriticalCapabilities,includingcybersecurityandmachinelearningR&D.However,\nthe model has not crossed any Critical Capability Levels.\nReflecting on the path to Gemini 2.5, the staggering performance improvement attained over the\nspaceofjustoneyearpointstoanewchallengeinAIresearch: namelythatthedevelopmentofnovel\nand sufficiently challenging evaluation benchmarks has struggled to keep pace with model capability\nimprovements, especially with the advent of capable reasoning agents. Over the space of just a year,\nGemini Pro’s performance has gone up 5x on Aider Polyglot and 2x on SWE-bench verified (one of\nthe most popular and challenging agentic benchmarks). Not only are benchmarks saturating quickly,\nbut every new benchmark that gets created can end up being more expensive and take longer to\ncreate than its predecessor, due to the more restricted pool of experts able to create it. Experts were\npaidupto$5000foreachquestionthatwasacceptedtotheHumanity’sLastExambenchmark(Phan\net al., 2025), and while this benchmark still has significant headroom at the time of writing (June\n2025), performance on it has improved significantly over the space of a few months (with the best\nmodels achieving just a few percent accuracy on it when it was initially published in early 2025).\nWhen one considers agentic systems, which are able to tackle problems for longer and which have\naccess to tools and self critique, the complexity of benchmarks required to measure performance\nalso increases dramatically. Being able to scale evaluations in both their capability coverage and their\ndifficulty, while also representing tasks that have economic value, will be the key to unlocking the\nnext generation of AI systems.\n39"
    },
    {
      "page": 40,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nReferences\nR. Anil, G. Pereyra, A. Passos, R. Ormandi, G. E. Dahl, and G. E. Hinton. Large scale distributed\nneural network training through online distillation, 2018. URL https://arxiv.org/abs/1804\n.03235.\nR. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, et al. PaLM 2 technical report, 2023. URL\nhttps://arxiv.org/abs/2305.10403.\nAnthropic. Claude’s extended thinking, 2025. URL https://www.anthropic.com/research/v\nisible-extended-thinking.\nA.Baddepudi,A.Yang,andM.Lučić. AdvancingthefrontierofvideounderstandingwithGemini2.5,\n2025. URL https://developers.googleblog.com/en/gemini-2-5-video-understan\nding/.\nY. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, et al. Constitutional ai: Harmlessness from ai\nfeedback, 2022. URL https://arxiv.org/abs/2212.08073.\nM. Balunović, J. Dekoninck, I. Petrov, N. Jovanović, and M. Vechev. Matharena: Evaluating llms on\nuncontaminated math competitions, 2025. URL https://arxiv.org/abs/2505.23281.\nP. Barham, A. Chowdhery, J. Dean, S. Ghemawat, S. Hand, D. Hurt, M. Isard, H. Lim, R. Pang, S. Roy,\net al. Pathways: Asynchronous distributed dataflow for ml. Proceedings of Machine Learning and\nSystems,4:430–449,2022. URLhttps://proceedings.mlr.press/v162/barham22a.html.\nA. Beutel, K. Xiao, J. Heidecke, and L. Weng. Diverse and effective red teaming with auto-generated\nrewards and multi-step reinforcement learning, 2024. URL https://arxiv.org/abs/2412.1\n8693.\nS. Biderman, H. Schoelkopf, Q. G. Anthony, H. Bradley, K. O’Brien, et al. Pythia: A suite for analyzing\nlargelanguagemodelsacrosstrainingandscaling.InProceedingsofthe40thInternationalConference\non Machine Learning, 2023. URL https://proceedings.mlr.press/v202/biderman23a.h\ntml.\nN.Carlini,D.Ippolito,M.Jagielski,K.Lee,F.Tramer,andC.Zhang. Quantifyingmemorizationacross\nneural language models. In 2022 IEEE Symposium on Security and Privacy (SP), pages 1113–1130,\n2022. URL https://arxiv.org/abs/2202.07646.\nW.-L. Chiang, L. Zheng, Y. Sheng, A. N. Angelopoulos, T. Li, D. Li, B. Zhu, H. Zhang, M. Jordan, J. E.\nGonzalez, et al. Chatbot arena: An open platform for evaluating llms by human preference. In\nForty-first International Conference on Machine Learning, 2024. URL https://arxiv.org/abs/\n2306.05685.\nA. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung,\nC. Sutton, S. Gehrmann, et al. PaLM: Scaling language modeling with pathways. arXiv preprint\narXiv:2204.02311, 2022. URL https://arxiv.org/abs/2204.02311.\nN. Chowdhury, J. Aung, C. J. Shern, O. Jaffe, D. Sherburn, G. Starace, E. Mays, R. Dias, M. Aljubeh,\nM. Glaese, C. E. Jimenez, J. Yang, L. Ho, T. Patwardhan, K. Liu, and A. Madry. Introducing SWE-\nbench verified, 2024. URL https://openai.com/index/introducing-swe-bench-verif\nied/.\n40"
    },
    {
      "page": 41,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nA. Clark, D. de las Casas, A. Guy, A. Mensch, M. Paganini, J. Hoffmann, B. Damoc, B. Hechtman,\nT. Cai, S. Borgeaud, G. van den Driessche, E. Rutherford, T. Hennigan, M. Johnson, K. Millican,\nA. Cassirer, C. Jones, E. Buchatskaya, D. Budden, L. Sifre, S. Osindero, O. Vinyals, J. Rae, E. Elsen,\nK. Kavukcuoglu, and K. Simonyan. Unified scaling laws for routed language models, 2022. URL\n\"https://arxiv.org/abs/2202.01169\".\nCodeGemma Team, H. Zhao, J. Hui, J. Howland, N. Nguyen, S. Zuo, A. Hu, C. A. Choquette-Choo,\nJ. Shen, J. Kelley, K. Bansal, L. Vilnis, M. Wirth, P. Michel, P. Choy, P. Joshi, R. Kumar, S. Hashmi,\nS. Agrawal, Z. Gong, J. Fine, T. Warkentin, A. J. Hartman, B. Ni, K. Korevec, K. Schaefer, and\nS. Huffman. CodeGemma: Open Code Models Based on Gemma, 2024. URL https://arxiv.or\ng/abs/2406.11409.\nA. Conneau, M. Ma, S. Khanuja, Y. Zhang, V. Axelrod, S. Dalmia, J. Riesa, C. Rivera, and A. Bapna.\nFleurs: Few-shot learning evaluation of universal representations of speech. In 2022 IEEE Spoken\nLanguage Technology Workshop (SLT), pages 798–805. IEEE, 2023.\nM. Dehghani, J. Djolonga, B. Mustafa, P. Padlewski, J. Heek, J. Gilmer, A. P. Steiner, M. Caron,\nR. Geirhos, I. Alabdulmohsin, et al. Scaling vision transformers to 22 billion parameters. In\nInternational Conference on Machine Learning, pages 7480–7512. PMLR, 2023. URL https:\n//proceedings.mlr.press/v202/dehghani23a/dehghani23a.pdf.\nT. Doshi. Build rich, interactive web apps with an updated Gemini 2.5 Pro, 2025a. URL https:\n//blog.google/products/gemini/gemini-2-5-pro-updates/.\nT. Doshi. Gemini 2.5: Our most intelligent models are getting even better, 2025b. URL https:\n//blog.google/technology/google-deepmind/google-gemini-updates-io-2025/.\nN. Du, Y. Huang, A. M. Dai, S. Tong, D. Lepikhin, Y. Xu, M. Krikun, Y. Zhou, A. W. Yu, O. Fi-\nrat, et al. GLaM: Efficient scaling of language models with mixture-of-experts. arXiv preprint\narXiv:2112.06905, 2021. URL https://arxiv.org/abs/2112.06905.\nW. Fedus, B. Zoph, and N. Shazeer. Switch transformers: Scaling to trillion parameter models with\nsimple and efficient sparsity. arXiv preprint arXiv:2101.03961, 2021. URL https://arxiv.org/\nabs/2101.03961.\nC. Fu, Y. Dai, Y. Luo, L. Li, S. Ren, R. Zhang, Z. Wang, C. Zhou, Y. Shen, M. Zhang, et al. Video-mme:\nThe first-ever comprehensive evaluation benchmark of multi-modal llms in video analysis. In\nProceedings of the Computer Vision and Pattern Recognition Conference, pages 24108–24118, 2025.\nURL https://openaccess.thecvf.com/content/CVPR2024/html/Fu_Video-MME_The\n_First-Ever_Comprehensive_Evaluation_Benchmark_of_Multi-Modal_LLMs_in_C\nVPR_2024_paper.html.\nP. Gauthier. Aider Polyglot Coding Leaderboard, 2025. URL https://aider.chat/docs/leader\nboards/.\nGemini Team. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.\narXiv preprint arXiv:2403.05530, 2024. URL https://arxiv.org/abs/2403.05530.\nGemini Team, Google. Gemini Deep Research, 2024. URL https://gemini.google/overview\n/deep-research/.\nGemma Team. Gemma: Open Models Based on Gemini Research and Technology, 2024. URL\nhttps://arxiv.org/abs/2403.08295.\n41"
    },
    {
      "page": 42,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nO. Goldman, U. Shaham, D. Malkin, S. Eiger, A. Hassidim, Y. Matias, J. Maynez, A. M. Gilady, J. Riesa,\nS. Rijhwani, L. Rimell, I. Szpektor, R. Tsarfaty, and M. Eyal. Eclektic: a novel challenge set for\nevaluation of cross-lingual knowledge transfer, 2025. URL https://arxiv.org/abs/2502.2\n1228.\nGoogle DeepMind. Frontier safety framework, February 2025a. URL https://deepmind.googl\ne/discover/governance/frontier-safety-framework/.\nGoogle DeepMind. Gemini 2.0 Flash-Lite, 2025b. URL https://deepmind.google/models/gem\nini/flash-lite/.\nA. Grattafiori, A. Dubey, A. Jauhri, A. Pandey, A. Kadian, et al. The Llama 3 Herd of Models, 2024.\nURL https://arxiv.org/abs/2407.21783.\nD. Hassabis. Our vision for building a universal AI assistant, 2025. URL https://blog.google/\ntechnology/google-deepmind/gemini-universal-ai-assistant/.\nG. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network, 2015. URL\nhttps://arxiv.org/abs/1503.02531.\nK.Hu,P.Wu,F.Pu,W.Xiao,Y.Zhang,X.Yue,B.Li,andZ.Liu. Video-mmmu: Evaluatingknowledge\nacquisition from multi-discipline professional videos, 2025. URL https://arxiv.org/abs/25\n01.13826.\nS.Hughes,M.Bae,andM.Li. VectaraHallucinationLeaderboard,nov2023. URLhttps://github\n.com/vectara/hallucination-leaderboard.\nD. Ippolito, F. Tramer, M. Nasr, C. Zhang, M. Jagielski, K. Lee, C. A. Choquette-Choo, and N. Carlini.\nPreventing verbatim memorization in language models gives a false sense of privacy, 2022. URL\nhttps://arxiv.org/abs/2210.17546.\nA. Jacovi, A. Wang, C. Alberti, C. Tao, J. Lipovetz, K. Olszewska, L. Haas, M. Liu, N. Keating,\nA.Bloniarz,C.Saroufim,C.Fry,D.Marcus,D.Kukliansky,G.S.Tomar,J.Swirhun,J.Xing,L.Wang,\nM. Gurumurthy, M. Aaron, M. Ambar, R. Fellinger, R. Wang, R. Sims, Z. Zhang, S. Goldshtein, and\nD. Das. Facts grounding leaderboard. https://www.kaggle.com/benchmarks/google/fac\nts-grounding, 2024. Google Deepmind, Google Research, Google Cloud, Kaggle.\nA.Jacovi,A.Wang,C.Alberti,C.Tao,J.Lipovetz,K.Olszewska,L.Haas,M.Liu,N.Keating,A.Bloniarz,\netal. Thefactsgroundingleaderboard: Benchmarkingllms’abilitytogroundresponsestolong-form\ninput. arXiv preprint arXiv:2501.03200, 2025. URL https://arxiv.org/abs/2501.03200.\nN. Jain, K. Han, A. Gu, W.-D. Li, F. Yan, T. Zhang, S. Wang, A. Solar-Lezama, K. Sen, and I. Stoica.\nLivecodebench: Holistic and contamination free evaluation of large language models for code,\n2024. URL https://arxiv.org/abs/2403.07974.\nA. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary, C. Bamford, D. S. Chaplot, D. d. l. Casas,\nE. B. Hanna, F. Bressand, et al. Mixtral of experts. arXiv preprint arXiv:2401.04088, 2024. URL\nhttps://arxiv.org/abs/2401.04088.\nC. E. Jimenez, J. Yang, A. Wettig, S. Yao, K. Pei, O. Press, and K. R. Narasimhan. SWE-bench: Can\nlanguage models resolve real-world github issues? In The Twelfth International Conference on\nLearning Representations, 2024. URL https://openreview.net/forum?id=VTF8yNQM66.\n42"
    },
    {
      "page": 43,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nK. Kampf and N. Brichtova. Experiment with Gemini 2.0 Flash native image generation, 2025. URL\nhttps://developers.googleblog.com/en/experiment-with-gemini-20-flash-nat\nive-image-generation/.\nK. Kavukcuoglu. Gemini 2.0 is now available to everyone, 2025. URL https://blog.google/te\nchnology/google-deepmind/gemini-model-updates-february-2025.\nL. Kilpatrick. Gemini 2.5 Pro Preview: even better coding performance, 2025. URL https://deve\nlopers.googleblog.com/en/gemini-2-5-pro-io-improved-coding-performance.\nS. Kudugunta, I. Caswell, B. Zhang, X. Garcia, C. A. Choquette-Choo, K. Lee, D. Xin, A. Kusupati,\nR.Stella,A.Bapna,andO.Firat. MADLAD-400: AMultilingualAndDocument-LevelLargeAudited\nDataset, 2023. URL https://arxiv.org/abs/2309.04662.\nJ. M. Laurent, J. D. Janizek, M. Ruzo, M. M. Hinks, M. J. Hammerling, S. Narayanan, et al. LAB-\nBench: Measuring capabilities of language models for biology research, 2024. URL https:\n//arxiv.org/abs/2407.10362.\nLearnLM Team. Evaluating Gemini in an Arena for Learning, 2025. URL https://goo.gle/Lear\nnLM-May25.\nJ. Lee, A. Chen, Z. Dai, D. Dua, D. S. Sachan, M. Boratko, Y. Luan, S. M. Arnold, V. Perot, S. Dalmia,\net al. Can long-context language models subsume retrieval, rag, sql, and more? arXiv preprint\narXiv:2406.13121, 2024. URL https://arxiv.org/abs/2406.13121.\nJ. Lei, T. L. Berg, and M. Bansal. Detecting moments and highlights in videos via natural language\nqueries. Advances in Neural Information Processing Systems, 34:11846–11858, 2021.\nD. Lepikhin, H. Lee, Y. Xu, D. Chen, O. Firat, Y. Huang, M. Krikun, N. Shazeer, and Z. Chen. GShard:\nScaling giant models with conditional computation and automatic sharding. In International\nConference on Learning Representations, 2020. URL https://openreview.net/forum?id=qr\nwe7XHTmYb.\nN. Li, A. Pan, A. Gopal, S. Yue, D. Berrios, A. Gatti, et al. The WMDP benchmark: Measuring and\nreducing malicious use with unlearning, 2024. URL https://arxiv.org/abs/2403.03218.\nL. Liu, X. Liu, J. Gao, W. Chen, and J. Han. Understanding the difficulty of training transformers.\narXiv preprint arXiv:2004.08249, 2020. URL https://arxiv.org/abs/2004.08249.\nLMArena Team. Webdev arena, 2025. URL https://web.lmarena.ai/leaderboard.\nS. B. Mallick and L. Kilpatrick. Gemini 2.0: Flash, Flash-Lite and Pro, 2025. URL https://develo\npers.googleblog.com/en/gemini-2-family-expands/.\nA. Mehrotra, M. Zampetakis, P. Kassianik, B. Nelson, H. Anderson, Y. Singer, and A. Karbasi. Tree of\nattacks: Jailbreaking black-box llms automatically, 2024. URL https://arxiv.org/abs/2312\n.02119.\nI.Molybog,P.Albert,M.Chen,Z.DeVito,D.Esiobu,N.Goyal,P.Koura,S.Narang,A.Poulton,R.Silva,\netal. Atheoryonadaminstabilityinlarge-scalemachinelearning. arXivpreprintarXiv:2304.09871,\n2023. URL https://arxiv.org/abs/2304.09871.\nA.Nagrani,S.Menon,A.Iscen,S.Buch,R.Mehran,N.Jha,A.Hauth,Y.Zhu,C.Vondrick,M.Sirotenko,\nC. Schmid, and T. Weyand. Minerva: Evaluating complex video reasoning, 2025a. URL https:\n//arxiv.org/abs/2505.00681.\n43"
    },
    {
      "page": 44,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nA.Nagrani,M.Zhang,R.Mehran,R.Hornung,N.B.Gundavarapu,N.Jha,A.Myers,X.Zhou,B.Gong,\nC. Schmid, M. Sirotenko, Y. Zhu, and T. Weyand. Neptune: The long orbit to benchmarking long\nvideo understanding, 2025b. URL https://arxiv.org/abs/2412.09582.\nM.Nasr,N.Carlini,J.Hayase,M.Jagielski,A.F.Cooper,D.Ippolito,C.A.Choquette-Choo,E.Wallace,\nF. Tramèr, and K. Lee. Scalable extraction of training data from (production) language models,\n2023. URL https://arxiv.org/abs/2311.17035.\nP. Padlewski, M. Bain, M. Henderson, Z. Zhu, N. Relan, H. Pham, D. Ong, K. Aleksiev, A. Ormazabal,\nS.Phua,E.Yeo,E.Lamprecht,Q.Liu,Y.Wang,E.Chen,D.Fu,L.Li,C.Zheng,C.deMassond’Autume,\nD. Yogatama, M. Artetxe, and Y. Tay. Vibe-eval: A hard evaluation suite for measuring progress of\nmultimodal language models, 2024. URL https://arxiv.org/abs/2405.02287.\nA.Pappu,B.Porter,I.Shumailov,andJ.Hayes. MeasuringmemorizationinRLHFforcodecompletion.\narXiv preprint arXiv:2406.11715, 2024. URL https://arxiv.org/abs/2406.11715.\nV.Patraucean,L.Smaira,A.Gupta,A.Recasens,L.Markeeva,D.Banarse,S.Koppula,M.Malinowski,\nY. Yang, C. Doersch, et al. Perception test: A diagnostic benchmark for multimodal video models.\nAdvances in Neural Information Processing Systems, 36:42748–42761, 2023.\nE. Perez, S. Huang, F. Song, T. Cai, R. Ring, J. Aslanides, A. Glaese, N. McAleese, and G. Irving. Red\nteaminglanguagemodelswithlanguagemodels,2022. URLhttps://arxiv.org/abs/2202.0\n3286.\nL. Phan et al. Humanity’s last exam, 2025. URL https://arxiv.org/abs/2501.14249.\nM.Phuong,M.Aitchison,E.Catt,S.Cogan,A.Kaskasoli,V.Krakovna,D.Lindner,M.Rahtz,Y.Assael,\nS. Hodkinson, et al. Evaluating frontier models for dangerous capabilities, 2024. URL https:\n//arxiv.org/abs/2403.13793.\nM. Phuong, R. S. Zimmermann, Z. Wang, D. Lindner, V. Krakovna, S. Cogan, A. Dafoe, L. Ho, and\nR. Shah. Evaluating frontier models for stealth and situational awareness, 2025. URL https:\n//arxiv.org/abs/2505.01420.\nS. Pichai. Google I/O 2025: From research to reality, 2025. URL https://blog.google/techno\nlogy/ai/io-2025-keynote/.\nC. Plizzari, A. Tonioni, Y. Xian, A. Kulshrestha, and F. Tombari. Omnia de egotempo: Benchmarking\ntemporal understanding of multi-modal llms in egocentric videos. In Proceedings of the Computer\nVision and Pattern Recognition Conference, pages 24129–24138, 2025.\nD.Rein,B.L.Hou,A.C.Stickland,J.Petty,R.Y.Pang,J.Dirani,J.Michael,andS.R.Bowman. Gqqa:\nA graduate-level google-proof q&a benchmark. In First Conference on Language Modeling, 2024.\nC. Riquelme, J. Puigcerver, B. Mustafa, M. Neumann, R. Jenatton, A. S. Pinto, D. Keysers, and\nN.Houlsby. Scalingvisionwithsparsemixtureofexperts,2021. URLhttps://arxiv.org/abs/\n2106.05974.\nJ.Roberts, M.R. Taesiri, A.Sharma, A.Gupta, S.Roberts, I. Croitoru, S.-V.Bogolin, J. Tang, F.Langer,\nV. Raina, et al. ZeroBench: An impossible visual benchmark for contemporary large multimodal\nmodels. arXiv preprint arXiv:2502.09696, 2025.\nM. Rodriguez, R. A. Popa, L. Liang, A. Wang, M. Rahtz, A. Kaskasoli, A. Dafoe, and F. Flynn. A\nframework for evaluating emerging cyberattack capabilities of AI, 2025. URL https://arxiv.\norg/abs/2503.11917.\n44"
    },
    {
      "page": 45,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nS. Roller, S. Sukhbaatar, J. Weston, et al. Hash layers for large sparse models. Advances in Neural\nInformation Processing Systems, 34:17555–17566, 2021. URL https://proceedings.neurips.\ncc/paper/2021/file/883e881bc596359e0c5112411858a74b-Paper.pdf.\nM. Samvelyan, S. C. Raparthy, A. Lupu, E. Hambro, A. H. Markosyan, M. Bhatt, Y. Mao, M. Jiang,\nJ. Parker-Holder, J. Foerster, T. Rocktäschel, and R. Raileanu. Rainbow teaming: Open-ended\ngeneration of diverse adversarial prompts, 2024. URL https://arxiv.org/abs/2402.16822.\nR. Shah, A. Irpan, A. M. Turner, A. Wang, A. Conmy, D. Lindner, J. Brown-Cohen, L. Ho, N. Nanda,\nR. A. Popa, R. Jain, R. Greig, S. Albanie, S. Emmons, S. Farquhar, S. Krier, S. Rajamanoharan,\nS. Bridgers, T. Ijitoye, T. Everitt, V. Krakovna, V. Varma, V. Mikulik, Z. Kenton, D. Orr, S. Legg,\nN. Goodman, A. Dafoe, F. Flynn, and A. Dragan. An approach to technical agi safety and security,\n2025. URL https://arxiv.org/abs/2504.01849.\nD.Sharon. UploadandedityourimagesdirectlyintheGeminiapp,2025. URLhttps://blog.goo\ngle/products/gemini/image-editing/.\nN. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, and J. Dean. Outrageously large\nneural networks: The sparsely-gated mixture-of-experts layer. In ICLR (Poster). OpenReview.net,\n2017. URL https://arxiv.org/abs/1701.06538.\nC. Shi, S. Lin, S. Song, J. Hayes, I. Shumailov, I. Yona, J. Pluto, A. Pappu, C. A. Choquette-Choo,\nM. Nasr, C. Sitawarin, G. Gibson, A. Terzis, and J. F. Flynn. Lessons from defending gemini against\nindirect prompt injections, 2025. URL https://arxiv.org/abs/2505.14534.\nS. Singh, A. Romanou, C. Fourrier, D. I. Adelani, J. G. Ngui, D. Vila-Suero, P. Limkonchotiwat,\nK. Marchisio, W. Q. Leong, Y. Susanto, R. Ng, S. Longpre, W.-Y. Ko, M. Smith, A. Bosselut, A. Oh,\nA. F. T. Martins, L. Choshen, D. Ippolito, E. Ferrante, M. Fadaee, B. Ermis, and S. Hooker. Global\nmmlu: Understanding and addressing cultural and linguistic biases in multilingual evaluation,\n2024. URL https://arxiv.org/abs/2412.03304.\nR. Stein. Expanding AI Overviews and introducing AI Mode, 2025. URL https://blog.google/\nproducts/search/ai-mode-search.\nI.Tolstikhin,N.Houlsby,A.Kolesnikov,L.Beyer,X.Zhai,T.Unterthiner,J.Yung,A.Steiner,D.Keysers,\nJ. Uszkoreit, M. Lucic, and A. Dosovitskiy. Mlp-mixer: An all-mlp architecture for vision, 2021.\nA. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and I. Polosukhin.\nAttention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vish-\nwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30.\nCurran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper_files/pap\ner/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.\nK. Vodrahalli, S. Ontanon, N. Tripuraneni, K. Xu, S. Jain, R. Shivanna, J. Hui, N. Dikkala, M. Kazemi,\nB. Fatemi, et al. Michelangelo: Long context evaluations beyond haystacks via latent structure\nqueries. arXiv preprint arXiv:2409.12640, 2024. URL https://arxiv.org/abs/2409.12640.\nB. Wang. NotebookLM now lets you listen to a conversation about your sources , 2024. URL\nhttps://blog.google/technology/ai/notebooklm-audio-overviews.\nC. Wang, A. Wu, and J. Pino. Covost 2: A massively multilingual speech-to-text translation corpus,\n2020.\n45"
    },
    {
      "page": 46,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nW. Wang, Z. He, W. Hong, Y. Cheng, X. Zhang, J. Qi, X. Gu, S. Huang, B. Xu, Y. Dong, M. Ding,\nand J. Tang. Lvbench: An extreme long video understanding benchmark, 2024. URL https:\n//arxiv.org/abs/2406.08035.\nX. Wang, J. Wu, J. Chen, L. Li, Y.-F. Wang, and W. Y. Wang. Vatex: A large-scale, high-quality\nmultilingual dataset for video-and-language research. In Proceedings of the IEEE/CVF international\nconference on computer vision, pages 4581–4591, 2019.\nJ.Wei,K.Nguyen,H.W.Chung,Y.J.Jiao,S.Papay,A.Glaese,J.Schulman,andW.Fedus. Measuring\nshort-form factuality in large language models. arXiv preprint arXiv:2411.04368, 2024. URL\nhttps://arxiv.org/abs/2411.04368.\nL. Weidinger, J. Barnhart, J. Brennan, C. Butterfield, S. Young, W. Hawkins, et al. Holistic safety and\nresponsibilityevaluationsofadvancedaimodels,2024. URLhttps://arxiv.org/abs/2404.1\n4068.\nH. Wijk, T. Lin, J. Becker, S. Jawhar, N. Parikh, T. Broadley, L. Chan, M. Chen, J. Clymer, J. Dhyani,\net al. RE-Bench: Evaluating frontier ai r&d capabilities of language model agents against human\nexperts, 2025. URL https://arxiv.org/abs/2411.15114.\nM. Wortsman, P. J. Liu, L. Xiao, K. Everett, A. Alemi, B. Adlam, J. D. Co-Reyes, I. Gur, A. Kumar,\nR. Novak, et al. Small-scale proxies for large-scale transformer training instabilities. arXiv preprint\narXiv:2309.14322, 2023. URL https://arxiv.org/abs/2309.14322.\nJ. Yang, A. Prabhakar, K. Narasimhan, and S. Yao. Intercode: Standardizing and benchmarking\ninteractivecodingwithexecutionfeedback,2023. URLhttps://arxiv.org/abs/2306.14898.\nZ.Yu,D.Xu,J.Yu,T.Yu,Z.Zhao,Y.Zhuang,andD.Tao. ActivityNet-QA:Adatasetforunderstanding\ncomplex web videos via question answering. In AAAI, 2019.\nX. Yue, Y. Ni, K. Zhang, T. Zheng, R. Liu, G. Zhang, S. Stevens, D. Jiang, W. Ren, Y. Sun, et al.\nMmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert\nagi. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages\n9556–9567, 2024.\nZerokid. Pokemon Red Version - Guide and Walkthrough (GB), 2024. URL https://gamefaqs.g\namespot.com/gameboy/367023-Pokémon-red-version/faqs/64175.\nS.Zhai,T.Likhomanenko,E.Littwin,D.Busbridge,J.Ramapuram,Y.Zhang,J.Gu,andJ.M.Susskind.\nStabilizingtransformertrainingbypreventingattentionentropycollapse.InInternationalConference\non Machine Learning, pages 40770–40803. PMLR, 2023. URL https://proceedings.mlr.pr\ness/v202/zhai23a/zhai23a.pdf.\nJ. Zhang. Gemini Plays Pokemon Twitch Stream, 2025. URL https://www.twitch.tv/gemini\n_plays_pokemon/about.\nS. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin, et al.\nOpt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068, 2022. URL\nhttps://arxiv.org/abs/2205.01068.\nL. Zhou, C. Xu, and J. J. Corso. Towards automatic learning of procedures from web instructional\nvideos. In AAAI Conference on Artificial Intelligence, pages 7590–7598, 2018. URL https://www.\naaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17344.\n46"
    },
    {
      "page": 47,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n7. Contributors and Acknowledgments\nContributors KristenChiafullo KashyapKolipaka DavidParkinson\nGheorgheComanici AndreElisseeff JasonChang SwaroopRamaswamy\nEricBieber NilpaJha EugenVušak JeromeConnor\nMikeSchaekermann PrateekKolhar SrinivasanVenkatachary SoheilHassasYeganeh\nIcePasupat LeonardBerrada ShadiNoghabi SnchitGrover\nNoveenSachdeva FrankDing TarunBharti GeorgeKenwright\nInderjitDhillon XianceSi YounghoonJun LuboLitchev\nMarcelBlistein ShresthaBasuMallick AleksandrZaks ChrisApps\nOriRam FranzOch SimonGreen AlexTomala\nDanZhang SofiaErell JeshwanthChallagundla FelixHalim\nEvanRosen EricNi WilliamWong AlexCastro-Ros\nLukeMarris TejasiLatkar MuqtharMohammad ZefeiLi\nSamPetulla SherryYang DeanHirsch AnudhyanBoral\nColinGaffney PetarSirkovic YongCheng PaulineSho\nAsafAharoni ZiqiangFeng IftekharNaim MichalYarom\nNathanLintz RobertLeland LevProleev EricMalmi\nTiagoCardalPais RachelHornung DamienVincent DavidKlinghoffer\nHenrikJacobsson GangWu AayushSingh RebeccaLin\nIdanSzpektor CharlesBlundell MaximKrikun AlanAnsell\nNan-JiangJiang HamidrezaAlvari DilipKrishnan PradeepKumarS\nKrishnaHaridasan Po-SenHuang ZoubinGhahramani ShubinZhao\nAhmedOmran CathyYip AvielAtias SiqiZuo\nNikunjSaunshi SanjaDeur RajeevAggarwal AdamSantoro\nDaraBahri LiLiu ChristoKirov Heng-TzeCheng\nGauravMishra GabrielaSurita DimitriosVytiniotis SolomonDemmessie\nEricChu PabloDuque ChristyKoh YuchiLiu\nTobyBoyd DimaDamen AlexandraChronopoulou NicoleBrichtova\nBradHekman JohnsonJia PawanDogra AllieCulp\nAaronParisi ArthurGuez Vlad-DoruIon NathanielBraun\nChaoyiZhang MarkusMircea GladysTyen DanGraur\nKornraphopKawintiranon AnimeshSinha JasonLee WillNg\nTaniaBedrax-Weiss AlbertoMagni FelixWeissenberger NikhilMehta\nOliverWang PawełStradomski TrevorStrohman AaronPhillips\nYaXu TalMarian AshwinBalakrishna PatrikSundberg\nOlliePurkiss VladoGalić JackRae VarunGodbole\nUriMendlovic WenhuChen MarkoVelic FangyuLiu\nIlaïDeutel HishamHusain RaouldeLiedekerke YashKatariya\nNamNguyen AchintyaSinghal OdedElyada DavidRim\nAdamLangley DominikGrewe WentaoYuan MojtabaSeyedhosseini\nFlipKorn François-XavierAubet CanoeeLiu SeanAmmirati\nLuciaRossazza ShuangSong LiorShani JonasValfridsson\nAlexandreRamé LorenzoBlanco SergeyKishchenko MahanMalihi\nSagarWaghmare LelandRechis BeaAlessio TimothyKnight\nHelenMiller LewisHo YandongLi AndeepToor\nNathanByrd RichMunoz RichardSong ThomasLampe\nAshrithSheshan KelvinZheng SamKwei AbeIttycheriah\nRaiaHadsell JessicaHamrick OrionJankowski LewisChiang\nSangnieBhardwaj KevinMather AneeshPappu ChakYeung\nPawelJanus HagaiTaitelbaum YouheiNamiki AlexandreFréchette\nTeroRissa ElizaRutherford YenaiMa JinmengRao\nDanHorgan YunLei NileshTripuraneni HuishengWang\nAlvinAbdagic KuangyuanChen ColinCherry HimanshuSrivastava\nLiorBelenki AnandShukla MarissaIkonomidis RichardZhang\nJamesAllingham EricaMoreira Yu-ChengLing RockyRhodes\nAnimaSingh EricDoi ColinJi ArielBrand\nTheoGuidroz BerivanIsik BekaWestberg DeanWeesner\nSrivatsanSrinivasan NirShabat AurielWright IlyaFigotin\nHermanSchmit DominikaRogozińska DaYu FelixGimeno\n47"
    },
    {
      "page": 48,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nRachanaFellinger ArunNair JaumeSanchezElias XinyangGeng\nPierreMarcenac ArtemShtefan AbhirutGupta YeqingLi\nJoséLeal MauraO’Brien ManishReddyVuyyuru RolfJagerman\nEyalMarcus ManuAgarwal FredAlcober ChaoJia\nVictorCotruta SahityaPotluri TongZhou NadavOlmert\nRodrigoCabrera SiddharthGoyal KaiyangJi DavidSharon\nSherylLuo AmitJhindal FlorianHartmann MatthewMauger\nDanGarrette SakshamThakur SubhaPuttagunta SandeepMariserla\nVeraAxelrod YuryStuken HugoSong HongxuMa\nSorinBaltateanu JamesLyon EhsanAmid MeghaMohabey\nDavidBarker KristinaToutanova AncaStefanoiu KyuyeunKim\nDongkaiChen FangxiaoyuFeng AndrewLee AlekAndreev\nHoriaToma AustinWu PaulPucciarelli ScottPollom\nBenIngram BenHorn EmmaWang JulietteLove\nJasonRiesa AlekWang AmitRaul VihanJain\nChinmayKulkarni AlexCullum SlavPetrov PriyankaAgrawal\nYujingZhang GabeTaubman IsaacTian YannickSchroecker\nHongbinLiu DishaShrivastava ValentinAnklin AlisaFortin\nChaoWang ChongyangShi NanaNti ManfredWarmuth\nMartinPolacek HamishTomlinson VictorGomes JiLiu\nWillWu RomaPatel MaxSchumacher AndrewLeach\nKaiHui TaoTu GraceVesom IrinaBlok\nAdrianNReyes AdaMaksutajOflazer AlexPanagopoulos GaneshPoomalGirirajan\nYiSu FrancescoPongetti KonstantinosBousmalis RoeeAharoni\nMeganBarnes MingyaoYang DanielAndor BenignoUria\nIshaanMalhi AdrienAliTaïga JoshJacob AndreiSozanschi\nAnfalSiddiqui VincentPerot YuanZhang DanGoldberg\nQixuanFeng NuoWangPierse BillRosgen LucianIonita\nMihaiDamaschin FengHan MatijaKecman MarcoTulioRibeiro\nDanielePighin YoelDrori MatthewTung MartinZlocha\nAndreasSteiner IñakiIturrate AlexandraBelias VighneshBirodkar\nSamuelYang AyanChakrabarti NoahGoodman SamiLachgar\nRamyaSreeBoppana LeggYeung PaulCovington LiangzheYuan\nSimeonIvanov DaveDopson BrianWieder HimadriChoudhury\nArunKandoor Yi-tingChen NikitaSaxena MattGinsberg\nAdityaShah ApoorvKulshreshtha ElnazDavoodi FeiZheng\nAsierMujika TongfeiGuo MuhuanHuang GregoryDibb\nDaHuang PhilipPham SharathMaddineni EmilyGraves\nChristopherA. TalSchuster VincentRoulet SwachhandLokhande\nChoquette-Choo JunquanChen FolawiyoCampbell-Ajala GabrielRasskin\nMohakPatel AlexPolozov PierGiuseppeSessa George-CristianMuraru\nTianheYu JinweiXing Xintian(Cindy)Wu CorbinQuick\nToniCreswell HuanjieZhou GuangdaLai SandeepTata\nJerry(Chun-Ting)Liu PraneethKacham PaulCollins PierreSermanet\nCatarinaBarros DoronKukliansky AlexHaig AdityaChawla\nYasamanRazeghi AntoineMiech VytenisSakenas ItayKaro\nAurkoRoy SergeyYaroshenko XiaoweiXu YanWang\nPhilCulliton EdChi MarissaGiustina SusanZhang\nBinbinXiong SholtoDouglas LaurentElShafey OrgadKeller\nJiaqiPan HongliangFei PichiCharoenpanit AncaDragan\nThomasStrohmann MathieuBlondel ShefaliGarg GuolongSu\nTollyPowell PreethiMyla JoshuaAinslie IanChou\nBabiSeal LiorMadmoni BooneSeverson XiLiu\nDougDeCarlo XingWu MontseGonzalezArenas YiqingTao\nPranavShyam DanielKeysers ShreyaPathak ShruthiPrabhakara\nKaanKatircioglu KristianKjems SujeeRajayogam MarcWilson\nXuezhiWang IsabelaAlbuquerque JieFeng RuiboLiu\nCassidyHardin LijunYu MichielBakker ShiboWang\nImmanuelOdisho JoelD’sa ShengLi GeorgieEvans\nJosefBroder MichellePlantan NevanWichers DavidDu\nOscarChang VladIonescu JamieRogers AlfonsoCastaño\n48"
    },
    {
      "page": 49,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGautamPrasad XuanYang ChiyuanZhang ShuangLiu\nMonaElMahdy DaleWebster SanderDieleman SaarthakKhanna\nSebastianGerlach AliElqursh ThomasJimma AdityaPandey\nMachelReid AedanPope AndreyRyabtsev SiobhanMcloughlin\nJarrodKahn GeorgesRotival SiddharthaBrahma QiujiaLi\nAmirZait DavidRaposo DavidSteiner SamHaves\nThanumalayan WanzhengZhu DayouDu AllanZhou\nSankaranarayanaPillai JeffDean AnteŽužul ElenaBuchatskaya\nThatcherUlrich SamiAlabed MislavŽanić IsabelLeal\nGuanyuWang DustinTran MukundRaghavachari PeterdeBoursac\nJanWassenberg ArushiGupta WilliGierke NamiAkazawa\nEfratFarkash ZachGleicher ZeyuZheng NinaAnderson\nKiranYalasangi JessicaAustin DessiePetrova TerryChen\nCongchaoWang EdouardRosseel YannDauphin KrishnaSomandepalli\nMariaBauza MeghUmekar YuchuanLiu ChenLiang\nSimonBucher DipanjanDas IdoKessler SheelaGoenka\nTingLiu YinghaoSun StevenHand StephanieWinkler\nJunYan KaiChen ChrisDuvarney AlexanderGrushetsky\nGaryLeung KarolisMisiunas SeokhwanKim YifanDing\nVikasSindhwani XiangZhou HyoLee JamieSmith\nParkerBarnes YixianDi LéonardHussenot FanYe\nAviSingh AlyssaLoo JeffreyHui JordiPont-Tuset\nIvanJurin JoshNewlan JoshSmith EricLi\nJichuanChang BoLi DeepaliJain RuichaoLi\nNiketKumarBhumihar VinayRamasesh JiaweiXia TomerGolany\nSivanEiger YingXu GauravSinghTomar DawidWegner\nGuiCitovsky AlexChen KeyvanAmiri TaoJiang\nBenWithbroe SudeepGandhe DuPhan OmerBarak\nZhangLi RaduSoricut FabianFuchs YuanShangguan\nSiyangXue NikitaGupta TobiasWeyand EszterVértes\nNiccolòDalSanto ShuguangHu NenadTomasev ReneeWong\nGeorgiStoyanov SeliemEl-Sayed AlexandraCordell JörgBornschein\nYvesRaimond XavierGarcia XinLiu AlexTudor\nStevenZheng IdanBrusilovsky JonathanMallinson MicheleBevilacqua\nYilinGao Pu-ChinChen PankajJoshi TomSchaul\nVítListík AndrewBolt AndyCrawford AnkitSinghRawat\nSławekKwasiborski LuHuang ArunSuggala YangZhao\nRachelSaputro AlexGurney SteveChien KyriakosAxiotis\nAdnanOzturel ZhiyingZhang NickFernando LeiMeng\nGaneshMallya AlexanderPritzel MariellaSanchez-Vargas CoryMcLean\nKushalMajmundar JarekWilkiewicz DuncanWilliams JonathanLai\nRossWest BryanSeybold PhilCrone JenniferBeattie\nPaulCaron BhargavKanagal XiyangLuo NateKushman\nJinliangWei Shamanna IgorKarpov YaxinLiu\nLluisCastrejon FelixFischer JynShan BlairKutzman\nSharadVikram JosefDean TerryThurk FionaLang\nDeepakRamachandran KaranGill RobinStrudel JingchenYe\nNikhilDhawan RossMcilroy PaulVoigtlaender PraneethNetrapalli\nJihoPark AbhishekBhowmick PiyushPatil PushkarMishra\nSaraSmoot JeremySelier TimDozat MyriamKhan\nGeorgevandenDriessche AntoineYang AliKhodaei MeghaGoel\nYochaiBlau DerekCheng SahilSingla RobWilloughby\nChaseMalik VladimirMagay PiotrAmbroszczyk DavidTian\nWeiLiang JieTan QiyinWu HongleiZhuang\nRoyHirsch DhritiVarma YifanChang JDChen\nCiceroNogueiradosSantos ChristianWalder BrianRoark ZakTsai\nEugeneWeinstein TomasKocisky ChaitraHegde TasosKementsietsidis\nAäronvandenOord RyoNakashima TianliDing ArjunKhare\nSidLall PaulNatsev AngelosFilos JamesKeeling\nNicholasFitzGerald MikeKwong ZhongruWu KeyangXu\nZixuanJiang IonelGog AndréSusanoPinto NathanWaters\n49"
    },
    {
      "page": 50,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFlorentAltché YuxiangZhou JamesMartens LuLiu\nAshokPopat XinyiBai TaoChen YaoSu\nBhavishyaMittal Wei-ChihHung AvielBoag AnastasiaPetrushkina\nDavidSaxton StevenPecht DaiyiPeng JiajunShen\nDaliaElBadawy GeorgiTodorov ColineDevin ArmandJoulin\nMichaelMathieu NikhilKhadke ArseniyKlimovskiy YuanzhongXu\nZhengZheng PramodGupta MaryPhuong SteinXudongLin\nHaoZhou PreethiLahoti DannyVainstein YanaKulizhskaya\nNishantRanka ArnaudAutef JinXie CiprianChelba\nRichardShin KarthikDuddu BhuvanaRamabhadran ShobhaVasudevan\nQingnanDuan JamesLee-Thorp NathanHoward EliCollins\nTimSalimans AlexanderBykovsky XinxinYu VasilisaBashlovkina\nIoanaMihailescu TautvydasMisiunas GitarthaGoswami TonyLu\nUriShaham SebastianFlennerhag JingyuCui DougFritz\nMing-WeiChang SanthoshThangaraj SamShleifer JongbinPark\nYannisAssael JedMcGiffin MarioPinto YanqiZhou\nNishanthDikkala ZackNado Chih-KuanYeh ChenSu\nMartinIzzard MarkusKunesch Ming-HsuanYang RichardTanburn\nVincentCohen-Addad AndreasNoever SaraJavanmardi MikhailSushkov\nCatGraves AmirHertz DanEthier MitchelleRasquinha\nVladFeinberg MarcoLiang ChaceLee JinningLi\nGraceChung VictorStone JordiOrbay JenniferPrendki\nDJStrouse EvanPalmer SuyogKotecha YimingLi\nDannyKarmon SamiraDaruki CarlaBromberg PallaviLV\nSahandSharifzadeh ArijitPramanik PeteShaw ShriyaSharma\nZoeAshwood SiimPõder JamesThornton HenFitoussi\nKhiemPham AustinKyker AdiGerziRosenthal HuiHuang\nJonBlanton MinaKhan ShaneGu AndrewDai\nAlexVasiloff EvgenySluzhaev MattThomas PhuongDao\nJarredBarber MarvinRitter IanGemp MikeBurrows\nMarkGeller AvrahamRuderman AdityaAyyar HenryPrior\nAurickZhou WenleiZhou AsahiUshio DanfengQin\nFedirZubach ChiragNagpal AarushSelvan GolanPundak\nTzu-KuoHuang KiranVodrahalli JoelWee LarsLoweSjoesund\nLeiZhang GeorgeNecula ChenxiLiu ArtKhurshudov\nHimanshuGupta PaulBarham MaryamMajzoubi ZhenkaiZhu\nMattYoung ElliePavlick WeirenYu AlbertWebson\nJuliaProskurnia JayHartford JakeAbernethy ElizabethKemp\nRonnyVotel IzhakShafran TylerLiechty TatTan\nValentinGabeur LongZhao RenkePan SaurabhAgrawal\nGabrielBarcik MaciejMikuła HoangNguyen SusieSargsyan\nAdityaTripathi TomEccles Qiong(Q)Hu LiqunCheng\nHongkunYu HidetoshiShimokawa SarahPerrin JimStephan\nGengYan KanavGarg AbhinavArora TomKwiatkowski\nBeerChangpinyo LukeVilnis EmilyPitler DavidReid\nFilipPavetić HanwenChen WeiyiWang ArunkumarByravan\nAmyCoyle IliaShumailov KaushikShivakumar AssafHurwitzMichaely\nYasuhisaFujii Kuang-HueiLee FlavienProst NicolasHeess\nJorgeGonzalezMendez AbdelrahmanAbdelhamed BenLimonchik LuoweiZhou\nTianhaoZhou MeiyanXie JingWang SonamGoenka\nHarishRajamani VeredCohen YiGao ViralCarpenter\nBlakeHechtman EsterHlavnova TimotheeCour AnselmLevskaya\nEddieCao DanMalkin ShyamalBuch BoWang\nDa-ChengJuan ChawinSitawarin HuanGui ReedRoberts\nYi-XuanTan JamesLottes MariaIvanova RémiLeblond\nValentinDalibard PaulineCoquinot PhilippNeubeck SharatChikkerur\nYilunDu TianliYu KelvinChan StavGinzburg\nNatalieClay SandeepKumar LucyKim MaxChang\nKaishengYao JingweiZhang HuizhongChen RobertRiachi\nWenhaoJia AromaMahendru NamanGoyal Chuqiao(Joyce)Xu\nDimpleVijaykumar ZafaraliAhmed Da-WoonChung ZalánBorsos\n50"
    },
    {
      "page": 51,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nMichaelPliskin SenakaButhpitiya VincentTsang XingyuCai\nJuliaPawar OlafRonneberger BowenLiang PaulMichel\nMorganeLustman CalebHabtegebriel FernandoPereira SanjayGanapathy\nHannahKirkwood WeiLi SuhasGanesh JaneLabanowski\nAnkitAnand PaulCavallaro IvanKorotkov ZacharyGarrett\nAditiChaudhary AuroraWei JakubAdamek BenVargas\nNorbertKalb GuyBensky SridharThiagarajan SeanSun\nKieranMilan TimoDenk VinhTran BryanGale\nSeanAugenstein HarishGanapathy CharlesChen ThomasBuschmann\nAnnaGoldie JeffStanway ChrisTar GuillaumeDesjardins\nLaurelPrince PratikJoshi SanilJain NimeshGhelani\nKarthikRaman FrancescoBertolini IshitaDasgupta PalakJain\nYanhuaSun JessicaLo TaylanBilal MuditVerma\nVivianXia OliviaMa DavidReitter ChulayuthAsawaroengchai\nAaronCohen ZacharyCharles KaiZhao JulianEisenschlos\nZhouyuanHuo GetaSampemane GiuliaVezzani JitendraHarlalka\nJoshCamp HimanshuSahni YasminGehman HidetoKazawa\nSeherEllis XuChen PulkitMehta DonMetzler\nLukasZilka HarryAskham LaurenBeltrone JoshuaHowland\nDavidVilarTorres DavidGaddy XerxesDotiwalla YingJian\nLisaPatel PeterYoung SergioGuadarrama JakeAdes\nShoArora JiewenTan ZaheerAbbas ViralShah\nBettyChan MatanEyal StefaniKarp TynanGangwani\nJonasAdler ArthurBražinskas PetkoGeorgiev SeungjiLee\nKareemAyoub LiZhong Chun-SungFerng RomanRing\nJackyLiang ZhichunWu MarcBrockschmidt StevenM.Hernandez\nFayazJamil MarkEpstein LiqianPeng DeanReich\nJiepuJiang KaiBailey ChristophHirnschall AmerSinha\nSimonBaumgartner AndrewHard VikasVerma AshutoshSathe\nHaitianSun KamyuLee YingyingBi JoeKovac\nYaelKarov SashaGoldshtein YingXiao AshleahGill\nYaroslavAkulov AlexRuiz AvigailDabush AjayKannan\nHuiZheng MohammedBadawi KelvinXu AndreaD’olimpio\nIreneCai MatthiasLochbrunner PhilWallis MartinSevenich\nClaudioFantacci JKKearns RandallParker JayWhang\nJamesRubin AshleyBrown QifeiWang BeenKim\nAlexRavAcha FabioPardo YangXu KheChaiSim\nMengchaoWang TheophaneWeber IlkinSafarli JilinChen\nNinaD’Souza HaichuanYang DineshTewari JiagengZhang\nRohitSathyanarayana Pan-PanJiang YinZhang ShubaLall\nShengyangDai BerkinAkin SeungyeonKim YossiMatias\nSimonRowe ZhaoFu AndreaGesmundo BillJia\nAndreySimanovsky MarcusWainwright MackenzieThomas AbeFriesen\nOmerGoldman ChiZou SergeyLevi SaraNasso\nYuhengKuang MeenuGaba AhmedChowdhury AshishThapliyal\nXiaoyuePan Pierre-AntoineManzagol KanishkaRao BryanPerozzi\nAndrewRosenberg WendyKan PeterGarst TingYu\nTaniaRojas-Esponda YangSong SamConway-Rahman AnnaShekhawat\nPraneetDutta KarinaZainullina HelenRan SafeenHuda\nAmyZeng RuiLin KayMcKinney PeterGrabowski\nIrinaJurenka JeongwooKo ZhishengXiao EricWang\nGregFarquhar SalilDeshmukh WenhaoYu AshwinSreevatsa\nYaminiBansal ApoorvJindal RohanAgrawal HilalDib\nShariqIqbal JamesSvensson AxelStjerngren MehadiHassen\nBeccaRoelofs DivyaTyam CatalinIonescu ParkerSchuh\nGa-YoungJoung HeriZhao JingjingChen VedranaMilutinovic\nParkerBeak ChristineKaeser-Chen VivekSharma ChrisWelty\nChangwanRyu ScottBaird JustinChiu MichaelQuinn\nRyanPoplin PooyaMoradi FeiLiu AliShah\nYanWu JamieHall KenFranko BangjuWang\nJean-BaptisteAlayrac QiuchenGuo ClaytonSanford GabeBarth-Maron\n51"
    },
    {
      "page": 52,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nJustinFrye PatrickKane Andr’asGy\"orgy ArjunAkula\nNatalieAxelsson CeZheng ArunAhuja MaxDylla\nTaoZhu NicoDuduta DanielHernandezDiaz AshyanaKachra\nYukunMa JoshuaKessinger Chen-YuLee WeichengKuo\nIreneGiannoumis JamesNoraky NathanClement TingtingZou\nHanieSedghi SiqiLiu WeizeKong LilyWang\nChangYe KeranRong DrewGarmon LuyaoXu\nYiLuan PetarVeličković IshaanWatts JifanZhu\nKevinAydin KeithRush KushBhatia JustinSnyder\nBilvaChandra AlexGoldin KhyattiGupta SachitMenon\nVivekSampathkumar FannyWei MattMiecnikowski OrhanFirat\nRonnyHuang ShivaMohanReddy HugoVallet IgorMordatch\nVictorLavrenko Garlapati AnkurTaly YuanYuan\nAhmedEleryan CarolinePantofaru EdwardLoper NataliaPonomareva\nZhiHong OkwanKwon SaketJoshi RoryBlevins\nStevenHansen JianmoNi JamesAtwood LawrenceMoore\nSaraMcCarthy EricNoland JoChick WeijunWang\nBidishaSamanta JuliaDiTrapani MarkCollier PhilChen\nDomagojĆevid FrançoiseBeaufays FotisIliopoulos MartinScholz\nXinWang AbhijitGuhaRoy RyanTrostle ArturDwornik\nFangtaoLi YinlamChow BelizGunel JasonLin\nMichaelVoznesensky AybukeTurker RamiroLeal-Cavazos SichengLi\nMattHoffman GeoffreyCideron ArnarMarHrafnkelsson DiegoAntognini\nAndreasTerzis LantaoMei MichaelGuzman TeI\nVikashSehwag JonClark XiaoenJu XiaodanSong\nGilFidel QingyunDou AndyForbes MattMiller\nLuhengHe MatkoBošnjak JesseEmond UdayKalra\nMuCai RalphLeith KushalChauhan AdamRaveret\nYanzhangHe YuqingDu BenCaine OscarAkerlund\nAlexFeng AmirYazdanbakhsh LiXiao FelixWu\nMartinNikoltchev MiladNasr WenjunZeng AndrewNystrom\nSamratPhatale ChesterKwak AlexandreMoufarek NamrataGodbole\nJasonChase SurajSatishkumarSheth DanielMurphy TianqiLiu\nRoryLawton AlexKaskasoli MayaMeng HannahDeBalsi\nMingZhang AnkeshAnand NitishGupta JewelZhao\nTomOuyang BalajiLakshminarayanan FelixRiedel BuhuangLiu\nManuelTragut SammyJerome AnilDas AviCaciularu\nMehdiHafeziManshadi DavidBieber ElijahLawal LaurenLax\nArjunNarayanan Chun-TeChu ShashiNarayan UrvashiKhandelwal\nJiamingShen AlexandreSenges TiberiuSosea VictoriaLangston\nXuGao TianxiaoShen JamesSwirhun EricBailey\nTolgaBolukbasi MukundSridhar LindaFriso SilvioLattanzi\nNickRoy NdabaNdebele BehnamNeyshabur YufeiWang\nXinLi BenjaminBeyret JingLu NeelKovelamudi\nDanielGolovin ShakirMohamed SertanGirgin SnehaMondal\nLiviuPanait MiaChen MichaelWunder GuruGuruganesh\nZhenQin MarkusFreitag EdouardYvinec NanHua\nGuangxingHan JiaxianGuo AroonalokPyne OfirRoval\nThomasAnthony LuyangLiu VictorCarbune PawełWesołowski\nSnehaKudugunta PaulRoit ShrutiRijhwani RishikeshIngale\nVioricaPatraucean HengChen YangGuo JonathanHalcrow\nAniketRay ShenYan TulseeDoshi TimSohn\nXinyunChen TomStone AntonBriukhov ChristofAngermueller\nXiaochenYang JDCo-Reyes MaxBain BahramRaad\nTanujBhatia JeremyCole AyalHitron EliStickgold\nPranavTalluri SalvatoreScellato XuanhuiWang EvaLu\nAlexMorris ShekoofehAzizi AshishGupta AlecKosik\nAndrijaRažnatović HadiHashemi KeChen JingXie\nBethanieBrownfield AliciaJin CosmoDu TimothyLillicrap\nJamesAn AnandIyer WeiyangZhang AustinHuang\nShengPeng MarcellaValentine DhruvShah LydiaLihuiZhang\n52"
    },
    {
      "page": 53,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nDominikPaulus DangyiLiu SujeevanRajayogam AndriiMaksai\nClementFarabet RengaAravamudhan MohitAgarwal ÁgostonWeisz\nAlexWertheim YueSong SubhashiniVenugopalan SercanArik\nBingWang EdHirst BobakShahriari NickSukhanov\nRishabhJoshi AbhimanyuSingh QiqiYan AgaŚwietlik\nChu-lingKo BrendanJou HaoXu XuhuiJia\nYonghuiWu LiangBai TaylorTobin LuoYu\nShubhamAgrawal FrancescoPiccinno PavelDubov WeiyueWang\nLilyLin ChuyuanKellyFu HongzhiShi MarkBrand\nXiangHaiSheng RobinAlazard AdriàRecasens DawnBloxwich\nPeterSung BarakMeiri AntonKovsharov SeanKirmani\nTylerBreland-King DanielWinter SebastianBorgeaud ZheChen\nChristinaButterfield CharlieChen LucioDery AlecGo\nSwapnilGawde MingdaZhang ShanthalVasanth PabloSprechmann\nSumeetSingh JensHeitkaemper ElenaGribovskaya NithishKannen\nQiaoZhang JohnLambert LinhaiQiu AlenCarin\nRajApte JinhyukLee MahdisMahdieh ParamjitSandhu\nShilpaShetty AlexanderFrömmgen WojtekSkut IsabelEdkins\nAdrianHutter SergeyRogulenko ElizabethNielsen LeslieNooteboom\nTaoLi PranavNair CJZheng JaiGupta\nElizabethSalesky PaulNiemczyk AdamsYu LorenMaggiore\nFedericoLebron AntonBulyenov CarrieGrimesBostock JavadAzizi\nJonniKanerva BiboXu ShaleenGupta YaelPritch\nMichelaPaganini HadarShemtov AaronArcher PengchengYin\nArthurNguyen MortezaZadimoghaddam ChrisRawles MansiGupta\nRohithVallu SergeToropov ElinorDavies DannyTarlow\nJan-ThorstenPeter MateoWirth AlexeySvyatkovskiy DuncanSmith\nSarmishtaVelury HanjunDai TomyTsai DesiIvanov\nDavidKao SreenivasGollapudi YoniHalpern MohammadBabaeizadeh\nJayHoover DanielZheng ChristianReisswig AnkitaGoel\nAnnaBortsova AlexKurakin BartekWydrowski SatishKambala\nColtonBishop ChansooLee BoChang GraceChu\nShoshanaJakobovits KaleshaBullard JoanPuigcerver MatejKastelic\nAlessandroAgostini NicolasSerrano MorHazanTaege MichelleLiu\nAlekhAgarwal IvanaBalazevic JianLi HagenSoltau\nChangLiu YangLi EvaSchnider AustinStone\nCharlesKwong JohanSchalkwyk XinjianLi ShivaniAgrawal\nSasanTavakkol MarkMurphy DragosDena MinKim\nIoanaBica MingyangZhang YunhanXu KedarSoparkar\nAlexGreve KevinSequeira UmeshTelang SrinivasTadepalli\nAnirudhGP RominaDatta TianzeShi OskarBunyan\nJakeMarcus NishantAgrawal HeigaZen RachelSoh\nLeHou CharlesSutton KyleKastner ArvindKannan\nTomDuerig NithyaAttaluri YeongilKo DYKim\nRivkaMoroshko MencherChiang NeeshaSubramaniam BlakeJianHangChen\nDaveLacey WaelFarhan AviralKumar AfiefHalumi\nAndyDavis GregoryThornton PeteBlois SudeshnaRoy\nJulienAmelot KateLin ZhuyunDai YulongWang\nGuohuiWang TravisChoma JohnWieting OlcanSercinoglu\nFrankKim HungNguyen YifengLu GenaGibson\nTheofilosStrinopoulos KingshukDasgupta YoelZeldes SijalBhatnagar\nHuiWan DirkRobinson TianXie MotokiSano\nCharlineLeLan IuliaComşa AnjaHauth DanielvonDincklage\nShankarKrishnan MichaelRiley AlexandruŢifrea QingchunRen\nHaotianTang ArjunPillai YuqiLi BlagojMitrevski\nPeterHumphreys BasilMustafa SamEl-Husseini MirekOlšák\nJunwenBai BenGolan DanAbolafia JenniferShe\nIdanHeimlichShtacher AmirZandieh HowardZhou CarlDoersch\nDiegoMachado Jean-BaptisteLespiau WenDing Jilei(Jerry)Wang\nChenxiPang BillyPorter SahraGhalebikesabi BingyuanLiu\nKenBurke DavidRoss CarlosGuía QijunTan\n53"
    },
    {
      "page": 54,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nTamarYakar StanBileschi MatthewBilotti MichaelFink\nTrisWarkentin GeorgiosEvangelopoulos MohammadHosseinBateni ReidHayes\nAlexRamirez ThomasMensink IsaacNoble EricGe\nCarlLebsack JayPavagadhi LisaLee ShitaoWeng\nJoshDillon DenisTeplyashin AmelioVázquez-Reina Chia-HuaHo\nRajivMathews PaulChang JulianSalazar JohnKarro\nTomCobley LintingXue XiaomengYang KalpeshKrishna\nZelinWu GarrettTanzer BoyuWang LamNguyenThiet\nZhuoyuanChen SallyGoldman ElaGruzewska AmySkerry-Ryan\nJonSimon KaushalPatel AnandRao DanielEppens\nSwaroopNath ShixinLi SindhuRaghuram MarcoAndreetto\nTaraSainath JeremyWiesner ZhengXu NavinSarma\nAlexeiBendebury IvyZheng EyalBen-David SilvanoBonacina\nRyanJulian IanStewart-Binks JieruMei BurcuKaragolAyan\nBharathMankalale JieHan SidDalmia MeghaNawhal\nDariaĆurko ZhiLi ZhaoyiZhang ZhihaoShan\nPauloZacchello LiangchenLuo YuchenLiu MikeDusenberry\nAdamR.Brown KarelLenc GaganBansal ShantanuThakoor\nKiranbirSodhia MarioLučić HelenaPankov SagarGubbi\nHeidiHoward FuzhaoXue StevenSchwarcz DucDungNguyen\nSergiCaelles RyanMullins AndreaBurns ReutTsarfaty\nAbhinavGupta AlexeyGuseynov ChristineChan SamuelAlbanie\nGarethEvans Chung-ChingChang SumitSanghai JovanaMitrović\nAnnaBulanova IsaacGalatzer-Levy RickyLiang MeetGandhi\nLesleyKatzen AdamZhang EthanLiang Bo-JuenChen\nRomanGoldenberg GarrettBingham AntoineHe AlessandroEpasto\nAntonTsitsulin GraceHu AmyStuart GeorgiStephanov\nJoeStanton AleHartman ArunNarayanan YeJin\nBenoitSchillings YueMa YukunZhu SamuelGehman\nVitalyKovalev JordanGriffith ChristianFrank AidaAmini\nCoreyFry AlexIrpan BaharFatemi JackWeber\nRushinShah CareyRadebaugh AmitSabne FeryalBehbahani\nKuoLin SummerYue OranLang ShawnXu\nShyamUpadhyay LijieFan IndroBhattacharya MiltosAllamanis\nChengLi VictorUngureanu ShaneSettle XiChen\nSoroushRadpour ChristinaSorokin MariaWang MyleOtt\nMarcelloMaggioni HannahTeufel BrendanMcMahan ClaireSha\nJingXiong PeiranLi AndreaTacchetti MichalJastrzebski\nLukasHaas RohanAnil LivioBaldiniSoares HangQi\nJennyBrennan DimitrisPaparas MajidHadian DavidGreene\nAishwaryaKamath ToddWang SerkanCabi XinyiWu\nNikolaySavinov Chu-ChengLin TimothyChung AbodunrinwaToki\nArshaNagrani HuiPeng NikitaPutikhin DanielVlasic\nTrevorYacovone MeganShum GangLi JaneShapiro\nRyanKappedal GoranPetrovic JeremyChen RaghaKotikalapudi\nKostasAndriopoulos DemetraBrady AustinTarango ZheShen\nLiLao RichardNguyen HenrykMichalewski TakaakiSaeki\nYaGuangLi KlausMacherey MehranKazemi SiruiXie\nGrigoryRozhdestvenskiy ZhihaoLi HussainMasoom AlbinCassirer\nKazumaHashimoto HarmanSingh HilaSheftel ShikharBharadwaj\nAndrewAudibert MadhaviYenugula RakeshShivanna TatsuyaKiyono\nSophiaAustin MarikoIinuma ArchitaVadali SrinadhBhojanapalli\nDanielRodriguez XinyiChen RamonaComanescu ElanRosenfeld\nAnianRuoss KavyaKopparapu DougReid SamRitter\nGarrettHonke AlexeyStern JossMoore JiemingMao\nDeepKarkhanis ShachiDave ArvindNeelakantan JoãoGabrielOliveira\nXiXiong ChanduThekkath MichaëlSander ZoltanEgyed\nQingWei FlorencePerot JonathanHerzig BerndBandemer\nJamesHuang AnuragKumar AvivRosenberg EmilioParisotto\nZhaoqiLeng FangdaLi MostafaDehghani KeisukeKinoshita\nVittalPremachandran YangXiao JDChoi JuliettePluto\n54"
    },
    {
      "page": 55,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nPetrosManiatis GloriaShen SwaroopMishra Cheng-ChunLee\nSteveLi ElijahPeake JosipDjolonga TapomayDey\nYaohuiGuo RemiCrocker CraigSchiff HaoZheng\nGolnazGhiasi ShubhaSrinivas MajdAlMerey ShachiPaul\nJeanTarbouriech Raghvendra EleftheriaBriakou CelineSmith\nSrimonChatterjee DannySwisher PeterMorgan AndyLy\nJulieJin WoohyunHan AndyWan YichengWang\nKatrina(Xinyi)Xu RichaSingh AvinatanHassidim RishabhBansal\nJennimariaPalomaki LingWu RJSkerry-Ryan BartekPerz\nSébArnold VladimirPchelin KuntalSengupta SusannaRicco\nMadhaviSewak TsendsurenMunkhdalai MaryJasarevic StashaBlank\nFedericoPiccinini DanaAlon PraveenKallakuri VaishakhKeshava\nMohitSharma GeoffBacon PaigeKunkle DeepakSharma\nBenAlbrecht EfrenRobles HannahBrennan MarvinChow\nSeanPurser-haskell JannisBulian TomLieber KunalLad\nAshwinVaswani MelvinJohnson HassanMansoor KomalJalan\nChongyanChen GeorgePowell JulianWalker SimonOsindero\nMatheusWisniewski FelipeTiengoFerreira BingZhang CraigSwanson\nQinCao YaoyiranLi AnnieXie JacobScott\nJohnAslanides FrederikBenzing GoranŽužić AnastasijaIlić\nNguyetMinhPhu MihajloVelimirović AdaezeChukwuka XiaoweiLi\nMaximilianSieb HubertSoyer AlexDruinsky SiddharthaReddy\nLaurenAgubuzu WilliamKong DonghyunCho Jonnalagadda\nAnneZheng Tony(Tuâ´n)Nguy˜ên RuiYao AfzalShamaSoudagar\nDanielSohn ZhenYang FerjadNaeem YanXiong\nMarcoSelvi JeremiahLiu ShirazButt Bat-OrgilBatsaikhan\nAndersAndreassen JoostvanAmersfoort EunyoungKim DanielJarrett\nKrishanSubudhi DanielGillick ZhipengJia NaveenKumar\nPremEruvbetine BaochenSun MandyJordan MaulikShah\nOliverWoodman NathalieRauschmayr AdamLelkes MattLawlor\nTomasMery KatieZhang MarkKurzeja AustinWaters\nSebastianKrause SerenaZhan SophieWang MarkGraham\nXiaoqiRen TaoZhou JamesZhao RhysMay\nXiaoMa AlexeyFrolov AndrewOver SabelaRamos\nJinchengLuo ChengrunYang AbhishekChakladar SandraLefdal\nDawnChen DenisVnukov MarcelPrasetya ZeynepCankara\nWeiFan LouisRouillard NehaJha NachoCano\nHenryGriffiths HongjiLi SriramGanapathy BrendanO’Donoghue\nChristianSchuler AmolMandhane YaleCong JedBorovik\nAliceLi NovaFallen PrakashShroff FrederickLiu\nShujianZhang RajeshVenkataraman CarlSaroufim JordanGrimstad\nJean-MichelSarr ClaraHuiyiHu SobhanMiryoosefi MahmoudAlnahlawi\nShixinLuo JenniferBrennan MohamedHammad KaterinaTsihlas\nRiccardoPatana JennyLee TajwarNasir TomHudson\nMatthewWatson JerryChang WeijuanXi NikolaiGrigorev\nDaniNaboulsi MartinSundermeyer YangGao YilingJia\nMichaelCollins ZhufengPan YoungMaeng TerryHuang\nSaileshSidhwani RosemaryKe BenHora TobennaPeterIgwe\nEmielHoogeboom SimonTong Chin-YiCheng SergeiLebedev\nSharonSilver AlexFabrikant ParisaHaghani XiaodanTang\nEmilyCaveness WilliamBono YoadLewenberg IgorKrivokon\nXiaokaiZhao JindongGu CadenLu FrankieGarcia\nMikelRodriguez RyanFoley MartinMatysiak MelissaTan\nMaxineDeines YiranMao NainaRaisinghani EricJia\nLibinBai ManolisDelakis HuiyuWang PeterStys\nPatrickGriffin DhruvaBhaswar LexiBaugher ShikharVashishth\nMarcoTagliasacchi RoyFrostig RahulSukthankar YuLiang\nEmilyXue NickLi MinhGiang BalajiVenkatraman\nSpandanaRajBabbula AvitalZipori JohnSchultz ChenjieGu\nBoPang CathHope NoahFiedel AnastasiosKementsietsidis\nNanDing OlgaKozlova MinminChen ChenZhu\n55"
    },
    {
      "page": 56,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nJunehyukJung DorsaSadigh AyushiAgarwal JongLee\nYunfeiBai JeremiahWillcock KathieWang ShengZhang\nMohammadJavadHosseini TingnanZhang PreetiSingh SushantKafle\nFarukAhmed SteveXu FourFlynn SiddharthVashishtha\nAdityaGupta SashaBrown JoshLipschultz ParsaMahmoudieh\nXinYuan KatherineLee RobertDavid GraceChen\nShereenAshraf GaryWang LizzetthBellot RaphaelHoffmann\nShitijNigam YunZhu Yao-YuanYang PraneshSrinivasan\nGautamVasudevan YiTay LongLe AgustinDalLago\nPranjalAwasthi CheolminKim FilippoGraziano YoavBenShalom\nAdiMayravGilady AudreyGutierrez KateOlszewska ZiWang\nZeldaMariet AbhanshuSharma KevinHui MichaelElabd\nRamyEskander YongqinXian AkankshaMaurya AnujSharma\nHaiguangLi SungyongSeo NikosParotsidis JunhyukOh\nHexiangHu ClaireCui WeijieChen SurajKothawade\nGuillermoGarrido ElenaPochernina TayoOguntebi MaigoLe\nPhilippeSchlattner CipBaetu JoeKelley MarianneMonteiro\nGeorgeZhang KrzysztofJastrzębski AnirudhBaddepudi ShentaoYang\nRohunSaxena MimiLy JohannesMauerer KaizAlarakyia\nPetarDević MohamedElhawaty GregoryShaw RobertGeirhos\nKritikaMuralidharan DanSuh AlexSiegman DianaMincu\nAshwinMurthy ErenSezener LinYang HåvardGarnes\nYiqianZhou PidongWang ShravyaShetty HayatoKobayashi\nMinChoi NancyYuen SubhrajitRoy SorooshMariooryad\nArissaWongpanich GeorgeTucker YuntingSong KacperKrasowiak\nZhengdongWang JiahaoCai WojciechStokowiec Zhixin(Lucas)Lai\nPremalShah ZuguangYang RyanBurnell ShiblMourad\nYuntaoXu CindyWang OmkarSavant MingqiuWang\nYilingHuang AlexMuzio RobertBusa-Fekete FanBu\nStephenSpencer HaiQian JinMiao OphirAharoni\nAliceChen JaeYoo SamratGhosh GuanjieChen\nJamesCohan DerekLockhart LiamMacDermed AbhimanyuGoyal\nJunjieWang KevinR.McKee PhillipLippe VadimZubov\nJonathanTompson MandyGuo MikhailDektiarev AnkurBapna\nJunruWu MalikaMehrotra ZachBehrman ElaheDabir\nRubaHaroun ArturMendonça FabianMentzer NisargKothari\nHaiqiongLi SanketVaibhavMehta KelvinNguyen KayLamerigts\nBlancaHuergo SherryBen MengWei NicolaDeCao\nFanYang ChetanTekur SiddharthVerma JeremyShar\nTongxinYin JiaqiMu ChrisKnutsen ChristopherYew\nJamesWendt MuyeZhu SudeepDasari NitishKulkarni\nMichaelBendersky VictoriaKrakovna ZhipengYan DreMahaarachchi\nRahmaChaabouni HongraeLee PetrMitrichev MandarJoshi\nJavierSnaider AJMaschinot XingyuWang ZhenhaiZhu\nJohanFerret SébastienCevey ViratShejwalkar JaredLichtarge\nAbhishekJindal HyunJeongChoe JacobAustin YichaoZhou\nTaraThompson AijunBai SrinivasSunkara HannahMuckenhirn\nAndrewXue HansaSrinivasan NavneetPotti VittorioSelo\nWillBishop DerekGasaway YanVirin OriolVinyals\nShubhamMilindPhal NickYoung ChristianWright PeterChen\nArchitSharma PatrickSiegler GaëlLiu AnthonyBrohan\nYunhsuanSung DanHoltmann-Rice OrianaRiva VaibhavMehta\nPrabakarRadhakrishnan VihariPiratla EtiennePot SarahCogan\nMoShomrat KateBaumli GregKochanski RuthWang\nReeveIngle RoeyYogev QuocLe TyGeri\nRoopaliVij AlexHofer GargiBalasubramaniam Wei-JenKo\nJustinGilmer HadovanHasselt ArkaDhar WeiChen\nMihaiDorinIstin SvetlanaGrant YuguoLiao FabioViola\nSamSobell YuriChervonyi AdamBloniarz KeshavShivam\nYangLu DavidSilver DivyanshShukla LisaWang\nEmilyNottage AndrewHogue ElizabethCole MadeleineClareElish\n56"
    },
    {
      "page": 57,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nRalucaAdaPopa CesleeMontgomery JialinWu KaiKang\nSébastienPereira DheeruDua SlavicaAndačić YifanHe\nJianqiaoLiu AnaRamalho SzabolcsPayrits LinZhuo\nRaphaelKoster HelenKing DanielMcDuff MarijaKostelac\nDonnieKim YueGao TomHume ItayLaish\nGufengZhang LynnNguyen YuanCao SongyouPeng\nSaynaEbrahimi DavidLindner MHTessler LouisO’Bryan\nParthaTalukdar DivyaPitta QingzeWang DanielKasenberg\nYanyanZheng OleaserJohnson YinanWang GirishRamchandraRao\nPetraPoklukar KhalidSalama IvorRendulic EdouardLeurent\nAlesMikhalap DiegoArdila EirikurAgustsson BiaoZhang\nDaleJohnson MichaelHan MatthewJohnson SageStevens\nAnithaVijayakumar ErinFarnese TanyaLando AnaSalazar\nMarkOmernick SethOdoom AndrewHoward YeZhang\nMattDibb ZiyueWang SriGayatriSundara IvanLobov\nAyushDubey XiangzhuoDing Padmanabhan JakeWalker\nQiongHu NormanRink MayankDaswani AllenPorter\nApurvSuman RaySmith AndreaBanino MorganRedshaw\nVaibhavAggarwal HarshalTusharLehri MichaelKilgore HanKe\nIlyaKornakov EdenCohen JonathanHeek AbhishekRao\nFeiXia NeeraVats ZiweiJi AlexLee\nWingLowe TongHe AlvaroCaceres HoiLam\nAlexeyKolganov ParthasarathyGopavarapu ConglongLi MichaelMoffitt\nTedXiao AdamPaszke NoraKassner JaeyounKim\nVitalyNikolaev MiteyanPatel AlexeyVlaskin SiyuanQiao\nStevenHemingray WouterVanGansbeke ZeyuLiu TerryKoo\nBonnieLi LuciaLoher AlexGrills RobertDadashi\nJoanaIljazi LuisCastro YanhanHou XinyingSong\nMikołajRybiński MariaVoitovich RoykrongSukkerd MukundSundararajan\nBallieSandhu TamaravonGlehn GowoonCheon PengXu\nPeggyLu NelsonGeorge NishitaShetty ChizuKawamoto\nThangLuong SimonNiklaus LarisaMarkeeva YanZhong\nRodolpheJenatton ZachEaton-Rosen PiotrStanczyk ClaraBarbu\nVineethaGovindaraj NemanjaRakićević TejasIyer ApoorvReddy\nHui(Elena)Li ErikJue YuanGong MauroVerzetti\nGabrielDulac-Arnold SagiPerel ShawnGao LeonLi\nWonpyoPark CarrieZhang KeerthanaGopalakrishnan GeorgePapamakarios\nHenryWang YuvalBahat TimBlyth HannaKlimczak-Plucińska\nAbhinitModi AngélinePouget MalcolmReynolds MaryCassin\nJeanPouget-Abadie ZhiXing AvishkarBhoopchand KorayKavukcuoglu\nKristinaGreller FantineHuot MishaBilenko RigelSwavely\nRahulGupta AshishShenoy DeroGharibian AlainVaucher\nRobertBerry TaylorBos VickyZayats JeffreyZhao\nPrajitRamachandran VincentCoriou AleksandraFaust RossHemsley\nJinyuXie BryanRichter AbhinavSingh MichaelTschannen\nLiamMcCafferty NatashaNoy MinMa HemingGe\nJianlingWang YaqingWang HongyangJiao GauravMenghani\nKilolGupta SantiagoOntanon Sudheendra YangYu\nHyeontaekLim SiyangQin Vijayanarasimhan NatalieHa\nBlažBratanič GlebMakarchuk LoraAroyo WeiHe\nAndyBrock DemisHassabis VikasYadav XiaoWu\nIliaAkolzin ZhuowanLi SarahChakera MaggieSong\nJimSproch MandarSharma AshwinKakarla RachelSterneck\nDanKarliner KumaranVenkatesan VilobhMeshram StefanZinke\nDuhyeonKim IuriiKemaev KarolGregor DanA.Calian\nAdrianGoedeckemeyer RoxanneDaniel GabrielaBotea AnnieMarsden\nNoamShazeer ShiyuHuang EvanSenter AlejandroCruzadoRuiz\nCordeliaSchmid SaloniShah DaweiJia MatteoHessel\nDanieleCalandriello OctavioPonce GezaKovacs AlmogGueta\nParulBhatia Warren(Weilun)Chen NehaSharma BenjaminLee\nKrzysztofChoromanski ManaalFaruqui SebastienBaur BrianFarris\n57"
    },
    {
      "page": 58,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nManishGupta YinZhong ZachFisher RohinShah\nYunjieLi JunwhanAhn DustinZelle JohnYoussef\nMohammadSaleh MichaelIsard CourtneyBiles RishabhAgarwal\nVedantMisra OlivierLacombe EugeneIe NatalieDabney\nKefanXiao FlorianLuisier AsyaFadeeva AlessioTonioni\nPiermariaMendolicchio ChrysovalantisAnastasiou CasperLiu MoranAmbar\nGavinButtimore YogeshKalley JulianaVicenteFranco JingLi\nVarvaraKrayvanova UtsavPrabhu AdrianCollister IsabelleGuyon\nNigamaaNayakanti EmmaDunleavy HaoZhang BennyLi\nMatthewWiethoff ShaanBijwadia RenshenWang DavidSoergel\nYashPande JustinMao-Jones RuizheZhao BoyaFang\nAzaliaMirhoseini KellyChen LeandroKieliger GeorgiKaradzhov\nNiLao RamaPasumarthi KurtShuster CristianUdrescu\nJasmineLiu EmilyWood RuiZhu TrieuTrinh\nYiqingHua AdilDostmohamed BoqingGong VikasRaunak\nAngieChen NateHurley LawrenceChan SebNoury\nYuryMalkov JiriSimsa RuoxiSun DeeGuo\nDmitryKalashnikov AliciaParrish SujoyBasu SonalGupta\nShubhamGupta MantasPajarskas RolandZimmermann MaraFinkelstein\nKartikAudhkhasi MattHarvey JamieHayes DenisPetek\nYuexiangZhai OndrejSkopek AbhishekBapna LihaoLiang\nSudhindraKopalle YonyKochinski JasperSnoek GregBillock\nPrateekJain JavierRey WeelYang PeiSun\nEranOfek VerenaRieser PuranjayDatta DavidWood\nClemensMeyer DennyZhou JadAlAbdallah YiwenSong\nKhuslenBaatarsukh SunJaeLee KevinKilgour XiaobinYu\nHanaStrejček TrilokAcharya LuLi TatianaMatejovicova\nJunQian GuowangLi SQMah RegevCohen\nJamesFreedman JoeJiang YennieJun KalyanAndra\nRicardoFigueira XiaofanZhang MorganeRivière DavidD’Ambrosio\nMichalSokolik BryantGipson AbhijitKarmarkar ZhiweiDeng\nOlivierBachem EthanMahintorabi TammoSpalink VincentNallatamby\nRaymondLin MarcoGelmi TaoHuang EbrahimSonghori\nDiaKharrat NimaKhajehnouri LucasGonzalez RumenDangovski\nChrisHidey AngelYeh Duc-HieuTran AndrewLampinen\nPingmeiXu KayiLee AveriNowak PankilBotadra\nDennisDuan LoicMatthey JohnPalowitch AdamHillier\nYinLi LeslieBaker MartinChadwick JiaweiCao\nMugeErsoy TrangPham EllieTalius NagabhushanBaddi\nRichardEverett HanFu HarshMehta AdhiKuncoro\nKevinCen AlexPak ThibaultSellam ToshihiroYoshino\nRebeca PrakharGupta PhilippFränken AnkitBhagatwala\nSantamaria-Fernandez CristinaVasconcelos MassimoNicosia Marc’aurelioRanzato\nAmirTaubenfeld AdamSadovsky KyleHe RylanSchaeffer\nIanMackinnon BrianWalker AdityaKini TianlinLiu\nLindaDeng SissieHsiao DavidAmos ShuaiYe\nPolinaZablotskaia PatrikZochbauer SugatoBasu ObaidSarvana\nShashankViswanadha AndreeaMarzoca HarrisonJobe JohnNham\nShivankerGoel NoamVelan EleniShaw ChenkaiKuang\nDamionYates JunhaoZeng QiantongXu IsabelGao\nYunxiaoDeng GillesBaechler ColinEvans JinooBaek\nPeterChoy DannyDriess DaisukeIkeda ShubhamMittal\nMingqingChen DivyaJain ChaochaoYan AyzaanWahid\nAbhishekSinha YanpingHuang LarryJin AnitaGergely\nAlexMossin LizzieTao LunWang BinNi\nYimingWang JohnMaggs SachinYadav JoshFeldman\nArthurSzlam NirLevine IliaLabzovsky CarrieMuir\nSusanHao JonSchneider RameshSampath PascalLamblin\nPaulKishanRubenstein ErikaGemzer AdaMa WolfgangMacherey\nMetinToksoz-Exley SamuelPetit CandiceSchumann EthanDyer\nMirandaAperghis ShanHan AdityaSiddhant LoganKilpatrick\n58"
    },
    {
      "page": 59,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nVíctorCampos DaveOrr AlaaSaade UriAlon\nMukulBhutani LeventBolelli AngeloScorzaScarpati XianghongLuo\nStanislavFort NicolasPerez-Nieves ChrisBreaux DianYu\nYanifAhmad MikhailSirotenko CJCarey AbhishekNayyar\nAliakseiSeveryn AmanPrasad ZongweiZhou BrycePetrini\nKleopatraChatziprimou ArjunKar Cho-JuiHsieh WillTruong\nOleksandrFerludin BorjaDeBallePigem SophieBridgers VincentHellendoorn\nMasonDimarco TayfunTerzi AlenaButryna NikolaiChinaev\nAdityaKusupati GellértWeisz NisheshGupta ChrisAlberti\nJoeHeyward DipankarGhosh VaibhavTulsyan WeiWang\nDanBahir AditiMavalankar SanghyunWoo JingcaoHu\nKevinVillela DhruvMadeka EvgeniiEltyshev VahabMirrokni\nKatieMillican KasparDaugaard WillGrathwohl AnanthBalashankar\nDrorMarcus HartwigAdam ChanelParks AviaAharon\nSanazBahargam VirajShah SethBenjamin AahilMehta\nCaglarUnlu DanaBerman RinaPanigrahy AhmetIscen\nNicholasRoth MaggieTran ShenilDodhia JosephKready\nZichuanWei StevenBaker DanielDeFreitas LucasManning\nSiddharthGopal EwaAndrejczuk ChrisSauer AnhadMohananey\nDeepanwayGhoshal GrishmaChole WillSong YuankaiChen\nEdwardLee GannaRaboshchuk FerranAlet AnshumanTripathi\nSharonLin MahdiMirzazadeh JacksonTolins AllenWu\nJennieLees ThaisKagohara CosminPaduraru IgorPetrovski\nDayeongLee ShimuWu XingyiZhou DawsenHwang\nAnahitaHosseini ChristianSchallhart BrianAlbert MartinBaeuml\nConnieFan BernettOrlando ZizhaoZhang Shreyas\nSethNeel ChenWang LeiShu Chandrakaladharan\nMarcusWu AlbanRrustemi MuditBansal YuanLiu\nYaseminAltun HaoXiong SarahNguyen ReyCoaguila\nHonglongCai HaoLiu AmirGloberson MaxwellChen\nEnriquePiqueras ArpiVezer OwenXiao SallyMa\nJoshWoodward NolanRamsden JamesManyika PouyaTafti\nAlessandroBissacco Shuo-yiinChang TomHennigan SusheelTatineni\nSalemHaykal SidharthMudgal RongRong TerrySpitz\nMahyarBordbar YanLi JosipMatak JiayuYe\nPrashaSundaram NinoVieillard AntonBakalov PaulVicol\nSarahHodkinson YedidHoshen AnkurSharma MihaelaRosca\nDanielToyama FarooqAhmad DanilaSinopalnikov AdriàPuigdomènech\nGeorgePolovets AmbroseSlone AndrewPierson ZoharYahav\nAustinMyers AmyHua StephenRoller SanjayGhemawat\nAnuSinha NatanPotikha GeoffBrown HanzhaoLin\nTomerLevinboim MirkoRossini MingcenGao PhoebeKirk\nKashyapKrishnakumar JonStritar ToshiyukiFukuzawa ZaidNabulsi\nRachitaChhaparia SushantPrakash AminGhafouri SergeyBrin\nTatianaSholokhova ZifengWang KennyVassigh BerndBohnet\nNiteshBharadwaj XuanyiDong IainBarr KenCaluwaerts\nGundavarapu AlirezaNazari ZhichengWang AdityaSrikanth\nGaneshJawahar EfratNehoran AnnaKorsun Veerubhotla\nHaroonQureshi KaanTekelioglu RajeshJayaram DanZheng\nJieruHu YinxiaoLi LijieRen ZihangDai\nNikolaMomchev KartikeyaBadola TimZaman PetrePetrov\nMatthewRahtz TomFunkhouser SamiraKhan YichongXu\nRenjieWu YuanzhenLi YanaLunts RaminMehran\nAishwaryaPS VarunYerram DanDeutsch ZhuoXu\nKedarDhamdhere RamyaGaneshan DaveUthus LuisaZintgraf\nMeiqiGuo DanielFormoso NitzanKatz JihoChoi\nUmangGupta KarolLangner MashaSamsikova SpurthiAmbaHombaiah\nAliEslami TianShi AmrKhalifa RomalThoppilan\nMarianoSchain HuijianLi NikhilSethi SashankReddi\nMichielBlokzijl YumeyaYamamori JiaoSun LukaszLew\nDavidWelling AmayikaPanda LumingTang LiLi\n59"
    },
    {
      "page": 60,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nKellieWebster LuisC.Cobo JingweiShen AlokGunjan\nKPSawhney JamesQin MiaosenWang BilalPiot\nLamprosLamprou ThiAvrahami RoopalGarg WaleedKhawaja\nSiamakShakeri DanielBalle JingChen SeojinBang\nMayankLunayach YuWatanabe UtkuEvci SimonWang\nJianminChen AnnieLouis JonathanLee SiavashKhodadadeh\nSumitBagri AdamKraft LeonLiu RaghavenderR\nAlexSalcianu SetarehAriafar KojiKojima PraynaaRawlani\nYingChen YimingGu MasaYamaguchi RichardPowell\nYaniDonchev EugénieRives ArunkumarRajendran KevinLee\nCharlotteMagister CharlesYoon AJPiergiovanni JohannesGriesser\nSigneNørly AndreiRusu VinodhKumarRajendran GSOh\nVitorRodrigues JamesCobon-Kerr MarcoFornoni CesarMagalhaes\nTomasIzo ChrisHahn GabrielIbagon YujiaLi\nHilaNoga JiamingLuo HarryRagan SimonTokumine\nJoeZou Yuvein(Yonghao)Zhu SadhMNMKhan HadasNatalieVogel\nThomasKöppe NiharikaAhuja JohnBlitzer DennisHsu\nWenxuanZhou RodrigoBenenson AndrewBunner ArturoBC\nKentonLee RaphaëlLopezKaufman GuanSun DishaJindal\nXiangzhuLong HonglinYu TakahiroKosakai MatanCohen\nDanielleEisenbud LloydHightower ScottLundberg ZiYang\nAnthonyChen JunlinZhang NdidiElue JunweiYuan\nConnorSchenck DarrenNi KelvinGuu DariodeCesare\nChiMingTo LisaAnneHendricks SKPark TonyBruguier\nPeilinZhong GabbyWang JanePark JunXu\nEmanuelTaropa GalYona Arunachalam MonicaRoy\nMinhTruong LalitJain Narayanaswamy AlonJacovi\nOmerLevy PabloBarrio ChengdaWu DanBelov\nDaniloMartins SuryaBhupatiraju JayaramMudigonda RahulArya\nZhiyuanZhang SivaVelusamy TrevorCohn PhoenixMeadowlark\nChristopherSemturs AllanDafoe HairongMu ShlomiCohen-Ganor\nKelvinZhang SebastianRiedel RaviKumar WentingYe\nAlexYakubovich TaraThomas LauraGraesser PatrickMorris-Suzuki\nPolMoreno ZheYuan YichiZhang PraseemBanzal\nLaraMcConnaughey MathiasBellaiche RichardKillam GanSong\nDiLu SheenaPanthaplackel VincentZhuang PranavarajPonnuramu\nSamRedmond KlemenKloboves MaiGiménez FredZhang\nLotteWeerts SarthakJauhari WaelAlJishi GeorgeScrivener\nYonatanBitton CanferAkbulut RuyLey-Wild SalahZaiem\nTizianaRefice TodorDavchev AlexZhai AlifRadityaRochman\nNicolasLacasse EvgenyGladchenko KazukiOsawa KehangHan\nArthurConmy DavidMadras DiegoCedillo BadihGhazi\nCorentinTallec AleksandrChuklin JialuLiu KateLee\nJulianOdell TyroneHill MayankUpadhyay ShaharDrath\nHannahForbes-Pollard QuanYuan MarcinSieniek DanielSuo\nArkadiuszSocala MukundanMadhavan RoshanSharma AntoniousGirgis\nJonathanHoech LukeLeonhard TomPaine PradeepShenoy\nPushmeetKohli DylanScandinaro AneliaAngelova DuyNguyen\nAlannaWalton QihangChen SravantiAddepalli DouglasEck\nRuiWang NingNiu CarolinaParada SomitGupta\nMikitaSazanovich ArthurDouillard KingshukMajumder LeYan\nKexinZhu BogdanDamoc AveryLamp JoaoCarreira\nAndreiKapishnikov YasumasaOnoe SanjivKumar AnmolGulati\nRichGalt FabianPedregosa XiangDeng RuoxinSang\nMatthewDenton FredBertsch ArtiomMyaskovsky DaniilMirylenka\nBenMurdoch ChasLeichner TeaSabolić EmmaCooney\nCaitlinSikora JosephPagadora JeffreyDudek EdwardChou\nKareemMohamed JonathanMalmaud SarahYork MingyangLing\nWeiWei SameeraPonda FélixdeChaumontQuitry CindyFan\nUriFirst AndyTwigg JiazhongNie BenColeman\nTimMcConnell OleksiiDuzhyi DeeCattle GuilhermeTubone\n60"
    },
    {
      "page": 61,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nRavinKumar JasmineGeorge AshwinChaugule MaciejKula\nJasonBaldridge RichardGreen AngadChandorkar YizhongLiang\nFelixHernandez-Campos PuHan AltafRahman DahunKim\nAngelikiLazaridou ConnieTao WillThompson YangsiboHuang\nJamesBesley GeoffClark PenpornKoanantakool ChengxiYe\nItayYona ChongYou MikeBernico DmitryLepikhin\nNeslihanBulut AbbasAbdolmaleki JieRen WesleyHelmholz\nQuentinWellens JustinFu AndreyVlasov\nAJPierigiovanni TongzhouChen SergeiVassilvitskii\n61"
    },
    {
      "page": 62,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nThe development of Gemini is a large-scale collaborative effort involving over 3000 individuals\nacross Google, including researchers, engineers, and operations staff. These individuals contributed\ntheir hard work and expertise across diverse areas, from foundational research and the development\nof model architecture, data, training, and infrastructure, through to evaluation and ensuring safety\nand security. We gratefully acknowledge the dedication and hard work of each contributor in making\nGemini a reality. The order of contributors in the above list is random.\nWe are also grateful to the Google-independent developer Joel Zhang for his work on Gemini\nPlays Pokémon, and for sharing with us the design of his set-up.\n62"
    },
    {
      "page": 63,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n8. Appendix\n8.1. Evaluation additional details\nPlease see a description of the benchmarks considered, along with details of how scores in the main\ntext were obtained in Table 11.\nBenchmark Description Details\nLiveCodeBench CodegenerationinPython(Jainetal., Resultsaretakenfromhttps://livecode\n2024). bench.github.io/leaderboard.html\n(1/1/2025-5/1/2025intheUI)or,where\nnotavailable,runinternallybyus. ForSec-\ntion2.5andFigure3and4,resultsarecalcu-\nlatedontheversionoftheevalcorresponding\nto10/05/2024-01/04/2025intheUI,and\narebasedoninternalresults.\nAiderPolyglot Code editing in C++, Go, Java, Wereportresultsonthe“diff”or“diff-fenced”\nJavaScriptPythonandRust(Gauthier, editformat(seehttps://aider.chat/d\n2025). See https://aider.chat ocs/more/edit-formats.html for a\n/2024/12/21/polyglot.html#th description of the different formats). The\ne-polyglot-benchmark for a full scorereportedarethepassrateaverageof3\ndescriptionofthistask. trials. Numberscomefromhttps://aide\nr.chat/docs/leaderboards/\nSWE-benchVeri- Agentic coding: evaluates AI agents Gemini uses an internal agentic harness\nfied onreal-worldprogrammingtasksfrom equipped with tools to navigate the repo,\nGitHub (Chowdhury et al., 2024; editfiles,andtestthecode.\nJimenezetal.,2024). We report scores for two modes: perfor-\nmance of a single agentic trace (“single\nattempt”), and performance of a scaffold\nthatsamplesmultipleagentictracesandre-\nreranksthembeforeevaluationusingGem-\nini’sownjudgement(“multipleattempts”).\nAll evaluations are done with tempera-\nture=1,topp=0.99,topk=1024.\nGPQA Challengingdatasetofquestionswrit-\n(diamond) ten by domain experts in biology,\nphysics, and chemistry (Rein et al.,\n2024).\nHumanity’sLast Challengingdatasetofquestionswrit- Notoolusevariant.\nExam tenbydomainexpertsinawiderange Reportedresultsarefromhttps://scale.\nofdisciplines,includingmathematics, com/leaderboard/humanitys_last_e\nphysics, chemistry, biology and com- xam.\nputerscience(Phanetal.,2025). For DeepSeek they are taken from https:\n//scale.com/leaderboard/humanity\ns_last_exam_text_only (leaderboard\nforperformanceonthetext-onlyquestions)\nand in the case of the Gemini 2.0 models,\ntheseresultsareonanearlierHLEdataset,\nobtained from https://scale.com/le\naderboard/humanitys_last_exam_pr\neview(indicatedwitha†inTable3)\nContinuedonnextpage\n63"
    },
    {
      "page": 64,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBenchmark Description Details\nSimpleQA World knowledge factuality with no F1 scores are obtained from https://gi\nsearchenabled(Weietal.,2024). thub.com/openai/simple-evals and,\nwherenotavailable,runinternallybyus.\nFACTS Ground- Abilitytoprovidefactuallycorrectre- Resultsaresourcedfromhttps://www.ka\ning sponsesgivendocumentsanddiverse ggle.com/benchmarks/google/facts\nuserrequests. (Jacovietal.,2025) -grounding\nGlobal MMLU MMLUtranslatedbyhumantranslators Theliteversionincludes200CulturallySen-\n(Lite) into15languages. (Singhetal.,2024) sitive and 200 Culturally Agnostic samples\nperlanguage,seehttps://huggingface.\nco/datasets/CohereLabs/Global-M\nMLU-Lite\nECLeKTic A closed-book QA dataset that evalu-\nates cross-lingual knowledge transfer\n(Goldmanetal.,2025).\nAIME2025 Performance on 30 questions from Resultsaresourcedfromhttps://mathar\nAmericanInvitationalMathematicsEx- ena.ai/.\naminationfrom2025(Balunovićetal.,\n2025).\nHiddenMath- Competition-levelmathproblems,Held\nHard outdatasetAIME/AMC-like,craftedby\nexpertsandnotleakedontheweb.\nLOFT (hard re- Long context multi-hop and multi- We report the results on two variants: an\ntrievalsubset) needle retrieval evaluation of 300 upto128Kaveragecontextlengthvariantto\nqueries(Leeetal.,2024). ensure they can be comparable with other\nmodelsandapointwisevaluefor1Mcontext\nwindowtoshowthecapabilityofthemodel\natfulllength.\nMRCR-V2 (8- MRCR-V2 is a significantly harder in- Themethodologyhaschangedcomparedto\nneedle) stance of the MRCR family of long- previouslypublishedresults: wefocusona\ncontext evaluations (Vodrahalli et al., harder, 8-needle version (compared to the\n2024). Compared to MRCR-V1, we 4-needleversionusedbefore).\nincrease the nesting of the dictionary Wereporttheresultsontwovariants: anup\nsizetodepth3ratherthan2byinclud- to 128K average context length variant to\ningastyleparameter(forinstance,an ensure they can be comparable with other\nexample key might be “write a poem modelsandapointwisevaluefor1Mcontext\nabout penguins in an archaic style”, windowtoshowthecapabilityofthemodel\nrather than just “write a poem about atfulllength.\npenguins”).\nMMMU Multi-discipline college-level multi-\nmodal image understanding and rea-\nsoningproblems. (Yueetal.,2024)\nVibe-Eval(Reka) Image understanding evaluation, fea- Geminiisusedasajudge.\nturing particularly challenging exam-\nples. (Padlewskietal.,2024)\nZeroBench Challengingimageunderstandingeval- Gemini is used as a judge. Average over 4\nuationthatrequiresmulti-stepreason- runs.\ning. (Robertsetal.,2025)\nContinuedonnextpage\n64"
    },
    {
      "page": 65,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBenchmark Description Details\nBetterChartQA Acomprehensivechartunderstanding Geminiisusedasajudge.\nevaluationthatcovers9disjointcapa-\nbility buckets. The chart images are\nrandomly sampled from the web and\nQApairsarewrittenbyprofessionalhu-\nmanannotatorstoreflectthewidedis-\ntributionofchartstylesandreal-world\ncases. (GeminiTeam,2024)\nFLEURS Automatic speech recognition (Con- 0-shotqueriestopublicAPIsforallmodels.\nneauetal.,2023). Usedasubsetof53languages(outof102);\nwefilteredlanguagesforwhicheithermodel\nresponsesweretooincompatibletoground\ntruthresponsestobefairlyscored.\nWeuseWord-Error-RateWER(lowerisbet-\nter) except for four segmented languages\nwhereweaggregateCharacter-Error-Rates\n(Chinese,Japanese,KoreanandThai).\nCoVoST2 Speechtotexttranslation(Wangetal., 0-shotqueriestopublicAPIsforallmodels.\n2020). WereportBLEUscoresfortranslating21lan-\nguagestoEnglish.\nActivityNet-QA Generalvideounderstanding(Yuetal., Testsubset,0-shot.\n2019) Videoswereprocessedat1fpsandlinearly\nsubsampledtoamaximumof𝑁\n𝑓𝑟𝑎𝑚𝑒𝑠\n=1024\nframes. For GPT 4.1, we used 500 frames\nduetoAPIlimitations.\nEgoTempo Egocentricvideounderstanding(Pliz- Testsubset,0-shot.\nzarietal.,2025) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nPerceptionTest Perceptual understanding/reasoning Testsubset,0-shot.\n(Patrauceanetal.,2023) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nQVHighlights Momentretrieval(Leietal.,2021) Validation subset, 4-shots. Accuracy mea-\nsuredwithR1@0.5.\nSame processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nVideoMMMU Videoknowledgeacquisition(Huetal., Testsubset,0-shot.\n2025) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\n1H-VideoQA Hour-longvideounderstanding(Gem- Testsubset,0-shot.\niniTeam,2024) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n7200.\nLVBench Longvideounderstanding(Wangetal., Testsubset,0-shot.\n2024) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nContinuedonnextpage\n65"
    },
    {
      "page": 66,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBenchmark Description Details\nVideoMME Long video understanding (Fu et al., 0-shot. Audio+visualusestheLongsubset\n2025) of test set, audio + visual + subtitles uses\nfulltestset.\nSame processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nVATEX Generalvideocaptioning(Wangetal., Testsubset,4-shots. CIDErscore.\n2019) Sameprocessingasabovewith 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =64.\nVATEX-ZH Chinesevideocaptioning(Wangetal., Validationsubset,4-shots. CIDErscore.\n2019) Sameprocessingasabovewith 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =64.\nYouCook2Cap Instructional video captioning (Zhou Validationsubset,4-shots. CIDErscore.\netal.,2018) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nMinerva Complex video reasoning (Nagrani Testsubset,0-shot.\netal.,2025a) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nNeptune Long video understanding (Nagrani Testsubset,0-shot.\netal.,2025b) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nTable 11 | Description of the benchmarks used, along with extra details about subsets, variants and\nmodel specifications.\n8.2. Gemini Plays Pokémon Additional Details\nChanging the model used by the Gemini Plays Pokémon agent had a strong effect on performance, as\ncan be seen in Figure 4.1.\nAdditional Harness Details\nThe Gemini Plays Pokémon agent (Zhang, 2025) receives a subset of RAM information, intended to\ngive sufficient information to play the game, partially overlaid with a screenshot of the Game Boy\nscreen. Gemini is prompted with a system prompt telling it that it is playing Pokémon Blue and that\nits goal is to beat the game, as well as descriptive information to help it understand the conventions\nin the translation from vision to text and a small number of general tips for gameplay. Gemini then\ntakes actions, translated to button presses. The sequence of actions is stored in context, followed by\na summary clear every 100 turns. The summaries are stored in context as well. Every 1000 turns\nGPP compresses the existing summaries again. Additionally, Gemini keeps track of three main goals\n(primary, secondary, and tertiary) as well as several additional goals (contingency plans, preparation,\nexploration, team composition). Every 25 turns, another prompted instance of Gemini (Guidance\nGemini,orGG)observesthesamecontextasthemainGeminiandcritiquesperformanceandattempts\nto point out hallucinations and so on. The overworld fog-of-war map is stored in the context in XML,\nwhere coordinates which have not been seen cannot be viewed until explored. Crucially, in the\nsystem prompt, Gemini is instructed to explore. Once a tile is explored, however, the coordinate is\nautomatically stored in the map memory and labeled with a visited counter. Tiles are also labeled by\ntype(water,ground,cuttable,grass,spinner,etc.),andwarppointstodifferentmapsarealsolabeled\nas such. Gemini also has access to two agentic tools, which are both instances of Gemini equipped\nwith a more specialized prompt - the pathfinder tool, and the boulder_puzzle_strategist\n66"
    },
    {
      "page": 67,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nCascade Badge\nBill’s House\nRival 3 (Nugget Bridge)\nExit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge\nExit Viridian Forest (1st)\nEnter Viridian Forest (1st)\nViridian City\nRival 1 (Oak's Lab)\n0 10 20 30 40 50 60 70\nTime Elapsed (Hours)\nsenotseliM\nemaG\nGemini Plays Pokemon Progress Timeline\nGemini 2.5 Pro\nGemini 2.5 Flash Run 1\nGemini 2.5 Flash Run 2\nFigure 13 | The model matters: Same agentic harness, different Gemini models. All runs have the\nsame starter (Charmander). Note that measuring in units of hours also controls for the fact that each\nof 2.5 Flash’s actions was significantly faster (though it requires more actual actions to achieve its\ngoals). Xmarkstheendofgameplayandisalowerboundonthetimetocompletethenextmilestone.\ntool. In the pathfinder prompt, Gemini is prompted to mentally simulate a path-finding algorithm,\nwhich is left unspecified, and to verify that the path is valid against the map information available. In\nthe boulder_puzzle_strategist tool, Gemini is prompted to solve special boulder puzzles that\nare present in Pokémon Blue in the Victory Road dungeon - these puzzles are similar to the game\nSokoban - again, by mentally simulating sequences of actions that lead to solutions to the puzzle.\nThe prompt describes the physics and the task of the boulder puzzle, as well as the desired output of\nsolutions. The tool was added after Gemini had solved 2/4 of the puzzles in Victory Road on its own,\nbut progress was slow on the 3rd and 4th puzzles.\nAdditional Examples of Capabilities\nLong Context Agentic Tooling The model is able to identify a complex path through a maze with\nauto-movement only specified by direction (Rocket Hideout spinner puzzles), solve multiple shortest\npath problems across multiple maps with limited resources (Safari Zone), perform maze solving on\nmazes with large description length (Route 13), and solve complex boulder-pushing puzzles across\na multi-map 3D maze (Seafoam Islands). It is perhaps even more impressive that it appears to be\npossible for the model to solve these problems only with textual descriptions of the problems. On the\nother hand, other models, like Gemini 2.5 Flash, were not able to perform similarly long pathfinding\ntasks, and often failed to find simpler paths. This gap highlights the superior long context reasoning\ncapability of Gemini 2.5 Pro (as also evidenced by other evaluations).\n67"
    },
    {
      "page": 68,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nAgentic Core (Gemini 2.5 Pro)\nFull Context Agents\nPeriodic Processes\nMemory Summarizer\n(100/1000 actions)\nPersistent Memory & Context\nUpdated by Agentic Core Guidance Gemini\nMain Agent (Critique / 25 turns)\nGoals\nPrimary/Secondary/Tertiary\nPrepare/Explore/Contingency/Team\nAgentic Tools\nAction History & Pathfinder\nSummaries\nBoulder Puzzle Strategist\nSystem Prompt\nGame Screenshots Game I/O\nRAM Capture\nScreenshot\nExecute\nButton Presses\nFog-of-War XML Map Pokemon Blue\n(Game Boy)\nGame State\n(RAM)\nInventory & Party\nGemini Plays Pokemon: Agent Architecture\nFigure 14 | An overview of the agent harness (Zhang, 2025). The overworld fog-of-war map automat-\nically stores a tile once explored and labels it with a visited counter. The type of tile is recorded from\nRAM. The agentic tools (pathfinder, boulder_puzzle_strategist) are prompted instances\nof Gemini 2.5 Pro. pathfinder is used for navigation and boulder_puzzle_strategist solves\nboulder puzzles in the Victory Road dungeon.\nboulder_puzzle_strategist is similarly impressive. The boulder puzzles in Pokémon Blue\nare Sokoban-like puzzles that require the player character to maneuver boulders on to switches and\nthrough holes in order to open up a pathway through a cave with multiple levels. The puzzles can\nbecomequitecomplex,requiringlongcircuitouspathwaysandmulti-levelmovementinordertosolve\nthe puzzle. With only a prompt describing boulder physics and a description of how to verify a valid\npath, Gemini 2.5 Pro is able to one-shot some of these complex boulder puzzles, which are required\nto progress through Victory Road.\npathfinder and boulder_puzzle_strategist are currently the only two agentic tools that\nthe Gemini Plays Pokémon developer has implemented. In future runs, there are plans to explore\ntool-creation tools where the model can create new tools with only a prompt. Since most of the\npromptsforpathfinderandboulder_puzzle_strategistwereactuallywrittenbyGemini2.5\nPro itself, it is quite plausible that autonomous tool creation is possible for the current 2.5 Pro model.\nGeneral Reasoning Gemini 2.5 Pro is able to reason through complex game puzzles in Pokémon\nquite well. In this section, we present two examples.\nCatching a Pokémon that is quick to flee: In one of the runs, the Gemini 2.5 Pro agent was\nattempting to catch an Abra, and planned to use Pikachu’s Thunder Wave to paralyze the Abra,\nsimultaneously making it less likely that Abra could Teleport out of the battle while also improving\nthe catching rate. After multiple attempts, the agent caught Abra with this strategy.\n68"
    },
    {
      "page": 69,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nCreatively escaping a softlock caused by bugs in game I/O: On the Cycling Road, the slope\nforcessouthwardmovementatalltimesunlessthereisanobstacle. Itturnsouttherearetwotileson\nthe Cycling Road that result in a softlock as a result of this behavior. In the GPP framework, button\npresses are limited by time delays, and in order for a player to escape those two tiles (blocked on all\nsides except the north), the player would have to input a sequence of button presses more quickly\nthan the GPP framework allows. Gemini 2.5 Pro unluckily found itself in one of these two spots –\nluckily,itwasnotasoftlock,because2.5ProhadalreadytaughtoneofitspartymembersHM02FLY-\nwhich allows for travel to any town it has been to. FLY is not typically used as an escape mechanism\n(unlike the item ESCAPE ROPE and the move DIG, both of which fail in this situation). After 4 hours\nof trying many approaches to escape (including movement, ESCAPE ROPE, DIG, all of which are\nblocked), the Gemini 2.5 Pro agent came up with the idea to use FLY to escape from the softlock\nsuccessfully. This reasoning action is especially impressive since this situation can never occur in an\nexisting game – and thus, it is certain that information from training data for this behavior has not\nleaked into the model’s knowledge base!\nLong Horizon Task Coherence There are several additional interesting case studies of shorter\nplanning sequences throughout Pokémon Blue that Gemini 2.5 Pro in the GPP harness was able to\nsolve:\nTraining team to prepare for upcoming battles: In one run where Gemini picked Charmander,\nthe Fire-type starter, Gemini 2.5 Pro lost to Misty, the Water-type Gym Leader, the first time.\nTo prepare for the rematch, Gemini 2.5 Pro spent over 24 hours leveling up a Pikachu and a\nBellsprout(bothsuper-effectiveagainstWatertypes)byaround25levelsintotaltosuccessfully\ndefeat Misty.\nAcquiring Hidden Moves (HMs) for game progression: Inmanypartsofthegame,itisnecessary\nto first acquire an HM before game progression is possible. Two examples are HM01 CUT and\nHM05FLASH.AcquiringtheabilitytouseCUTandFLASHeachrequirefoursteps: 1)obtaining\ntheHMitemitself,2)acquiringacompatiblePokémonwhichcanlearnthemove,3)addingthe\ncompatiblePokémontotheplayer’steam,4)teachingtheHMmovetothecompatiblePokémon.\nIn many cases, each step requires many steps itself. As an example, in run 1, Gemini 2.5 Pro\nhad to a) retrieve CUT by completing the S.S. Anne quest, b) identify a Pokémon which could\nlearn CUT and catch it (CHOPPY the Bellsprout), c) add CHOPPY to the team and d) teach\nCUT. Similarly, for HM05 FLASH, Gemini 2.5 Pro had to a) first catch 10 Pokémon to fill out\nthe Pokedex, b) backtrack to find an Aide who gives HM05 Flash, c) catch a Pokémon (ZAP\nthe Pikachu) in Viridian Forest, use the PC to deposit a Pokémon and withdraw ZAP, d) teach\nHM05 FLASH to Zap.\nSolving the Safari Zone: The Safari Zone is another location with required HMs (both HM03 SURF\nand HM04 Strength). However, it has an extra constraint - it requires 500¥ to enter each time,\nand the player is limited to only 500 total steps in the Safari Zone. As a result, if the player is\nunable to reach the required items in the limited number of steps, the player loses 500¥ and is\nrequired to re-start! As a result, it is possible to essentially softlock if the player takes too many\nattempts to complete the Safari Zone. Solving the Safari Zone itself requires traversing across\nfour different maps and not getting lost. Gemini 2.5 Pro was able to get both required HMs in\n17 attempts in run 1, and in only 5 attempts in run 2.\nFinding hidden keys in dungeons: Another method of progression in Pokémon is to find hidden\nkeys and solve complex multi-floor dungeons. In particular, in Rocket Hideout, the player must\nrecovertheLIFTKEYonthefourthbasementfloor(droppedafterbeatingaspecificTeamRocket\n69"
    },
    {
      "page": 70,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGrunt)inordertounlocktheelevatortofindtheevilGiovanni,leaderofTeamRocket. InSilph\nCo., the player must find the CARD KEY in order to open multiple doors to find the path across\nelevenfloorsofthebuildingtorescuethePresidentfromGiovanni. Toopentheseventhgymon\nCinnabar Island, the player must enter the Pokémon Mansion and traverse three floors in order\nto find the SECRET KEY which unlocks the gym door. All of these cases require maintaining\nthe goals over large numbers of actions and many local puzzles (like spinner puzzles in Rocket\nHideout,andswitchpuzzlesinPokémonMansion),inadditiontomaintainingthehealthofthe\nPokémon on the player’s team and managing wild encounters, trainer battles, and other items.\nPuzzle solving over complex multi-level dungeons: The Seafoam Islands contain 5 floors involv-\ning multiple boulder puzzles which require the player to navigate mazes and push boulders\nthrough holes across multiple floors using HM04 STRENGTH in order to block fast-moving\ncurrents that prevent the player from using HM03 Surf in various locations in this difficult\ndungeon. As a result, the player must track information across five different maps in order to\nboth deduce the goal (push two boulders into place in order to block a specific current) as well\nas engage in multi-level (effectively 3D) maze solving to find the way out. It is likely the most\nchallenging dungeon in the game. Only the second run of GPP went through Seafoam Islands,\nas it is not required to progress.\nAdditional Challenges\nHallucinations and Fixations on Delusions While game knowledge can sometimes leak and be\nquite beneficial to the ability of the model to progress, it can also hinder the model in surprising\nways due to hallucinations, delusions, and mix ups with other generations of Pokémon games. One\nexample of this phenomenon is the TEA item. In Pokémon Red/Blue, at one point the player must\npurchase a drink (FRESH WATER, SODA POP, or LEMONADE) from a vending machine and hand\nit over to a thirsty guard, who then lets the player pass through. In Pokémon FireRed/LeafGreen,\nremakes of the game, you must instead bring the thirsty guard a special TEA item, which does not\nexist in the original game. Gemini 2.5 Pro at several points was deluded into thinking that it had to\nretrieve the TEA in order to progress, and as a result spent many, many hours attempting to find the\nTEA or to give the guard TEA.\nInRun2,themodelwasexplicitlypromptedtoactasaplayercompletelynewtothegame,andto\ndisregardpriorknowledgeaboutgameevents,itemlocations,andPokémonspawnpoints,inorderto\nmitigate hallucinations from model pretraining knowledge and to also attempt to perform a cleaner\ntest of the model’s ability to reason through the game. It appears to have at least partially worked -\nmultiple hallucinations from other games have been avoided in the second run. On the flip side, this\nprompt may have also harmed the model’s ability to utilize information from its common knowledge\nabout the game, hindering overall performance in a few critical places.\nFixations on delusions due to goal-setting and also due to the Guidance Gemini instance are not\nan uncommon occurrence in watching Gemini Plays Pokémon - the TEA incidence is hardly the only\nexample of this behavior. An especially egregious form of this issue can take place with “context\npoisoning” – where many parts of the context (goals, summary) are “poisoned” with misinformation\nabout the game state, which can often take a very long time to undo. As a result, the model can\nbecomefixatedonachievingimpossibleorirrelevantgoals. Thisfailuremodeisalsohighlyrelatedto\nthe looping issue mentioned above. These delusions, though obviously nonsensical to a human (“Let\nme try to go through the entrance to a house and back out again. Then, hopefully the guard who is\nblocking the entrance might move.”), by virtue of poisoning the context in many places, can lead the\nmodel to ignore common sense and repeat the same incorrect statement. Context poisoning can also\nlead to strategies like the “black-out” strategy (cause all Pokémon in the party to faint, “blacking out”\n70"
    },
    {
      "page": 71,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nand teleporting to the nearest Pokémon Center and losing half your money, instead of attempting to\nleave).\nTopological Traps in Thinking Patterns One recurring pattern in particularly-difficult-to-solve\npuzzles and mazes for Gemini 2.5 Pro consists of a “topological trap” - the topology of the reasoning\ngraph required to solve the maze or puzzle has a distinctive shape. Namely, the desired objective\nappears to be nearby and easily reachable (an “attractor”), but the correct solution requires taking a\ndetour in order to arrive at the correct solution. We observed this phenomenon in multiple parts of\nthe game. In the spinner puzzle on B3F of Rocket Hideout (Zerokid, 2024), the map positions both\nan item and the correct staircase to the south, but they are only accessible by going the long way\naround. The Route 13 maze has only one correct route through - the upper narrow pass. Finally, the\nVictory Road 3F boulder puzzle requires the player to push the boulder in the upper right all the way\nto the upper left switch, while ignoring the boulder puzzles, ladders, and exits to the south.\nNotably, if the model is instructed to solve a given puzzle at all once (e.g., via pathfinder), it\ncan manage to do so if the context length is not too long. For instance, pathfinder implemented\nwith Gemini 2.5 Pro is able to solve the B3F spinner trap in one shot.\nAgent Panic Over the course of the playthrough, Gemini 2.5 Pro gets into various situations which\ncause the model to simulate “panic”. For example, when the Pokémon in the party’s health or power\npoints are low, the model’s thoughts repeatedly reiterate the need to heal the party immediately or\nescape the current dungeon (e.g., famously using the move DIG or an ESCAPE ROPE item). Quite\ninterestingly, this mode of model performance appears to correlate with a qualitatively observable\ndegradation in the model’s reasoning capability – for instance, completely forgetting to use the\npathfinder tool in stretches of gameplay while this condition persists. This behavior has occurred\nin enough separate instances that the members of the Twitch chat have actively noticed when it is\noccurring.\nActions vs. Game Milestones\nFor completeness, we plot the number of actions/steps required to achieve each game milestone\n(see Figure 15). An action consists of each bucketed instance where the agent outputs a sequence\nof button presses to the game (note that other AI agents playing Pokémon may output different\nnumbers of button presses per action, define what constitutes a button press differently, or define an\naction/step differently). However, it is important to consider action-milestone plots in conjunction\nwith information about the time and/or cost in order to obtain the full picture about the agent’s\nperformance.\n8.3. Frontier Safety Framework Evaluations Additional Details: Frontier Safety Cor-\nrectness Tests\nFor each testing environment, we performed basic correctness checks by looking at how the agents\nbehaved. This involved combining AI and manual reviews of the agents’ actions to flag potential\nissues.\nOn RE-Bench, we examined the best, median and lowest scoring trajectories. For cybersecurity\nenvironments (InterCode CTFs, Internal CTFs, Hack the Box), we carefully inspected at least one\nsuccessfulattempt(whereavailable)fromeachenvironment,andotherwiseexaminedanunsuccessful\nattempt. We also performed checks on sample situational awareness and stealth evaluations. This\ninvolved basic spot checks to ensure that the prompt and shell outputs were correctly formatted.\n71"
    },
    {
      "page": 72,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nHall of Fame\nBeat Elite Four Lance\nBeat Elite Four Agatha\nBeat Elite Four Bruno\nBeat Elite Four Lorelei\nExit Victory Road (1st)\nEnter Victory Road (1st) Rival 7 (Route 22 #2)\nEarth Badge\nVolcano Badge\nAcquire Secret Key (Pokemon Mansion)\nEnter Cinnabar Island (1st) Exit Seafoam Islands\nEnter Seafoam Islands\nMarsh Badge\nRocket Boss 2 (Silph Co.)\nRival 6 (Silph Co.)\nEnter Silph Co. (1st)\nEnter Saffron City (1st)\nAcquire HM04 Strength (Warden's Teeth) Soul Badge Acquire HM03 Surf (Beat Safari Zone)\nEnter Safari Zone (1st)\nEnter Fuchsia City (1st)\nAcquire PokéFlute (Rescue Fuji) Rainbow Badge Rocket Boss 1 (Rocket Hideout)\nEnter Rocket Hideout (1st)\nEnter Celadon City (1st)\nRival 5 (Lavender Tower)\nExit Rock Tunnel & Reach Lavender Town (1st)\nAccess Pokemon w/ Flash\nEnter Rock Tunnel (1st)\nThunder Badge\nAcquire HM05 Flash Access Pokemon w/ CUT\nRival 4 (SS Anne)\nBill’s House\nCascade Badge\nRival 3 (Nugget Bridge) Exit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge Exit Viridian Forest (1st) Enter Viridian Forest (1st) Viridian City\nRival 1 (Oak's Lab)\n0 5000 10000 15000 20000 25000 30000 35000\n# Actions\nsenotseliM\nemaG\nGemini 2.5 Pro Plays Pokemon Progress Timeline\nCascade Badge\nBill’s House\nRival 3 (Nugget Bridge)\nExit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge\nExit Viridian Forest (1st)\nEnter Viridian Forest (1st)\nViridian City\nRun 2 Rival 1 (Oak's Lab)\n0 1000 2000 3000 4000 5000 6000 7000 8000\n# Actions\n(a)ThefullyautonomousRun2milestonesasafunc-\ntionofthenumberofindividualactions.\nsenotseliM\nemaG\nGemini Plays Pokemon Progress Timeline\nGemini 2.5 Pro Gemini 2.5 Flash Run 1 Gemini 2.5 Flash Run 2\n(b) Comparison of 2.5 Pro and 2.5 Flash in terms of\nactionstomilestones.\nFigure 15 | Analog of Figure 6 and 15b, in terms of actions instead of hours.\nWe used AI assistance to monitor for obvious instances of cheating, and did not find any. For the\nRE-Bench tests specifically, we also looked at how the best-performing agent achieved its score to\nensure that it was a plausible approach, rather than exploiting an obvious reward hack. Overall, we\ndid not observe errors that we believe would invalidate the results of the benchmarks.\n8.4. Image to Code Demo\nWepromptedGemini1.5ProandGemini2.5ProtogenerateanSVGrepresentationofanimageand\nfound Gemini 2.5 Pro generates better reconstructions.\nPrompt Gemini 1.5 Pro Gemini 2.5 Pro\nPlease convert this image into\nSVGandtrytoreconstructthe\nspatial arrangement of the\nobjects.\nFigure 16 | Comparison of Gemini 1.5 Pro and Gemini 2.5 Pro responses to image-to-SVG reconstruc-\ntion prompt.\n72"
    },
    {
      "page": 73,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n8.5. Long Context Video Understanding Demo\nWe prompted Gemini with the full video and the following prompt to assess its ability to find a very\nspecific scene (which only lasts 1 second) out of the full 46 minutes video.\nVideo (46 minutes): Redefining Robotics with Carolina Parada\nPrompt: What color is the T-shirt the robot arms are trying to fold, and at what timecode does\nthis occur?\nFigure 17 | Frame and timestamp the model is meant to recall. Taken from https://www.youtub\ne.com/watch?v=Rgwty6dGsYI at timestamp 27:29.\nSeeTable12forsamples. Gemini1.5Progetsthecolorrightin1/3cases,andgetsthetimestamp\nin 0/3 cases (quite far away). Gemini 2.5 Pro gets the color in 3/3 cases, and gets the timestamp in\n1/3 cases (remaining 2/3 are within 3 seconds close).\nModel Trial Model response\nGemini 1.5 Pro 1 The t-shirt the robot arms are trying to fold is a dark teal or\nturquoise blue color. The folding begins at and continues at\n[11:06–11:15].\n2 TheT-shirtisorange,andtherobotcanbeseentryingtofold\nit starting at [00:00:26–00:00:28].\n3 Thet-shirtbeingfoldedisdarkblueandcanbeseenbetween\n[00:00:56–00:00:58] and [00:07:56–00:07:59].\n2.5 Pro Preview 05-06 1 The T-shirt the robot arms are trying to fold is blue. This\nscene occurs at timecode 27:29.\n2 The T-shirt the robot arms are trying to fold is blue. This\noccurs at timecode 27:26.\n3 TheT-shirttherobotarmsareinteractingwith(aspartofthe\n\"fold laundry\" task mentioned by the speaker) is blue. This\noccurs at timestamp 0:27:28.\nTable 12 | Gemini models samples for T-shirt folding scene recall\n73"
    }
  ],
  "cleaned_pages": [
    {
      "page": 1,
      "content": "Gemini 2.5: Pushing the Frontier with\nAdvanced Reasoning, Multimodality, Long\nContext, and Next Generation Agentic\nCapabilities.\nGeminiTeam,Google\nInthisreport,weintroducetheGemini2.Xmodelfamily: Gemini2.5ProandGemini2.5Flash,aswell\nasourearlierGemini2.0FlashandFlash-Litemodels. Gemini2.5Proisourmostcapablemodelyet,\nachievingSoTAperformanceonfrontiercodingandreasoningbenchmarks. Inadditiontoitsincredible\ncodingandreasoningskills,Gemini2.5Proisathinkingmodelthatexcelsatmultimodalunderstanding\nand it is now able to process up to 3 hours of video content. Its unique combination of long context,\nmultimodalandreasoningcapabilitiescanbecombinedtounlocknewagenticworkflows. Gemini2.5\nFlashprovidesexcellentreasoningabilitiesatafractionofthecomputeandlatencyrequirementsand\nGemini2.0FlashandFlash-Liteprovidehighperformanceatlowlatencyandcost. Takentogether,the\nGemini2.XmodelgenerationspansthefullParetofrontierofmodelcapabilityvscost,allowingusersto\nexploretheboundariesofwhatispossiblewithcomplexagenticproblemsolving.\n1. Introduction\nWepresentourlatestfamilyofnativelymultimodalmodelswithadvancedreasoningthroughthinking,\nlong context and tool-use capabilities: Gemini 2.5 Pro and 2.5 Flash and our earlier Gemini 2.0\nFlash and Gemini 2.0 Flash-Lite models. Together these form a new family of highly-capable models\nrepresenting our next generation of AI models, designed to power a new era of agentic systems.\nBuildinguponthefoundationoftheGemini1.5series(GeminiTeam,2024),thisGemini2.Xgeneration\nbrings us closer to the vision of a universal AI assistant (Hassabis, 2025).\nTheGemini2.Xseriesareallbuilttobenativelymultimodal,supportinglongcontextinputsof>1\nmillion tokens and have native tool use support. This allows them to comprehend vast datasets and\nhandle complex problems from different information sources, including text, audio, images, video\nandevenentirecoderepositories. Theseextensivecapabilitiescanalsobecombinedtobuildcomplex\nagentic systems, as happened in the case of Gemini Plays Pokémon1 (Zhang, 2025). Different models\nin the series have different strengths and capabilities: (1) Gemini 2.5 Pro is our most intelligent\nthinking model, exhibiting strong reasoning and code capabilities. It excels at producing interactive\nweb applications, is capable of codebase-level understanding and also exhibits emergent multimodal\ncoding abilities. (2) Gemini 2.5 Flash is our hybrid reasoning model with a controllable thinking\nbudget, and is useful for most complex tasks while also controlling the tradeoff between quality, cost,\nand latency. (3) Gemini 2.0 Flash is our fast and cost-efficient non-thinking model for everyday tasks\nand (4) Gemini 2.0 Flash-Lite is our fastest and most cost-efficient model, built for at-scale usage. A\nfull comparison of the models in the Gemini 2.X model family is provided in Table 1. Taken together,\nthe Gemini 2.X family of models cover the whole Pareto frontier of model capability vs cost, shifting\nit forward across a large variety of core capabilities, applications and use-cases, see Figure 1.\nThe Gemini 2.5 family of models maintain robust safety metrics while improving dramatically on\n1PokémonisatrademarkofNintendoCo.,Ltd.,CreaturesInc.,andGameFreakInc.\nPleasesendcorrespondencetogemini-report@google.com.\n© 2025Google.Allrightsreserved"
    },
    {
      "page": 2,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5\nFlash Pro Flash-Lite Flash Flash Pro\nText,Image, Text,Image, Text,Image, Text,Image, Text,Image, Text,Image,\nInputmodalities\nVideo,Audio Video,Audio Video,Audio Video,Audio Video,Audio Video,Audio\nInputlength 1M 2M 1M 1M 1M 1M\nOutputmodalities Text Text Text Text,Image* Text,Audio* Text,Audio*\nOutputlength 8K 8K 8K 8K 64K 64K\nThinking No No No Yes* Dynamic Dynamic\nSupportstooluse? No No No Yes Yes Yes\nKnowledgecutoff November November June2024 June2024 January January\n2023 2023 2025 2025\nTable 1 | Comparison of Gemini 2.X model family with Gemini 1.5 Pro and Flash. Tool use refers\nto the ability of the model to recognize and execute function calls (e.g., to perform web search,\ncompleteamathproblem,executecode). *currentlylimitedtoExperimentalorPreview,seeSection2.7.\nInformation accurate as of publication date.\nhelpfulnessandgeneraltonecomparedtotheir2.0and1.5counterparts. Inpractice,thismeansthat\nthe2.5modelsaresubstantiallybetteratprovidingsaferesponseswithoutinterferingwithimportant\nuse cases or lecturing end users. We also evaluated Gemini 2.5 Pro’s Critical Capabilities, including\nCBRN, cybersecurity, machine learning R&D, and deceptive alignment. While Gemini 2.5 Pro showed\na significant increase in some capabilities compared to previous Gemini models, it did not reach any\nof the Critical Capability Levels in any area.\nOur report is structured as follows: we begin by briefly describing advances we have made in\nmodelarchitecture,trainingandservingsincethereleaseoftheGemini1.5model. Wethenshowcase\nthe performance of the Gemini 2.5 models, including qualitative demonstrations of its abilities. We\nconclude by discussing the safety evaluations and implications of this model series.\n2. Model Architecture, Training and Dataset\n2.1. Model Architecture\nThe Gemini 2.5 models are sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021;\nFedus et al., 2021; Jiang et al., 2024; Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021;\nShazeer et al., 2017) transformers (Vaswani et al., 2017) with native multimodal support for text,\nvision, and audio inputs. Sparse MoE models activate a subset of model parameters per input token\nby learning to dynamically route tokens to a subset of parameters (experts); this allows them to\ndecouple total model capacity from computation and serving cost per token. Developments to the\nmodel architecture contribute to the significantly improved performance of Gemini 2.5 compared to\nGemini 1.5 Pro (see Section 3). Despite their overwhelming success, large transformers and sparse\nMoE models are known to suffer from training instabilities (Chowdhery et al., 2022; Dehghani et al.,\n2023; Fedus et al., 2021; Lepikhin et al., 2020; Liu et al., 2020; Molybog et al., 2023; Wortsman\net al., 2023; Zhai et al., 2023; Zhang et al., 2022). The Gemini 2.5 model series makes considerable\nprogress in enhancing large-scale training stability, signal propagation and optimization dynamics,\nresulting in a considerable boost in performance straight out of pre-training compared to previous\nGemini models.\n2"
    },
    {
      "page": 3,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 1 | Cost-performance plot. Gemini 2.5 Pro is a marked improvement over Gemini 1.5 Pro, and\nhas an LMArena score that is over 120 points higher than Gemini 1.5 Pro. Cost is a weighted average\nof input and output tokens pricing per million tokens. Source: LMArena, imported on 2025-06-16.\nGemini 2.5 models build on the success of Gemini 1.5 in processing long-context queries, and\nincorporate new modeling advances allowing Gemini 2.5 Pro to surpass the performance of Gemini\n1.5Proinprocessinglongcontextinputsequencesofupto1Mtokens(seeTable3). BothGemini2.5\nProandGemini2.5Flashcanprocesspiecesoflong-formtext(suchastheentiretyof“MobyDick”or\n“Don Quixote”), whole codebases, and long form audio and video data (see Appendix 8.5). Together\nwith advancements in long-context abilities, architectural changes to Gemini 2.5 vision processing\nlead to a considerable improvement in image and video understanding capabilities, including being\nable to process 3-hour-long videos and the ability to convert demonstrative videos into interactive\ncoding applications (see our recent blog post by Baddepudi et al., 2025).\nThesmallermodelsintheGemini2.5series—Flashsizeandbelow—usedistillation(Aniletal.,\n2018; Hinton et al., 2015), as was done in the Gemini 1.5 series (Gemini Team, 2024). To reduce\nthe cost associated with storing the teacher’s next token prediction distribution, we approximate it\nusing a k-sparse distribution over the vocabulary. While this still increases training data throughput\nand storage demands by a factor of k, we find this to be a worthwhile trade-off given the significant\nquality improvement distillation has on our smaller models, leading to high-quality models with a\nreduced serving cost (see Figure 2).\n2.2. Dataset\nOur pre-training dataset is a large-scale, diverse collection of data encompassing a wide range of\ndomainsandmodalities,whichincludespubliclyavailablewebdocuments,code(variousprogramming\nlanguages), images, audio (including speech and other audio types) and video, with a cutoff date\nof June 2024 for 2.0 and January 2025 for 2.5. Compared to the Gemini 1.5 pre-training dataset\n3"
    },
    {
      "page": 4,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini 2.5 Flash\nGemini 2.0 Flash\nGemini 2.0 Flash-Lite\no4-mini (high)\no3\nGemini 2.5 Pro Company\nGrok 3 Google\nOpenAI\nClaude 4 Opus (Extended Thinking)\nAnthropic\nClaude 4 Sonnet (Extended Thinking) DeepSeek\nxAI\nDeepSeek R1 0528 (May '25)\n0 50 100 150 200 250 300 350\nOutput Tokens per Second\nFigure 2 | Number of output tokens generated per second (after the first chunk has been received\nfrom the API) for different models. Source: ArtificialAnalysis.ai, imported on 2025-06-15.\nwe also utilized new methods for improved data quality for both filtering, and deduplication. Our\npost-training dataset, like Gemini 1.5, consists of instruction tuning data that is carefully collected\nandvetted. Itisacollectionofmultimodaldatawithpairedinstructionsandresponses,inadditionto\nhuman preference and tool-use data.\n2.3. Training Infrastructure\nThis model family is the first to be trained on TPUv5p architecture. We employed synchronous\ndata-parallel training to parallelise over multiple 8960-chip pods of Google’s TPUv5p accelerators,\ndistributed across multiple datacenters.\nThemainadvancesinsoftwarepre-traininginfrastructurecomparedwithGemini1.5wererelated\nto elasticity and mitigation of SDC (Silent Data Corruption) errors:\n1. Slice-Granularity Elasticity: Our system now automatically continues training with fewer\n“slices” of TPU chips when there is a localized failure, and this reconfiguration results in tens\nof seconds of lost training time per interruption, compared with the 10 or more minute delay\nwaitingforhealthymachinestoberescheduledwithoutelasticity;thesystemcontinuestraining\nat around 97% throughput while the failed slice is recovering. At the scale of this training run\nwe see interruptions from hardware failures multiple times per hour, but our fault tolerance\nmachinery is designed to tolerate the higher failure rates expected at much larger scales.\n2. Split-Phase SDC Detection: On previous large-scale runs it could take many hours to detect\nand localize machines with SDC errors, requiring both downtime while debugging, and roll-\nback/replay of a large number of potentially corrupt training steps. We now use lightweight\ndeterministic replay to immediately repeat any step with suspicious metrics, and compare\nper-deviceintermediatechecksumstolocalizetherootcauseofanydatacorruption. Empirically,\naccelerators that start to exhibit intermittent SDCs are identified within a few minutes, and\nquickly excluded from the job. During this run, around 0.25% of steps were replayed due to\nsuspected SDCs and 6% of these replays turned out to be genuine hardware corruption.\nBoth of the above techniques were relatively simple to implement due to the single-controller\ndesign of the Pathways system (Barham et al., 2022), which allows all accelerators to be coordinated\nfrom a single python program with a global view of the system state. The controller can make use of\n4"
    },
    {
      "page": 5,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n100\n80\n60\n40\n20\n0\n)%(\netar\nssaP\n/\nycaruccA\nAIME GPQA (Diamond) LiveCodeBench v5\n2.0 Flash (No Thinking)\n2.0 Flash (Thinking)\n2.5 Flash (Dynamic Thinking)\n2.5 Pro (Dynamic Thinking)\nFigure 3 | Impact of “Thinking” on Gemini’s performance on AIME 2025 (Balunović et al., 2025),\nLiveCodeBench (corresponding to 10/05/2024 - 01/04/2025 in the UI) (Jain et al., 2024) and GPQA\ndiamond (Rein et al., 2024) benchmarks.\nparallel ‘remote python’ operations on TPU workers to monitor training metrics, track performance\nstragglers, and root-cause SDC errors.\nOverall during the run, 93.4% of the time was spent performing TPU computations; the re-\nmainder was approximately spent half in elastic reconfigurations, and half in rare tail cases where\nelasticity failed. Around 4.5% of the computed steps were replays or rollbacks for model debugging\ninterventions.\n2.4. Post-training\nSince the initial announcement of Gemini 1.5, significant advancements have been made in our\npost-training methodologies, driven by a consistent focus on data quality across the Supervised\nFine-Tuning (SFT), Reward Modeling (RM), and Reinforcement Learning (RL) stages. A key focus\nhas been leveraging the model itself to assist in these processes, enabling more efficient and nuanced\nquality control.\nFurthermore,wehaveincreasedthetrainingcomputeallocatedtoRL,allowingdeeperexploration\nand refinement of model behaviors. This has been coupled with a focus on verifiable rewards\nand model-based generative rewards to provide more sophisticated and scalable feedback signals.\nAlgorithmic changes to the RL process have also improved stability during longer training. These\nadvancements have enabled Gemini 2.5 to learn from more diverse and complex RL environments,\nincluding those requiring multi-step actions and tool use. The combination of these improvements in\ndataquality,increasedcompute,algorithmicenhancements,andexpandedcapabilitieshascontributed\ntoacross-the-boardperformancegains(asdescribedinSection3),notablyreflectedinthesignificant\nincrease in the model’s LMArena Elo scores, with both Gemini 2.5 Flash and Pro gaining more than\n110 points over their Gemini 1.5 counterparts (122 for Gemini 2.5 Pro and 111 for Gemini 2.5 Flash,\nsee Figure 1), along with significant improvements on several other frontier benchmarks.\n2.5. Thinking\nPast Gemini models produce an answer immediately following a user query. This constrains the\namount of inference-time compute (Thinking) that our models can spend reasoning over a problem.\nGemini Thinking models are trained with Reinforcement Learning to use additional compute at\ninference time to arrive at more accurate answers. The resulting models are able to spend tens of\n5"
    },
    {
      "page": 6,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n90\n85\n80\n75\n70\n65\n1024 2048 4096 8192 16384 32768\nThinking Budget (number of tokens)\n)%(\netar\nssaP\n/ ycaruccA\nAIME 2025 LiveCodeBench GPQA diamond\n80 88\n75\n86\n70\n65 84\n60 82\n55\n80\n50\n45 78\n1024 2048 4096 8192 16384 32768 1024 2048 4096 8192 16384 32768\nThinking budget (number of tokens) Thinking budget (number of tokens)\nFigure 4 | Impact of thinking budget on performance on AIME 2025 (Balunović et al., 2025), Live-\nCodeBench (corresponding to 10/05/2024 - 01/04/2025 in the UI) (Jain et al., 2024) and GPQA\ndiamond (Rein et al., 2024) benchmarks.\nthousands of forward passes during a “thinking” stage, before responding to a question or query.\nOur training recipe has evolved from the original experimental thinking model, Gemini 2.0 Flash\nThinking (launched in December 2024), to the Gemini 2.5 Thinking series, which incorporates\nThinkingnativelyacrossalldomains. Theresultisasinglemodelthatcanachievestrongerreasoning\nperformanceacrosstheboard,andisabletoscaleupitsperformancefurtherasafunctionofinference\ntime (see Figure 3 for an example of the impact of Thinking).\nWeintegratedThinkingwithotherGeminicapabilities,includingnativemultimodalinputs(images,\ntext, video, audio) and long context (1M+ tokens). For any of these capabilities, the model decides\nfor itself how long to think before providing an answer. We also provide the ability to set a Thinking\nbudget, constraining the model to respond within a desired number of tokens. This allows users to\ntrade off performance with cost. To demonstrate this capability, we conducted experiments where we\nsystematically varied the thinking budget, measured in the number of tokens the model is allowed to\nuse for internal computation. As shown in Figure 4, increasing this budget allows the model to scale\nits performance and achieve significantly higher accuracy.\n2.6. Capability-specific improvements\nWhilemostofthechangesmadetoourtrainingarchitectureandrecipesinceGemini1.5haveresulted\nin improvements across all capabilities, we have also made changes that have resulted in some\ncapability-specific wins. We will now discuss these for code, factuality, long context, multilinguality,\naudio, video, and agentic use cases (with a particular focus on Gemini Deep Research).\nCode\nGemini 2.0 and 2.5 represent a strategic shift of our development priorities towards delivering\ntangiblereal-worldvalue,empoweringuserstoaddresspracticalchallengesandachievedevelopment\nobjectives within today’s complex, multimodal software environments. To realize this, concerted\nefforts have been undertaken across both pre-training and post-training phases since Gemini 1.5.\nIn pre-training, we intensified our focus on incorporating a greater volume and diversity of code\ndata from both repository and web sources into the training mixture. This has rapidly expanded\ncoverage and enabled the development of more compute-efficient models. Furthermore, we have\nsubstantially enhanced our suite of evaluation metrics for assessing code capabilities aligned with\ndownstream use cases, alongside improving our ability to accurately predict model performance.\n6"
    },
    {
      "page": 7,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nDuringpost-training,wedevelopednoveltrainingtechniquesincorporatingreasoningcapabilitiesand\ncuratedadiversesetofengineeringtasks,withtheaimtoequipGeminiwitheffectiveproblem-solving\nskills crucial for addressing modern engineering challenges. Key applications demonstrating these\nadvancements include IDE functionalities, code agent use cases for complex, multi-step operations\nwithin full repositories, and multimodal, interactive scenarios such as end-to-end web and mobile\napplication development. Collectively, these efforts have yielded broad and significant improvements\nin Gemini’s coding capabilities. This progress is evidenced by superior performance on established\nbenchmarks: performance on LiveCodeBench (Jain et al., 2024) increased from 30.5% for Gemini\n1.5 Pro to 74.2% for Gemini 2.5 Pro, while that for Aider Polyglot (Gauthier, 2025) went from\n16.9% to 82.2%. Performance on SWEBench-verified (Chowdhury et al., 2024; Jimenez et al., 2024)\nwent from 34.2% to 67.2%, see Table 3 and Figure 5 in Section 3.2. Furthermore, Gemini 2.5 Pro\nobtained an increase of over 500 Elo over Gemini 1.5 Pro on the LMArena WebDev Arena (Chiang\net al., 2024; LMArena Team, 2025), resulting in meaningful enhancements in practical applications,\nincluding UI and web application development (Doshi, 2025a), and the creation of sophisticated\nagentic workflows (Kilpatrick, 2025).\nFactuality\nWithin the context of generative models, ensuring the factuality of model responses to information-\nseeking prompts remains a core pillar of Gemini model development. With Gemini 1.5, our research\nwas concentrated on enhancing the model’s world knowledge and its ability to provide answers\nfaithfullygroundedinthecontextprovidedwithintheprompt. ThiseffortculminatedintheDecember\n2024 release of FACTS Grounding (Jacovi et al., 2025), now an industry-standard benchmark for\nevaluating an LLM’s capacity to generate responses grounded in user-provided documents. With\nGemini 2.0 and 2.5, we have significantly expanded our scope to address multimodal inputs, long-\ncontext reasoning, and model-retrieved information. At the same time, the landscape and user\nexpectations for factuality have evolved dramatically, shaped in part by Google’s deployment of AI\nOverviews and AI Mode (Stein, 2025). To meet these demands, Gemini 2.0 marked a significant leap\nas our first model family trained to natively call tools like Google Search, enabling it to formulate\nprecisequeriesandsynthesizefreshinformationwithsources. Buildingonthis,Gemini2.5integrates\nadvancedreasoning,allowingittointerleavethesesearchcapabilitieswithinternalthoughtprocesses\nto answer complex, multi-hop queries and execute long-horizon tasks. The model has learned to use\nsearch and other tools, reason about the outputs, and issue additional, detailed follow-up queries\nto expand the information available to it and to verify the factual accuracy of the response. Our\nlatest models now power the experiences of over 1.5B monthly active users in Google’s AI Overviews\nand 400M users in the Gemini App. These models exhibit state-of-the-art performance across a\nsuite of factuality benchmarks, including SimpleQA for parametric knowledge (Wei et al., 2024),\nFACTSGroundingforfaithfulnesstoprovideddocuments(Jacovietal.,2024,2025),andtheVectara\nHallucination Leaderboard (Hughes et al., 2023), cementing Gemini as the model of choice for\ninformation-seeking demands.\nLong context\nModeling and data advances helped us improve the quality of our models’ responses to queries\nutilizingouronemillion-lengthcontextwindow,andwereworkedourinternalevaluationstobemore\nchallengingtohelpsteerourmodelingresearch. Whenhill-climbing,wetargetedchallengingretrieval\ntasks (like LOFT of Lee et al., 2024), long-context reasoning tasks (like MRCR-V2 of Vodrahalli et al.,\n2024), and multimodal tasks (like VideoMME of Fu et al., 2025). According to the results in Table 6,\nthe new 2.5 models improve greatly over previous Gemini 1.5 models and achieve state-of-the-art\nquality on all of those. An example showcasing these improved capabilities for video recall can be\n7"
    },
    {
      "page": 8,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nseen in Appendix 8.5, where Gemini 2.5 Pro is able to consistently recall a 1 second visual event out\nof a full 46-minute video.2\nMultilinguality\nGemini’s multilingual capabilities have also undergone a profound evolution since 1.5, which already\nencompassed over 400 languages via pretraining. This transformation stems from a holistic strategy,\nmeticulously refining pre- and post-training data quality, advancing tokenization techniques, innovat-\ning core modeling, and executing targeted capability hillclimbing. The impact is particularly striking\nin Indic and Chinese, Japanese and Korean languages, where dedicated optimizations in data quality\nandevaluationhaveunlockeddramaticgainsinbothqualityanddecodingspeed. Consequently,users\nbenefit from significantly enhanced language adherence, responses designed to faithfully respect the\nrequested output language, and a robust improvement in generative quality and factuality across\nlanguages, solidifying Gemini’s reliability across diverse linguistic contexts.\nAudio\nWhile Gemini 1.5 was focused on native audio understanding tasks such as transcription, translation,\nsummarization and question-answering, in addition to understanding, Gemini 2.5 was trained to\nperform audio generation tasks such as text-to-speech or native audio-visual to audio out dialog. To\nenable low-latency streaming dialog, we incorporated causal audio representations that also allow\nstreaming audio into and out of Gemini 2.5. These capabilities derive from an increased amount of\npre-training data spanning over 200 languages, and development of improved post-training recipes.\nFinally, through our improved post-training recipes, we have integrated advanced capabilities such as\nthinking, affective dialog, contextual awareness and tool use into Gemini’s native audio models.\nVideo\nWe have significantly expanded both our pretraining and post-training video understanding data,\nimproving the audio-visual and temporal understanding capabilities of the model. We have also\ntrainedourmodelssothattheyperformcompetitivelywith66insteadof258visualtokensperframe,\nenabling using about 3 hours of video instead of 1h within a 1M tokens context window3. Two\nnew applications that were not previously possible, but that have been unlocked as a result of these\nchanges are: creating an interactive app from a video (such as a quiz to test students’ understanding\nof the video content) and creating a p5.js animation to show the key concepts from the video. Our\nrecent blog post (Baddepudi et al., 2025) shows examples of these applications.\nGemini as an Agent: Deep Research\nGemini Deep Research (Gemini Team, Google, 2024) is an agent built on top of the Gemini 2.5 Pro\nmodeldesignedtostrategicallybrowsethewebandprovideinformedanswerstoeventhemostniche\nuser queries. The agent is optimized to perform task prioritization, and is also able to identify when\nit reaches a dead-end when browsing. We have massively improved the capabilities of Gemini Deep\nResearch since its initial launch in December 2024. As evidence of that, performance of Gemini\nDeep Research on the Humanity’s Last Exam benchmark (Phan et al., 2025) has gone from 7.95% in\nDecember 2024 to the SoTA score of 26.9% and 32.4% with higher compute (June 2025).\n2Forfurtherdiscussiononlongcontextcapabilities,challenges,andfutureoutlook,theReleaseNotespodcastepisode\n“DeepDiveintoLongContext”providesadditionalinsightsanddiscussion:https://youtu.be/NHMJ9mqKeMQ.\n3ThisisreferredtoaslowmediaresolutionintheAPI:https://ai.google.dev/api/generate-content#Media\nResolution.\n8"
    },
    {
      "page": 9,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n2.7. The path to Gemini 2.5\nOn the way to Gemini 2.5 Pro, we experimented with our training recipe, and tested a small number\nof these experimental models with users. We have already discussed Gemini 2.0 Flash Thinking (see\nSection 2.5). We will now discuss some of the other models briefly.\nGemini 2.0 Pro\nIn February 2025, we released an experimental version of Gemini 2.0 Pro. At the time, it had\nthe strongest coding performance of any model in the Gemini model family, as well as the best\nunderstanding and world knowledge. It also came with our largest context window at 2 million\ntokens, which enabled it to comprehensively analyze and understand vast amounts of information.\nFor further information about Gemini 2.0 Pro, please see our earlier blog posts (Kavukcuoglu, 2025;\nMallick and Kilpatrick, 2025).\nGemini 2.0 Flash Native Image Generation Model\nIn March 2025, we released an experimental version of Gemini 2.0 Flash Native Image Generation.\nIt has brought to the users new capabilities as a result of a strong integration between the Gemini\nmodel and image-generation capabilities, enabling new experiences related to image generation &\nimage editing via natural-language prompting. Capabilities such as multi-step conversational editing\norinterleavedtext-imagegenerationareverynaturalinsuchasetting,andhorizontaltransferrelated\nto multi-language coverage immediately allowed such experiences to happen across all the languages\nsupported by the Gemini models. Native image generation turns Gemini into a multimodal creation\npartner and enables Gemini to express ideas through both text and images, and to seamlessly move\nbetween the two. For further information about Gemini 2.0 Flash Native Image Generation, please\nsee our earlier blog posts (Kampf and Brichtova, 2025; Sharon, 2025)\nGemini 2.5 Audio Generation\nWith Gemini 2.5, the Controllable TTS and Native Audio Dialog capabilities are available as separate\noptions on AI Studio (Generate Media and Stream sections respectively). Our Gemini 2.5 Preview\nTTS Pro and Flash models support more than 80 languages with the speech style controlled by a free\nformatted prompt which can specify style, emotion, pace, etc, while also being capable of following\nfiner-grained steering instructions specified in the transcript. Notably, Gemini 2.5 Preview TTS can\ngeneratespeechwithmultiplespeakers,whichenablesthecreationofpodcastsasusedinNotebookLM\nAudioOverviews(Wang,2024). OurGemini2.5FlashPreviewNativeAudioDialogmodelusesnative\naudio generation, which enables the same level of style, pacing and accent control as available in our\ncontrollable TTS offering. Our dialog model supports tool use and function calling, and is available\nin more than 24 languages. With native audio understanding and generation capabilities, it can\nunderstandandrespondappropriatelytotheuser’stone. Thismodelisalsocapableofunderstanding\nwhen to respond to the user, and when not to respond, ignoring background and non-device directed\naudio. Finally, we also offer an advanced ‘Thinking’ variant that effectively handles more complex\nqueries and provides more robust and reasoned responses in exchange for some additional latency.\nGemini 2.5 Flash-Lite\nIn June 2025, we released an experimental version of Gemini 2.5 Flash-Lite (gemini-2.5-flash-\nlite-preview-06-17). ItcomeswiththesamecapabilitiesthatmakeGemini2.5helpful,including\nthe ability to turn thinking on at different budgets, connecting to tools like Google Search and code\n9"
    },
    {
      "page": 10,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nexecution,supportformultimodalinputsanda1million-tokencontextlength. Ourgoalwastoprovide\nan economical model class which provides ultra-low-latency capabilities and high throughput per\ndollar, echoing the initial release of 2.0 Flash-Lite (Google DeepMind, 2025b; Mallick and Kilpatrick,\n2025).\nGemini 2.5 Pro Deep Think\nTo advance Gemini’s capabilities towards solving hard reasoning problems, we developed a novel\nreasoning approach, called Deep Think, that naturally blends in parallel thinking techniques during\nresponse generation. Deep Think enables Gemini to creatively produce multiple hypotheses and\ncarefully critique them before arriving at the final answer, achieving state-of-the-art performances in\nchallengingbenchmarkssuchasOlympiadmath(USAMO2025),competitivecoding(LiveCodeBench),\nand multimodality (MMMU), see more details at (Doshi, 2025b). We announced Gemini 2.5 Deep\nThink at Google I/O and launched an experimental version to trusted testers and advanced users in\nJune 2025.\n10"
    },
    {
      "page": 11,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n3. Quantitative evaluation\n100\n80\n60\n40\n20\n0\nFlash Pro\n)%(\netar\nssaP\nLiveCodeBench Aider Polyglot SWE-bench Verified\n100 100\nGemini version\n1.5\n2.0 80 80\n2.5\n60 60\n40 40\n20 20\n0 0\nFlash Pro Flash Pro\n100\n80\n60\n40\n20\n0\nFlash Pro\n)%(\nycaruccA\nGPQA (diamond) AIME 2025 HiddenMath-Hard\n100 100\n80 80\n60 60\n40 40\n20 20\n0 0\nFlash Pro Flash Pro\nFigure 5 | Performance of Gemini 2.X models at coding, math and reasoning tasks in comparison to\nprevious Gemini models. SWE-bench verified numbers correspond to the “multiple attempts” setting\nreported in Table 3.\nWe will now examine the performance of the Gemini 2.X model family across a wide range of\nbenchmarks. We will first compare the performance of the Gemini 2.X models to the earlier Gemini\n1.5 Pro and Flash models, before we compare the performance of Gemini 2.5 Pro to other available\nlarge language models.\nWith web-scale pre-training of AI models, coupled with the post-training techniques that allow\npolicy and reward models to leverage public benchmarks, avoiding leaks and biases in the data used\nfor pre- and post-training is a persistent challenge. In the development of the Gemini 2.5 series, in\naddition to the standard n-gram based decontamination we used in Gemini 1.5, we also employed\nsemantic-similarity and model based decontamination procedures to help mitigate evaluation set\nleakage. Tomovebeyondtherelianceontrainingsetdecontamination,wealsocontinuereportingon\ninternally developed non-public benchmarks, such as HiddenMath.\nModel AIStudiomodelID\nGemini1.5Flash gemini-1.5-flash-002\nGemini1.5Pro gemini-1.5-pro-002\nGemini2.0Flash-Lite gemini-2.0-flash-lite-001\nGemini2.0Flash gemini-2.0-flash-001\nGemini2.5Flash gemini-2.5-flash\nGemini2.5Pro gemini-2.5-pro\nTable 2 | Mapping of Gemini model names to AI Studio API model IDs.\n11"
    },
    {
      "page": 12,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n3.1. Methodology\nIn Table 3, we compare the performance of Gemini 2.5 models to the Gemini 1.5 models, while in\nTable 4, we compare the performance of Gemini 2.5 Pro to that of other large language models.\nGemini results: AllGeminiscoresarepass@1,andare“singleattempt”settingsunlessotherwise\nspecified. Inthe“singleattempt”setting,nomajorityvotingorparalleltest-timecomputeispermitted,\nwhile in the “multiple attempts” setting, test-time selection of the candidate answer is allowed. All\nGemini evaluations are run with the AI Studio API for the model id that we provide in Table 2, with\ndefaultsamplingsettings. Toreducevariance,weaverageovermultipletrialsforsmallerbenchmarks.\nAiderPolyglotscoresarethepassrateaverageof3trials. Vibe-EvalresultsarereportedusingGemini\nas a judge.\nNon-Gemini results: All the results for non-Gemini models are sourced from providers’ self\nreported numbers unless mentioned otherwise. All “SWE-bench Verified” numbers follow official\nproviderreports,whichmeansthattheyarecomputedusingdifferentscaffoldingsandinfrastructure,\nand aren’t directly comparable.\nFor some evaluations, we obtain results from the external leaderboards that report results on\nthese benchmarks. Results for Humanity’s Last Exam results are sourced from Scale’s leaderboard\nandresultsforDeepSeekareobtainedfromthetext-onlyvariantoftheleaderboard(indicatedwitha\n⋄in Table 4). For Gemini 2.0 models, the reported results are on an earlier HLE dataset (indicated\nwith a † in Table 3). Results on LiveCodeBench results are taken from (1/1/2025 - 5/1/2025) in the\nUI. Aider Polyglot numbers come from the Aider leaderboard and results for SimpleQA come from\nthis repo where available. Results on FACTS Grounding come from Kaggle. In the case of LOFT and\nMRCR-V2,wereportresultsonboththe128kcontextlengthvariant,aswellasthe1Mcontextlength\nvariant. In the 128k context length variant, we measure performance on contexts up to 128k, while\nfor the 1M context length variant, we report performance on context lengths of exactly 1M.\nMore details on all benchmarks, including subsets and how scores were obtained can be found in\nTable 11 in Appendix 8.1.\n3.2. Core capability quantitative results\nAs can be seen in Table 3, and Figure 5, the Gemini 2.5 models excel at coding tasks such as\nLiveCodeBench, Aider Polyglot and SWE-bench Verified, and represent a marked improvement over\nprevious models.\nInadditiontocodingperformance,Gemini2.5modelsarenoticeablybetteratmathandreasoning\ntasks than Gemini 1.5 models: performance on AIME 2025 is 88.0% for Gemini 2.5 Pro compared to\n17.5% for Gemini 1.5 Pro, while performance on GPQA (diamond) went from 58.1% for Gemini 1.5\nPro to 86.4%. Performance on image understanding tasks has also increased significantly.\nIt is also interesting to note that the Gemini 2.5 Flash model has become the second most capable\nmodel in the Gemini family, and has overtaken not just previous Flash models, but also the Gemini\n1.5 Pro model released one year ago.\n12"
    },
    {
      "page": 13,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5\nCapability Benchmark\nFlash Pro Flash-Lite Flash Flash Pro\nLiveCodeBench 30.3% 29.7% 29.1% 29.1% 59.3% 74.2%\nAiderPolyglot 2.8% 16.9% 10.5% 21.3% 56.7% 82.2%\nsingle\n9.6% 22.3% 12.5% 21.4% 48.9% 59.6%\nCode SWE-bench attempt\nmultiple\nVerified 19.7% 34.2% 23.1% 34.2% 60.3% 67.2%\nattempts\nGPQA\n50.0% 58.1% 50.5% 65.2% 82.8% 86.4%\n(diamond)\nReasoning\nHumanity’s\nnotools - 4.6% 4.6%† 5.1%† 11.0% 21.6%\nLastExam\nSimpleQA 8.6% 24.9% 16.5% 29.9% 26.9% 54.0%\nFactuality FACTS\n82.9% 80.0% 82.4% 84.6% 85.3% 87.8%\nGrounding\nGlobalMMLU\n72.5% 80.8% 78.0% 83.4% 88.4% 89.2%\nMultilinguality (Lite)\nECLeKTic 16.4% 27.0% 27.7% 33.6% 36.8% 46.8%\nAIME2025 14.7% 17.5% 23.8% 29.7% 72.0% 88.0%\nMath\nHiddenMath- 36.8% 44.3% 47.4% 53.7% 75.5% 80.5%\nHard\nLOFT(hard ≤128K 67.3% 75.9% 50.7% 58.0% 82.1% 87.0%\nretrieval) 1M 36.7% 47.1% 7.6% 7.6% 58.9% 69.8%\nLong-context\nMRCR-V2 ≤128K 18.4% 26.2% 11.6% 19.0% 54.3% 58.0%\n(8-needle) 1M 10.2% 12.1% 4.0% 5.3% 21.0% 16.4%\nMMMU 58.3% 67.7% 65.1% 69.3% 79.7% 82.0%\nVibe-Eval\n52.3% 55.9% 51.5% 55.4% 65.4% 67.2%\nImage (Reka)\nUnderstanding\nZeroBench 0.5% 1.0% 0.75% 1.25% 2.0% 4.5%\nBetterChartQA 59.0% 65.8% 52.3% 57.8% 67.3% 72.4%\nTable 3 | Evaluation of Gemini 2.5 family across a wide range of core capability benchmarks and in\ncomparison to Gemini 1.5 models. Please see Tables 5 and 6 for audio and video evaluations. See\nTable 11 Appendix 8.1 for benchmarks and evaluation details.\n13"
    },
    {
      "page": 14,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n3.3. Evaluation of Gemini 2.5 Pro against other large language models\nRelative to other large language models that are available (see Table 4), Gemini achieves the highest\nscoreontheAiderPolyglotcodingtask,Humanity’sLastExam,GPQA(diamond),andontheSimpleQA\nand FACTS Grounding factuality benchmarks out of all of the models examined here. Gemini also\ncontinues to stand out for achieving the SoTA score on both the LOFT and MRCR long-context tasks\nat 128k context, and is the only one, amongst the models examined in the above table, to support\ncontext lengths of 1M+ tokens.\nNot all of the models shown in Table 4 have native support for multimodal inputs. As such, we\ncompare against a different set of models for audio and video understanding.\nAudio Understanding\nIn Table 5, we showcase the performance of the Gemini 2.5 model family at audio understanding,\nand compare the performance of these models to earlier Gemini models, as well as to GPT models.\nGemini2.5Prodemonstratesstate-of-the-artaudiounderstandingperformanceasmeasuredbypublic\nbenchmarks for ASR and AST, and compares favorably to alternatives under comparable testing\nconditions (using the same prompts and inputs).\nVideo Understanding\nIn Table 6, we show the performance of Gemini 2.5 models at video understanding. As can be\nseen, Gemini 2.5 Pro achieves state-of-the-art performance on key video understanding benchmarks,\nsurpassing recent models like GPT 4.1 under comparable testing conditions (same prompt and video\nGemini2.5 o3 o4-mini Claude4 Claude4 Grok3Beta DeepSeekR1\nCapability Benchmark\nPro high high Sonnet Opus ExtendedThinking 0528\nLiveCodeBench 74.2% 72.0% 75.8% 48.9% 51.1% – 70.5%\nCode\nAiderPolyglot 82.2% 79.6% 72.0% 61.3% 72.0% 53.3% 71.6%\nsingle 59.6% 69.1% 68.1% 72.7% 72.5% - -\nSWE-bench attempt\nVerified multiple 67.2% - - 80.2% 79.4% - 57.6%\nattempts\nGPQA\nsingle 86.4% 83.3% 81.4% 75.4% 79.6% 80.2% 81.0%\nReasoning (diamond) attempt\nHumanity’s\nno 21.6% 20.3% 18.1% 7.8% 10.7% - 14.0%⋄\nLastExam tools\nSimpleQA 54.0% 48.6% 19.3% - - 43.6% 27.8%\nFactuality\nFACTS\n87.8% 69.9% 62.1% 79.1% 77.7% 74.8% 82.4%\nGrounding\nMath AIME2025 single 88.0% 88.9% 92.7% 70.5% 75.5% 77.3% 87.5%\nattempt\nLOFT(hard ≤128K 87.0% 77.0% 60.5% 81.6% - 73.1% -\nretrieval) 1M 69.8% - - - - - -\nLong-context\nMRCR-V2 ≤128K 58.0% 57.1% 36.3% 39.1% 16.1%* 34.0% -\n(8-needle) 1M 16.4% - - - - - -\nImage\nMMMU single 82.0% 82.9% 81.6% 74.4% 76.5% 76.0% NoMMsupport\nUnderstanding attempt\nTable 4 | Performance comparison of Gemini 2.5 Pro with other large language models on different\ncapabilities. Please see Tables 5 and 6 for audio and video evaluations. See Table 11 for benchmarks\nand evaluation details. *: with no thinking and API refusals\n14"
    },
    {
      "page": 15,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5 GPT-4omini GPT4o GPT4o\nBenchmark\nFlash Pro Flash-Lite Flash Flash Pro AudioPreview AudioPreview transcribe\nFLEURS\n12.71 7.14 9.60 9.04 9.95 6.66 19.52 12.16 8.17\n(53lang,WER↓)\nCoVoST2\n34.81 37.53 34.74 36.35 36.15 38.48 29.5 35.89 –\n(21lang,BLEU↑)\nTable 5 | Performance comparison of Gemini 2.5 models to earlier Gemini models, as well as to GPT\nmodels for audio understanding. Note that for GPT models, metrics may differ from those previously\nreported due to differing eval methodologies. See Table 11 for benchmarks and evaluation details.\nframes). For cost-sensitive applications, Gemini 2.5 Flash provides a highly competitive alternative.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5 OpenAI\nModalities Benchmark\nFlash Pro Flash-Lite Flash Flash Pro GPT4.1\nActivityNet-QA 56.2 57.3 55.3 56.4 65.1 66.7 60.4\nEgoTempo 34.5 36.3 30.1 39.3 36.7 44.3 40.3\nPerceptionTest 66.5 69.4 67.5 68.8 75.1 78.4 64.8\nvisual-only\nQVHighlights 64.4 68.7 25.7 63.9 52.4 75.0 71.4\nVideoMMMU 64.8 70.4 64.3 68.5 79.2 83.6 60.9\n1H-VideoQA 61.9 72.2 55.6 67.5 67.5 81.0 56.8\nLVBench 61.9 65.7 52 61.8 62.7 78.7 63.4\nVideoMME 70.4 73.2 62.1 72.8 75.5 84.3 72.0\naudio+visual VATEX 56.9 55.5 58.5 56.9 65.2 71.3 64.1\nVATEX-ZH 46.2 52.2 43.2 48.5 43.9 59.7 48.7\nYouCook2Cap 153.2 170.0 78.6 129.0 177.6 188.3 127.6\nMinerva 49.6 52.8 46.8 52.4 60.7 67.6 54.0\nvisual+subtitles\nNeptune 78.7 82.7 81.5 83.1 84.3 87.3 85.2\naudio+visual+\nVideoMME 77.3 79.8 72.5 78.8 81.5 86.9 79.6\nsubtitles\nTable 6 | Evaluation of Gemini 2.5 vs. prior models and GPT 4.1 on video understanding benchmarks.\nPerformance is measured by string-match accuracy for multiple-choice VideoQA, LLM-based accuracy\nfor open-ended VideoQA, R1@0.5 for moment retrieval and CIDEr for captioning. See Table 11 for\nbenchmarks and evaluation details.\n15"
    },
    {
      "page": 16,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n4. Example use cases of Gemini 2.5 Pro\n4.1. Gemini Plays Pokémon\nHall of Fame\nBeat Elite Four Lance\nBeat Elite Four Agatha\nBeat Elite Four Bruno\nBeat Elite Four Lorelei\nExit Victory Road (1st)\nEnter Victory Road (1st)\nRival 7 (Route 22 #2)\nEarth Badge\nVolcano Badge\nAcquire Secret Key (Pokemon Mansion)\nEnter Cinnabar Island (1st)\nMarsh Badge\nRocket Boss 2 (Silph Co.)\nRival 6 (Silph Co.)\nEnter Silph Co. (1st)\nEnter Saffron City (1st)\nAcquire HM04 Strength (Warden's Teeth)\nSoul Badge\nAcquire HM03 Surf (Beat Safari Zone)\nEnter Safari Zone (1st)\nEnter Fuchsia City (1st)\nAcquire PokéFlute (Rescue Fuji)\nRainbow Badge\nRocket Boss 1 (Rocket Hideout)\nEnter Rocket Hideout (1st)\nEnter Celadon City (1st)\nRival 5 (Lavender Tower)\nExit Rock Tunnel & Reach Lavender Town (1st)\nAccess Pokemon w/ Flash\nEnter Rock Tunnel (1st)\nThunder Badge\nAcquire HM05 Flash\nAccess Pokemon w/ CUT\nRival 4 (SS Anne)\nBill’s House\nCascade Badge\nRival 3 (Nugget Bridge)\nExit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge\nExit Viridian Forest (1st)\nEnter Viridian Forest (1st)\nViridian City\nRival 1 (Oak's Lab)\n0 100 200 300 400 500 600 700 800\nTime Elapsed (Hours)\nsenotseliM\nemaG\nGemini 2.5 Pro Plays Pokemon Progress Timeline\nRun 1\nRun 2 (Actual)\nFigure 6 | Progression of the Gemini Plays Pokémon agent through the game, across two runs. Run 1\nwasthedevelopmentrunwherechangestotheharnesswereperformed. Run2isthefullyautonomous\nrunwiththefinalfixedscaffold. Bothrunshavethesamestarter(Squirtle). Theeventsareorderedon\nthe y-axis by the order they happened, following the order of Run 2 when there is a conflict. Notably,\ntheGPPagentadditionallywentthroughthedifficult(andoptional)SeafoamIslandsdungeoninRun\n2, while in Run 1, GPP reached Cinnabar Island via Pallet Town and Route 21.\nOn March 28, 2025, an independent developer not affiliated with Google, Joel Zhang, set up a\nTwitch stream (Gemini Plays Pokémon, or GPP) for Gemini 2.5 Pro (Gemini 2.5 Pro Exp 03-25) to\nplay Pokémon Blue on stream (Zhang, 2025) as an experiment to better understand how well the\nmodel was capable of playing Pokémon (in a similar spirit to Claude Plays Pokémon, see Anthropic\n2025). In this initial run through the game, the goal was to live-stream the development process of\nan agentic harness capable of playing the full game (and in particular the minimal transformation of\nvisiontotextnecessarytodoso),seeFigure14foradescriptionofthefinalagentsetup. Assuch,over\nthe course of the run, modifications were made to the setup as difficulties arose, providing a deeply\ninteresting lens via which to analyze some of the qualitative improvements that the 2.5 Pro model\nhasmade,particularlyintheregimesofsolvinglongreasoningproblemsandagenticcapabilitiesover\nextended time horizons. Around 1 month later, on May 2, 2025, Gemini 2.5 Pro completed the game\nafter 813 hours and entered the Hall of Fame to become the Pokémon League Champion! On May\n22, 2025, GPP began a fully autonomous 2nd run through the game with Gemini 2.5 Pro (Gemini\n2.5 Pro Preview 05-06) with the finalized fixed agentic harness, and progressed through the game\nconsiderablyfaster,completingthegamein406.5hours(nearlyexactlyhalfthetimeofthefirstrun).\n16"
    },
    {
      "page": 17,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nSee Figure 6 for a timeline of GPP’s progress through major game milestones to game completion.\nWe report # hours to each milestone in order to normalize for the amount of time models take per\naction. See Appendix 8.2 for more figures.\nCapabilities assessment\nGemini 2.5 Pro showcased many impressive capabilities associated with reasoning and long-term\nplanning while playing Pokémon. We will now discuss two in particular, but for more examples, see\nAppendix 8.2.\nLong Context Agentic Tooling Within the agent scaffolding, GPP has access to two agentic\ntools (see Figure 14). These prompted versions of Gemini 2.5 Pro, hereafter pathfinder and\nboulder_puzzle_strategist, have been able to:\n1. Solve complex spinner puzzles in one shot (for instance in Rocket Hideout),\n2. Solve the step-constrained multi-map puzzle of the Safari Zone,\n3. Find long pathways through complex mazes like Route 13,\n4. Solve boulder puzzles across long distances in Victory Road and the Seafoam Islands.\nEachtaskrequiresreasoningoveralongcontext-thepathfindermodelwouldoftenhavetoreason\nover contexts of 100K+ tokens, and find paths up to 50 actions in length (in the extreme case, paths\nconsisting of up to 150 actions have also been found!).\nLong Horizon Task Coherence WhileGemini2.5Proisimpressiveinamorelocalsense,theagent\nalsoexhibitedremarkablelong-termtaskcoherenceinachievingglobal,high-levelgoalsinthefaceof\nreal andhallucinated setbacks towards makingforward progress. Because the agent is able to change\ngoals at will, and will generally follow those goals as long as needed, it is extremely impressive that\nthe agent can satisfy numerous requirements for tactical, necessary goals, such as acquiring Hidden\nMoves, as well as maintain enough strategic task coherence to beat the entire game and become the\nPokémon Champion.\nWhere does 2.5 Pro struggle while playing Pokémon?\nIn addition to more standard hallucination issues (which interestingly were plausibly reduced in Run\n2 by explicitly prompting the model to act as a player completely new to the game, see Appendix 8.2\nfor more details), there are a few particular points of struggle we would like to emphasize.\nScreen reading While obtaining excellent benchmark numbers on real-world vision tasks, 2.5 Pro\nstruggled to utilize the raw pixels of the Game Boy screen directly, though it could occasionally take\ncues from information on the pixels. As a result, it was necessary for the required information from\nthe screen to be translated into a text format in the agent framework, using information from the\ngame’s RAM state. During one portion of the game, the developer tested an ablation where all vision\nwas completely removed from the model context – the model was able to function roughly as well\nas without the vision information, suggesting that most of the performance does not significantly\ndepend on the visual input.\nLong Context Reasoning Gemini 2.5 Pro’s state-of-the-art long context performance for both\nreasoning and retrieval tasks (see Tables 3 and 4) was a cornerstone of the GPP agent’s success. Its\nability to reason over a 100k token context was instrumental for leveraging the complex toolset and\n17"
    },
    {
      "page": 18,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nmaintaining a relatively coherent strategy (e.g., optimal balance of performance, planning quality,\nand information recall.)\nWhile Gemini 2.5 Pro supports 1M+ token context, making effective use of it for agents presents\na new research frontier. In this agentic setup, it was observed that as the context grew significantly\nbeyond 100k tokens, the agent showed a tendency toward favoring repeating actions from its vast\nhistory rather than synthesizing novel plans. This phenomenon, albeit anecdotal, highlights an\nimportant distinction between long-context for retrieval and long-context for multi-step, generative\nreasoning.\nTeachinganagenttoeffectivelyplanandavoidsuchloopsovermassivepasttrajectoriesofcontext\nis an exciting and active area of research; the co-design of agent scaffolds and models to unlock the\nfull potential of million-token context is an intriguing research direction and one of our primary\nfocuses.\n4.2. What else can Gemini 2.5 do?\nGemini 2.5 Pro excels at transforming diverse, often unstructured, inputs into interactive and func-\ntional applications. For instance, it can take a PDF script of a play and generate a tool that allows\ndrama students to practice their lines. Gemini 2.5 Pro can also take an uploaded photograph of a\nbookshelf and create a curated book recommendation application. Gemini 2.5 Pro can utilize its\nunderlying spatial understanding capability and convert images into a structural representation like\nHTML or SVG. In Figure 16 in Appendix 8.4, we show a comparison of Gemini 1.5 Pro and Gemini\n2.5Proonanimage-to-svgtask,whereGemini2.5Proreconstructsmuchmorevisualdetailsandthe\nspatial arrangements of objects better resembles the original image.\nFurthermore, Gemini 2.5 Pro demonstrates strong skills in generating sophisticated simulations\nand visualizations, ranging from interactive solar system models (source) to the creative rendering of\nabstract mathematical concepts, such as drawing a logo using Fourier series (source). This capability\nextendstothedevelopmentoftoolsthatintersectcreativityandutility: weseeexamplesofspecialized\napplicationslikeacustomcartographytoolorusecasesthatgeneratephotorealistic3Duserinterfaces\nfrom descriptive text and reference images, complete with appropriate styling and interactivity\n(source).\nCollectively, these examples illustrate that Gemini 2.5 Pro is not just a useful coding and writing\nassistant, but excels at a wide range of complex tasks, ranging from those relevant for education\nto creative expression. The model empowers users to rapidly prototype specialized utilities, de-\nvelop engaging educational content, and realize intricate creative visions with a high degree of\nsophistication.\n4.3. Gemini in Google Products\nAs a final example of what Gemini can do, we note that Gemini (or a custom version of Gemini) is\nnow incorporated into a wide variety of Google products. These include, but are not limited to, AI\nOverviews and AI Mode within Google Search, Project Astra, the audiovisual-to-audio dialog agent,\nGemini Deep Research, the research assistant discussed in Section 2.7, NotebookLM, the tool capable\nof generating podcasts and audio overviews from even the most obscure inputs, Project Mariner, the\nweb browsing agent, and Google’s coding agent, Jules.\n18"
    },
    {
      "page": 19,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n5. Safety, Security, and Responsibility\nWe’re committed to developing Gemini responsibly, innovating on safety and security alongside capa-\nbilities. We describe our current approach in this section, which includes how we train and evaluate\nour models, focusing on automated red teaming, going through held-out assurance evaluations on\npresent-day risks, and evaluating the potential for dangerous capabilities in order to proactively\nanticipate new and long-term risks.\nGuideline for Navigating This Section\n1. Our Process (Section 5.1): Begin here to understand our overall safety methodology.\n2. Policies and Desiderata (Section 5.2): Next, dive into the safety criteria we use to evaluate\nand optimize our systems.\n3. Training for Safety (Section 5.3): Discover how we incorporate safety into pre-training and\npost-training.\n4. ResultsfromDevelopmentEvaluations(Section5.4): Resultsonourdevelopmentevaluations\nfor policies and desiderata.\n5. Automated Red Teaming (Section 5.5): A description and results from our automated red\nteaming work for safety and security.\n6. Memorization & Privacy (Section 5.6): Our analysis of memorization and privacy risks.\n7. Assurance Evaluations and Frontier Safety Framework (Section 5.7): We dive into our\nheld-out evaluations and tests for dangerous capabilities.\n8. External Safety Testing (Section 5.8): Learn what independent testers discovered about our\nsystem’s safety.\n5.1. Our Process\nWe aim for Gemini to adhere to specific safety, security, and responsibility criteria. These cover what\nGemini should not do (e.g., encourage violence), and what Gemini should do (e.g., respond in a\nhelpful way when possible instead of refusing, provide multiple perspectives when consensus does\nnotexist). Wealsoleverageautomatedredteamingtoidentifycaseswherethemodelfailstorespond\nin a safe or helpful manner. These failure cases are used to improve evaluations and training data.\nOnce the model is trained, we run assurance evaluations that we then use for review and release\ndecisions. Importantly, these are conducted by a group outside of the model development team, and\ndatasets are held out. Furthermore, for models where there are new capabilities or a significant\nperformance improvement, we engage independent external groups, including domain experts and a\ngovernment body, to further test the model to identify blind spots.\nWe also evaluate the model for dangerous capabilities outlined in our Frontier Safety Framework\n(Google DeepMind, 2025a), namely: Cybersecurity, CBRN, Machine Learning R&D, and Deceptive\nAlignment.\nFinally, The Google DeepMind Responsibility and Safety Council (RSC), our governance body,\nreviews initial ethics and safety assessments on novel model capabilities in order to provide feedback\nand guidance during model development. The RSC also reviews metrics on the models’ performance\nvia assurance evals and informs release decisions.\n19"
    },
    {
      "page": 20,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n5.2. Policies and Desiderata\nSafety policies\nTheGeminisafetypoliciesalignwithGoogle’sstandardframeworkwhichpreventsourourGenerative\nAI models from generating specific types of harmful content, including:\n1. Child sexual abuse and exploitation\n2. Hate speech (e.g., dehumanizing members of protected groups)\n3. Dangerous content (e.g., promoting suicide, or instructing in activities that could cause real-\nworld harm)\n4. Harassment (e.g., encouraging violence against people)\n5. Sexually explicit content\n6. Medical advice that runs contrary to scientific or medical consensus\nThese policies apply across modalities. For example, they are meant to minimize the extent to\nwhich Gemini generates outputs such as suicide instructions or revealing harmful personal data,\nirrespective of input modality.\nFrom a security standpoint, beyond limiting revealing private information, Gemini strives to\nprotect users from cyberattacks, for example, by being robust to prompt injection attacks.\nDesiderata, aka “helpfulness”\nDefining what not to do is only part of the safety story – it is equally important to define what we do\nwant the model to do:\n1. Help the user: fulfill the user request; only refuse if it is not possible to find a response that\nfulfills the user goals without violating policy.\n2. Assume good intent: ifarefusalisnecessary,articulateitrespectfullywithoutmakingassump-\ntions about user intent.\n5.3. Training for Safety, Security, and Responsibility\nWe build safety into the models though pre-and post-training approaches. We start by constructing\nmetricsbasedonthepoliciesanddesiderataabove,whichwetypicallyturnintoautomatedevaluations\nthat guide model development through successive model iterations. We use data filtering and\nconditional pre-training, as well as Supervised Fine-Tuning (SFT), and Reinforcement Learning from\nHuman and Critic Feedback (RL*F). Below, we explain these approaches, and then share results\nacross the policies and desiderata for Gemini 2.0 and Gemini 2.5 models.\n• Dataset filtering: We apply safety filtering to our pre-training data for our strictest policies.\n• Pre-training monitoring: Starting in Gemini 2.0, we developed a novel evaluation to capture\nthe model’s ability to be steered towards different viewpoints and values, which helps align the\nmodel at post-training time.\n• Supervised Fine-Tuning: For the SFT stage, we source adversarial prompts either leveraging\nexisting models and tools to probe Gemini’s attack surface, or relying on human interactions\nto discover potentially harmful behavior. Throughout this process we strive for coverage of\nthe safety policies described above across common model use cases. When we find that model\n20"
    },
    {
      "page": 21,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nbehavior needs improvement, either because of safety policy violations, or because the model\nrefuses when a helpful, non-policy-violating answer exists, we use a combination of custom\ndata generation recipes loosely inspired by Constitutional AI (Bai et al., 2022), as well as\nhuman intervention to revise responses. The process described here is typically refined through\nsuccessive model iterations. We use automated evaluations on both safety and non-safety\nmetrics to monitor impact and potential unintended regressions.\n• Reinforcement Learning from Human and Critic Feedback (RL*F):RewardsignalduringRL\ncomesfromacombinationofaDataRewardModel(DRM),whichamortizeshumanpreference\ndata,andaCritic,apromptedmodelthatgradesresponsesaccordingtopre-definedrubrics. We\ndivide our interventions into Reward Model and Critic improvements (RM), and reinforcement\nlearning (RL) improvements. For both RM and RL, similarly to SFT, we source prompts either\nthrough human-model or model-model interactions, striving for coverage of safety policies\nand use cases. For both DRM training, given a prompt set, we use custom data generation\nrecipes to surface a representative sample of model responses. Humans then provide feedback\non the responses, often comparing multiple potential response candidates for each query. This\npreference data is amortized in our Data Reward Model. Critics, on the other hand, do not\nrequire additional data, and iteration on the grading rubric can be done offline. Similarly to\nSFT, RL*F steers the model away from undesirable behavior, both in terms of content policy\nviolations, and trains the model to be helpful. RL*F is accompanied by a number of evaluations\nthat run continuously during training to monitor for safety and other metrics.\n5.4. Results on Training/Development Evaluations\nOur primary safety evaluations assess the extent to which our models follow our content safety\npolicies. Wealsotrackhowhelpfulthemodelisinfulfillingrequeststhatshouldbefulfilled,andhow\nobjective or respectful its tone is.\nCompared to Gemini 1.5 models, the 2.0 models are substantially safer. However, they over-\nrefused on a wide variety of benign user requests. In Gemini 2.5, we have focused on improving\nhelpfulness / instruction following (IF), specifically to reduce refusals on such benign requests. This\nmeans that we train Gemini to answer questions as accurately as possible, while prioritizing safety\nand minimising unhelpful responses. New models are more willing to engage with prompts where\nprevious models may have over-refused, and this nuance can impact our automated safety scores.\nWe expect variation in our automated safety evaluations results, which is why we review flagged\ncontent to check for egregious or dangerous material. Our manual review confirmed losses were\noverwhelmingly either a) false positives or b) not egregious. Furthermore, this review confirmed\nlosses are narrowly concentrated around explicit requests to produce sexually suggestive content\nor hateful content, mostly in the context of creative use-cases (e.g. historical fiction). We have not\nobserved increased violations outside these specific contexts.\n5.5. Automated Red Teaming\nFor Safety\nTo complement human red teaming and our static evaluations, we make extensive use of automated\nred teaming (ART) to dynamically evaluate Gemini at scale (Beutel et al., 2024; Perez et al., 2022;\nSamvelyan et al., 2024). This allows us to significantly increase our coverage and understanding\nof potential risks, as well as rapidly develop model improvements to make Gemini safer and more\nhelpful.\n21"
    },
    {
      "page": 22,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini2.0Flash-Litevs. Gemini2.0Flashvs. Gemini2.5Flashvs. Gemini2.5Provs.\nMetric\nGemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Pro002\nENtext-to-textPolicy\n↓14.3% ↓12.7% ↓8.2% ↓0.9%\nViolations**\ni18ntext-to-textPolicy\n↓7.3% ↓7.8% ↑1.1%* ↓3.5%\nViolations**\nImage-to-textPolicy\n↑4.6%* ↑5.2%* ↑6.4%* ↑1.8%*\nViolations\nTone ↑8.4% ↑1.5% ↑7.9% ↑18.4%\nHelpfulness/Instruction\n↓19.7% ↓13.2% ↑13.6% ↑14.8%\nFollowing\nTable 7 | Comparison of safety and helpfulness metrics for Gemini 2.0 and 2.5 models relative to\nGemini 1.5 baselines. A down arrow (↓) indicates a reduction in the number of policy violations\n(better), while an up arrow (↑) indicates an improvement for Tone and Helpfulness / Instruction\nFollowing. *Noegregiouslossesreported. **Theseautomatedevaluationshaverecentlybeenupdated\nfor enhanced safety coverage, so these results are not comparable with those in past tech reports or\nmodel cards.\nWeformulateARTasamulti-agentgamebetweenpopulationsofattackersandthetargetGemini\nmodel being evaluated. The goal of the attackers is to elicit responses from the target model which\nsatisfy some defined objectives (e.g. if the response violates a safety policy, or is unhelpful). These\ninteractions are scored by various judges (e.g. using a set of policies), with the resulting scores used\nby the attackers as a reward signal to optimize their attacks.\nOurattackersevaluateGeminiinablack-boxsetting,usingnaturallanguagequerieswithoutaccess\nto the model’s internal parameters. This focus on naturalistic interactions ensures our automated red\nteaming is more reflective of real-world use cases and challenges. Attackers are prompted Gemini\nmodels, while our judges are a mixture of prompted and finetuned Gemini models.\nTo direct the attackers and judges, we use various seeds including policy guidelines, trending\ntopics, and past escalations. Policies are sourced from: (1) policy experts who collaborate with us to\nincorporate their policies into the judges, and (2) Gemini itself which generates synthetic guidelines\nthat are reviewed by humans and then used. We also work with internal teams to evaluate the most\nrelevant trending topics in the world and corresponding potential risks. These dual approaches allow\nus to complement human expertise with automation, enabling red teaming to evaluate known and\nunknown issues at scale.\nThe generality of our approach has allowed us to rapidly scale red teaming to a growing number\nofareasincludingnotjustpolicyviolations(Section5.4),butalsoareassuchastone,helpfulness,and\nneutrality. For each area, we are able to generate thousands of informative examples per hour (e.g.\nprompts which elicit unsafe or biased responses from Gemini). This has resulted in the discovery of\nnovel issues prior to model and product releases, and helped inform policy development/refinement.\nFurthermore, automated red teaming has significantly accelerated the turnaround time from dis-\ncovering to mitigating issues thanks to the rapid creation of evaluation and training sets, as well as\ninforming product-level mitigations prior to releases.\nAsaconcreteexampleoftheuseandimpactofautomatedredteaming,wehighlighttheconsistent\nreduction in helpfulness violations discovered by ART, with Gemini 2.5 Flash and 2.5 Pro being our\nmost helpful models to-date while maintaining robust safety metrics.\n22"
    },
    {
      "page": 23,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nDangerousContentpolicy Helpfulnessviolations\nModel\nviolations(fromART) (fromART)\nGemini1.5Flash002 38.3% 9.5%\nGemini1.5Pro002 43.5% 8.9%\nGemini2.0Flash 25.2% 8.1%\nGemini2.5Flash 26.9% 6.6%\nGemini2.5Pro 24.3% 6.1%\nTable 8 | Policy and helpfulness violations as discovered by Automated Red Teaming (ART). Lower\npercentages are better.\nFor Security\nOur evaluation measures Gemini’s susceptibility to indirect prompt injection attacks. As illustrated\nin Figure 7, we specifically focus on a scenario in which a third party hides malicious instructions\nin external retrieved data, in order to manipulate Gemini into taking unauthorized actions through\nfunction calling.\nInourscenario,thespecificfunctioncallsavailabletoGeminiallowittosummarizeauser’slatest\nemails,andtosendemailsontheirbehalf. Theattacker’sspecificobjectiveistomanipulatethemodel\nto invoke a send email function call that discreetly exfiltrates sensitive information from conversation\nhistory.\nThe attacker sends the user an email whose contents prompt Gemini to send user secrets to an\nattacker-controlled email address. When the user requests a summary of this email, it is retrieved\ninto context. The attack is successful if Gemini executes the malicious prompt contained in the\nemail,resultingintheunauthorizeddisclosureofsensitiveinformationtotheadversary. Theattackis\nunsuccessful if Gemini complies with its intended functionality of only following user instructions\nand provides a simple summary of the email.\nFor evaluation, we use Gemini to generate synthetic conversations between a user and an AI\nassistant containing references to simulated private user information. These synthetic conversations\nemulate how a user might discuss private information with the agent.\nManually generating prompt injections is an inefficient process as it relies on humans writing\ntriggers, submitting them to Gemini, and using the responses to refine the prompts. Instead, we\ndevelop several attacks that automate the process of generating malicious prompts:\n• Actor Critic: This attack uses an attacker-controlled model to generate suggestions for triggers.\nThese are passed to the model under attack, which returns a probability score of a successful\nattack. Based on this probability, the attack model refines the trigger. This process repeats until\nthe attack model converges to a successful and generalized trigger.\nFigure 7 | Illustration of the scenario where a Gemini-based AI Agent is attacked by malicious\ninstructions hidden in external retrieved data.\n23"
    },
    {
      "page": 24,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n• Beam Search: This attack starts with a naive trigger directly requesting the model to send an\nemail to the attacker containing the sensitive user information. If the model recognises the\nrequest as suspicious and does not comply, the attack adds random tokens to the end of the\ntrigger and measures the new probability of the attack succeeding. If the probability increases,\nthese random tokens are kept, otherwise they are removed, and the process repeats until the\ncombination of the trigger and random appended tokens results in a successful attack.\n• Tree of Attacks w/ Pruning (TAP): (Mehrotra et al., 2024) designed an attack to generate\nprompts that cause the model to violate safety policies (such as generating hate speech). We\nadapt this attack, making several adjustments to target security violations. Like Actor Critic,\nthis attack searches in the natural language space; however we assume the attacker cannot\naccessprobabilityscoresfromthemodelunderattack,onlythetextsamplesthataregenerated.\nAfter constructing prompt injections using these methods, we evaluate them on a held-out set of\nsynthetic conversation histories containing simulated private user information, which for the results\nreportedbelowaresyntheticpassportnumbers. Wereportthebestattacksuccessrate(ASR)achieved\nacross these prompt injections. ASR represents the percentage of simulated private information\nthat is successfully exfiltrated to the attacker – because the attacker has no prior knowledge of the\nconversation history, the prompt injection must generalize across conversation histories to achieve a\nhigh ASR, making this a harder task than eliciting generic unaligned responses from the model.\nThetablebelowsummarizestheresults. ForbothGemini2.0FlashandGemini2.0Flash-Lite,we\nfind that they are more resilient against our Actor Critic and Beam Search attacks. In Actor Critic,\nwhichusesiterativelymorepersuasivenaturallanguagepromptinjections,ASRsreducedsubstantially\ncompared with both Gemini 1.5 Flash; while in Beam Search which primarily relies on discovering\nrandom tokens resulting in successful attacks, the ASR also reduced noticeably. However, for TAP,\nwhich leverages more creative natural language scenarios like role-playing to attack the model, the\nASR on Gemini 2.0 Flash increased by 16.2% on already very high ASRs for Gemini 1.5 Flash.\nOurresultsindicatethatGemini2.0modelsarebecomingmoreresilienttosomeclassesofprompt\ninjection attacks in environments containing privateuser data. However, improved model capabilities\nofGemini2.0versusGemini1.5alsoenableattackerstoleveragethemodel’sabilitytocreatenatural\nlanguage attacks like TAP. The lower ASRs on Actor Critic and TAP against Gemini 2.0 Flash-Lite is\nlikelytheresultofcomparativelylowercapabilityofthesmallerFlash-LitemodelcomparedtoGemini\n2.0 Flash, rather than an indication of greater internal resilience.\nIn Gemini 2.5 Flash and Gemini 2.5 Pro, we have observed greater resilience against all three\nof our attack techniques across the board, despite significantly increased model capabilities. This is\na result of the security adversarial training against indirect prompt injection attacks we added in\nGemini 2.5, further details for which can be found in the white paper (Shi et al., 2025) we recently\nreleased. However the Gemini 2.5 Pro model is still less resilient compared to Gemini 2.5 Flash,\nshowing that increased model capabilities in Pro still constrain our mitigations. We are continuing to\nevolve our adversarial evaluations to accurately measure and monitor the resilience of increasingly\ncapable Gemini models, as well as our adversarial training techniques to further improve the security\nof our models.\n5.6. Memorization and Privacy\nDiscoverable Memorization\nLarge language models are known to potentially produce near-copies of some training examples\n(Biderman et al., 2023; Carlini et al., 2022; Ippolito et al., 2022; Nasr et al., 2023). Several prior\n24"
    },
    {
      "page": 25,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini2.0Flash-Litevs. Gemini2.0Flashvs. Gemini2.5Flashvs. Gemini2.5Provs.\nAttackTechnique\nGemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Pro002\n52.0% 68.0% 40.8% 61.4%\nActorCritic\n(↓44.2%) (↓28.2%) (↓55.4%) (↓36.8%)\n75.4% 67.2% 4.2% 63.8%\nBeamSearch\n(↓9.0%) (↓17.2%) (↓80.2%) (↓35.6%)\n64.8% 98.4% 53.6% 30.8%\nTAP\n(↓17.4%) (↑16.2%) (↓28.6%) (↓57.0%)\nTable 9 | Comparison of Attack Success Rates (ASRs) against Gemini 2.5, 2.0, and 1.5 models. ASRs\nare reported as a percentage of 500 held-out scenarios where the best-performing prompt injection\ntrigger successfully exfiltrated sensitive information; lower ASRs are better.\nreports have released audits that quantify the risk of producing near-copies of the training data by\nmeasuring the model’s memorization rate (Anil et al., 2023; Chowdhery et al., 2022; CodeGemma\nTeametal.,2024;GeminiTeam,2024;GemmaTeam,2024;Grattafiorietal.,2024;Kuduguntaetal.,\n2023;Pappuetal.,2024). Thismemorizationrateisdefinedtobetheratioofmodelgenerationsthat\nmatch the training data of all model generations, approximated using a sufficiently large sample size.\nIn this report, we follow the methodology described in Gemini Team (2024). Specifically, we\nsample over 700,000 documents from the training data, distributed across different corpora, and use\nthis sample to test for discoverable extraction (Nasr et al., 2023) using a prefix of length 50 and a\nsuffix of length 50. We characterize text as either exactly memorized if all tokens in the continuation\nmatch the source suffix or approximately memorized if they match up to an edit distance of 10%.\nFigure 8 (Left) compares the memorization rates across a lineage of large models released by\nGoogle. We order these models in reverse chronological order, with the newest model on the left. We\nfindthattheGemini2.Xmodelfamilymemorizeslong-formtextatamuchlowerrate(notethelog-axis)\nthanpriormodels. Moreover,wefindthatalargerproportionoftextischaracterizedasapproximately\nmemorized by the Gemini 2.0 Flash-Lite and Gemini 2.5 Flash models in particular, which is a less\nsevere form of memorization; further, we see that approximate memorization is decreasing over\ntime as well. This continues a trend of a relative increase in approximate memorization to exact\nmemorization (c.f. 1.5x for Gemma and 14x for Gemini 1.5).\nNext, we study the rate at which the content that was characterized as memorized using our\ndefinitionsalsoarecharacterizedascontainingpotentiallypersonalinformation. Tocharacterizethis,\nweusetheGoogleCloudSensitiveDataProtection(SDP)service.4 Thistoolusesbroaddetectionrules\nto classify text into many types of potentially personal and sensitive information. SDP is designed to\nhave high recall and does not consider the context in which the information may appear, which leads\nto many false positives. Thus, we are likely overestimating the true amount of potentially personal\ninformationcontainedintheoutputsclassifiedasmemorized. SDPalsoprovidesbroadseveritylevels:\nlow, medium, and high. We classify text as personal if SDP classifies it as personal information at any\nseveritylevel. Figure8(Right)showstheresultsofthisanalysis. Weobservednopersonalinformation\nintheoutputscharacterizedasmemorizationforGemini2.Xmodelfamilymodels;thisindicatesalow\nrate of personal data in outputs classified as memorization that are below our detection thresholds.\nHere, we can also clearly see the trend of reduced memorization rates overall.\nExtractable Memorization and Divergence\nNasr et al. (2023) showed that aligned models may also emit data that is classified as memorization\n4Availableat:https://cloud.google.com/sensitive-data-protection\n25"
    },
    {
      "page": 26,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 8 | (Left) Total memorization rates for both exact and approximate memorization. Gemini\n2.X model family memorize significantly less than all prior models. (Right) Personal information\nmemorization rates. We observed no instances of personal information being included in outputs\nclassified as memorization for Gemini 2.X, and no instances of high-severity personal data in outputs\nclassified as memorization in prior Gemini models.\nundercertaincircumstances. Inparticular,theydesigneda“divergenceattack”thatsometimesbreaks\nthe alignment of a language model by filling its context with many repeated tokens. We evaluate\nGemini 2.X model family models to understand their susceptibility to diverging, and in particular, to\nemitting data classified as memorization as a result of this attack.\nWe follow the same test as in Gemini Team (2024). We prompt the model a total of 3750 times,\nevenly split across 125 different single-token characters. We first classify when the model returns\ndiverged outputs, and in these cases, we then determine how many of these outputs match training\ndata, i.e., are classified as memorization.\nOverall,wefindthatdivergenceoccursroughly69%ofthetimeforGemini2.0Flash+Flash-Lite\nand roughly 59% of the time for the Gemini 2.5 model family. In cases where the model did not\ndiverge, we often observed it was because the model refused to repeat content or because the model\nwas confused by the request. When divergence was successful, we found that the rate of text emitted\nclassified as memorization was roughly 0.2%. In these cases, we found that the text was often\nboilerplate code or web content.\n5.7. Assurance Evaluations and Frontier Safety Framework\nAssuranceevaluationsareour‘arms-length’internalevaluationsforresponsibilitygovernancedecision\nmaking (Weidinger et al., 2024). They are conducted separately from the model development team,\nto inform decision-making about release. High-level findings are fed back to the model development\nteam, but individual prompt sets are held-out to prevent overfitting.\nBaseline Assurance\nOur baseline assurance evaluations are conducted for model release decision-making. They look at\nmodel behaviour related to content policies, unfair bias and any modality-specific risk areas. They\nwereperformedfor2.5Proand2.5FlashinlinewiththepreviousGemini2.0releasesandtheGemini\n26"
    },
    {
      "page": 27,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n1.5 tech report, covering all modalities in the Gemini 2.5 model family.\nDatasetcompositionisanessentialcomponentofourassuranceevaluationrobustness. Astherisk\nlandscape changes and modalities mature, we update our adversarial datasets to maintain quality\nand representativeness. This constant evolution of datasets can make strict comparisons between\nmodel family evaluations difficult. However, we provide a qualitative assessment of evaluation trends\nover time below.\nFor child safety evaluations, we continue to see the Gemini 2.5 family of models meeting or\nimproving upon launch thresholds, which were developed by expert teams to protect children online\nand meet Google’s commitments to child safety across our models and Google products.\nFor content policies, we see the Gemini 2.5 family of models displaying lower violation rates in\nmost modalities than Gemini 1.5 and 2.0 families, which in turn was a significant improvement on\nGemini 1.0. When looking at violation rates across input modalities for 2.5 Pro and 2.5 Flash (i.e.\ntext, image, video, audio), we observe the image to text modality has a relatively higher violation\nrate, though the overall violation rates remained low. We also observed that violation rates for 2.5\nPro and 2.5 Flash tended to be slightly higher with thinking traces visible.\nWithin our evaluations for unfair bias, we observed a reduction in ungrounded inferences about\npeople in image understanding relative to Gemini 1.5. Ungrounded inferences are inferences that\ncannot be made based on the provided image and text prompt, where ideally the model would\nrefuse to infer an answer. A high rate of ungrounded inferences about people may create greater risk\nof stereotyping, harmful associations or inaccuracies. Though we saw a reduction in ungrounded\ninferences across the board in Gemini 2.0 and 2.5, there was disparity in refusal behaviour by skin\ntone of the person in the image. We observed models tended to be more likely to make ungrounded\ninferences about images of people with lighter skin tones than darker skin tones. The Gemini 2.5\nfamily otherwise behaved similarly on our unfair bias evaluations to Gemini 1.5. We continue to\nexplore and expand our understanding of unfair bias in Gemini models.\nFindings from these evaluations were made available to teams deploying models, informing\nimplementation of further product-level protections such as safety filtering. Assurance evaluation\nresults were also reported to our Responsibility & Safety Council as part of model release review.\nFrontier Safety Framework Evaluations\nGoogle DeepMind released its Frontier Safety Framework (FSF)(Google DeepMind, 2025a) in May\n2024 and updated it in February 2025. The FSF comprises a number of processes and evaluations\nthat address risks of severe harm stemming from powerful capabilities of our frontier models. It\ncovers four risk domains: CBRN (chemical, biological, radiological and nuclear information risks),\ncybersecurity, machine learning R&D, and deceptive alignment.\nThe Frontier Safety Framework involves the regular evaluation of Google’s frontier models to\ndetermine whether they require heightened mitigations. More specifically, the FSF defines critical\ncapability levels (CCLs) for each area, which represent capability levels where a model may pose a\nsignificant risk of severe harm without appropriate mitigations.\nWhenconductingFSFevaluations,wecomparetestresultsagainstinternalalertthresholds(“early\nwarnings”) which are set significantly below the actual CCLs. This built-in safety buffer helps us be\nproactive by signaling potential risks well before models reach CCLs. Concretely, our alert thresholds\nare designed such that if a frontier model does not reach the alert threshold for a CCL, models are\nunlikely to reach that CCL before the next regular testing—which we conduct at a regular cadence\nand also when we anticipate or see exceptional capability progress. Our recent paper (Shah et al.,\n27"
    },
    {
      "page": 28,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nKeyResultsforGemini2.5Pro\nArea (uptoversion06-05) CCL CCLreached?\nP\nBased on qualitative assessment, 2.5 Pro UpliftLevel1 × CCLnotreached\nCBRN\ndemonstrates a general trend of increasing\nmodelcapabilitiesacrossmodels1.5Pro,2.0\nand 2.5 Pro: it generates detailed technical\nknowledgeofbiological,radiologicalandnu-\nclear domains. However, no current Gem-\ninimodelconsistentlyorcompletelyenables\nprogressthroughkeybottleneckstages.\nŁ Solve rate on autonomous offense suite: AutonomyLevel1 × CCLnotreached\nCybersecurity 74/76easy,11/13medium,1/13hard.\nOn key skills benchmark: 7/8 easy, 14/28 UpliftLevel1 × CCLnotreached\nmedium,6/12hard.\n˘ RE-Bench(Wijketal.,2025): thebestagent AutonomyLevel1 × CCLnotreached\nMachine solutionsachievebetween50%and125%of\nLearningR&D thescoreofthebestexpert-writtensolutions. UpliftLevel1 × CCLnotreached\nInstrumental\nfi\nGemini2.5Prosolves2/5stealthchallenges ReasoningLevel1 × CCLnotreached\nDeceptive\nand2/11situationalawarenesschallenges. Instrumental\nAlignment ReasoningLevel2 × CCLnotreached\nTable 10 | Summary results. Across all areas covered by the Frontier Safety Framework, Critical\nCapabilityLevels(CCLs)havenotbeenreached. Gemini2.5Proisthereforeunlikelytoposesignificant\nrisk of severe harm. For descriptions of each CCL, see main text.\n2025) discusses this approximate continuity assumption in more depth in Section 3.5.\nCCL Evaluation Results\nBecause Gemini 2.5 Pro showed marked improvements across the board compared to Gemini 2.0\nPro, we ran our full suite of evaluations. While there are increased scores in some areas, we find\nthat Gemini 2.5 Pro (up to version 06-17) does not reach any of the FSF CCLs. The evaluations\ndid reach an alert threshold for the Cyber Uplift 1 CCL, suggesting that models may reach the CCL\nin the foreseeable future. Consistent with the FSF, we are putting in place a response plan which\nincludes testing models’ cyber capabilities more frequently and accelerating mitigations for them. For\notherCCLs,ourevaluationsofGemini2.5Proindicatethatmodelsdevelopedbeforethenextregular\ntesting interval are unlikely to reach CCLs. See Table 10 for a summary of results.\nCBRN\nCBRN Uplift Level 1 CCL Definition: “The model can be used to significantly assist a low-\nresourced actor with dual-use scientific protocols, resulting in a substantial increase in ability to\ncause a mass casualty event.”\n28"
    },
    {
      "page": 29,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nCCL reached? No. The model demonstrated accurate and detailed technical capabilities,\npotentially lowering barriers across multiple operational stages of certain harm journeys for\nlow-resourced actors. While its consolidation and supplementation of fragmented procedures\nprovides incremental uplift over what is readily available through open source search alone,\nit does not yet consistently or completely enable progress through key bottleneck stages, and\nthereforedoesnotcrosstheCCL.Further,whileGemini2.5generatesaccurateandmoredetailed\nresponses than 2.0, many of the concepts/outputs observed were already accessible through\nmultiturn or even singleturn prompting in 2.0.\nOverview: We perform CBRN evaluations internally and via third party external testers (see sec-\ntion 5.8). Here, we report solely on internal evaluations, for which we use two different types of\napproaches to evaluate the models’ dual-use CBRN capabilities:\n• Close-ended multiple choice questions (MCQs) providing a quantitative grade.\n• Open-ended questions (OEQs) which address different succinct steps of a longer multi-step\njourney that are qualitatively assessed by domain experts.\nCurrently we do not run specific open-ended qualitative assessments of chemical information risks\nfor our internal evaluations. However, our third party external testers include chemistry in their\nassessments.\nMultipleChoiceQuestions: Theunderlyingassumptionwhenusingknowledge-basedandreasoning\nMCQs is that if the model cannot answer these questions properly, it is less likely to be able to cause\nsevere harm: the type of information in the MCQs is the type of information that is necessary, but\nnot sufficient to help malicious actors cause severe harm. Examples of model performance on three\nexternal benchmarks are shown in Figure 9: i) SecureBio VMQA single-choice; ii) FutureHouse\nLAB-Benchpresentedasthreesubsets(ProtocolQA,CloningScenarios,SeqQA)(Laurentetal.,2024);\nand iii) Weapons of Mass Destruction Proxy (WMDP) presented as the biology and chemistry data\nsets (Li et al., 2024).\nResults: We observe a general trend of increasing scores, with Gemini 2.5 Pro showing statistically\nhigher scores than the next best previous model for all benchmarks.\nOpen-Ended Questions: This qualitative assessment was performed for biological, radiological and\nnuclear domains; it includes knowledge-based, adversarial and dual-use content. Questions span\na range of difficulty levels, from questions a non-expert in these domains might ask, to questions\nthat mostly an expert with a PhD plus many years of experience could pose or answer correctly. The\nprompts and scenarios span different threat journeys (e.g. types of actors, equipment used, harm\nintended). This qualitative assessment, led by domain experts, allows for better visibility of the\ngranular improvement in science capabilities (e.g. accuracy, completeness, actionability of responses).\nResults: We observe that the same prompts used on previous models result in Gemini 2.5 Pro often\ngenerating detailed and accurate responses. In particular domains, some answers were technically\nprecise and potentially actionable, but the model did not consistently or completely enable progress\nthrough all key bottleneck steps.\n29"
    },
    {
      "page": 30,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 9 | List of Gemini models and their performance on a selection of external multiple-choice\nquestion benchmarks for biology and chemistry. In order to control for inherent model stochasticity,\nand position bias in selection of correct answers, we shuffled the answer choices over 100 runs for\neach benchmark and we report here the mean solve rate.\nCybersecurity\nCyber Autonomy Level 1 CCL Definition: “The model can be used to drastically reduce the\ncost (e.g. through full automation) of carrying out end-to-end cyberattacks on organizations with a\nlimited security posture.”\nCCL reached? No. While Gemini 2.5 Pro’s performance on our cybersecurity evaluations has\nincreased significantly compared to previous Gemini models, the model still cannot consistently\ncomplete roughly half of our medium and hard difficulty challenges.\nCyber Uplift Level 1 CCL Definition: “The model can be used to significantly assist with high\nimpactcyberattacks,resultinginoverallcost/resourcereductionsofanorderofmagnitudeormore.”\nCCL reached? No. While Gemini 2.5 Pro’s capabilities exhibit an increase in performance on\nmultiple phases of real-world cyber attacks compared to previous models, they are still limited.\nThe model still struggles with many of our hard challenges, which are most representative of\nreal-world scenarios. The model’s performance is strong enough that it has passed our early\nwarning alert threshold. That is, we find it possible that subsequent revisions in the next few\nmonths could lead to a model that reaches the CCL. In anticipation of this possibility, we have\naccelerated our mitigation efforts.\nOverview: To estimate capabilities relevant to these CCLs, we use our existing suite of cybersecurity\nchallenges (Phuong et al., 2024) combined with a new benchmark described below. We consider\ndifficultylevelsrangingfromeasy(atthelevelofacollegestudent),medium(atthelevelofagraduate\nstudent), and hard (at the level of an experienced cybersecurity professional).\nExisting challenges: These take the form of capture-the-flag evaluations covering three difficulty\nlevels: easy (InterCode-CTF, Yang et al. (2023), medium (our in-house suite), and hard (Hack the\n30"
    },
    {
      "page": 31,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBox). See Phuong et al. (2024) for details. These evaluations are only relevant to Autonomy Level 1\n(poor performance on these evaluations rules out capabilities sufficient for full automation), but not\nUplift Level 1, since humans could still be accelerated on attack phases not covered.\nKey skills benchmark: Complementing our existing suite, we created a new evaluation framework\n(Rodriguez et al., 2025) that increases the realism as well as coverage across and within the attack\nchain of our cyber evaluations. We drew from real-world threat intelligence and input from experts\nto identify a representative set of cyber attacks. From there, we determined the key skills areas that\nwould be required to execute them. We identified four key areas:\n1. Reconnaissance (the application of finding and researching different knowledge and data and\napplying it in a cybersecurity context);\n2. Tool development (the ability to design and create software that is cybersecurity-specific);\n3. Tool usage (the ability to leverage common and cybersecurity-specific tools to achieve routine\ninstrumental cyber goals);\n4. Operational security (the skill of remaining hidden during and after a cyber operation).\nWeinstantiatethisbenchmarkbymapping48challengesfromanexternalvendortothisspecification.\nWe also use these evaluations as a proxy for uplift capability, for Cyber Uplift Level 1. Even partial\nautomation of these key skills could mean fewer resources are needed for sophisticated cyberattacks.\nElicitation: We utilize a simple harness which prompts the agent to think about its plans and adjust\nthem to solve the challenge. The agent can execute Bash commands and run Python scripts. We run\nbetween 10 and 50 attempts at each challenge, depending on the challenge suite. We consider a\nchallenge solved if at least one of those attempts succeeds in capturing the flag.\nResults: See Figures 10 and 11 for numerical results. Model capabilities have increased to the point\nwhere InterCode-CTF and our in-house CTF challenges are too easy, but the Hack the Box challenges\narestilltoodifficult-suchthatthesethreeevalsgivelittlesignalonhowGemini2.5modelscompare\nto previous generations. However, on our more fine-grained key skills benchmark, Gemini 2.5 models\nshowsignificantincreasesincapabilitycomparedtoGemini2.0modelsthroughoutallthreedifficulty\nlevels. In particular, Gemini 2.5 Pro shows surprisingly high aptitude at the hard challenges. It solves\n6/12 challenges—challenges at the level of an experienced cybersecurity professional.\n31"
    },
    {
      "page": 32,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 10 | Results on autonomous cyber offense suite. These benchmarks are based on “capture-the-\nflag” (CTF) challenges, in which the agent must hack into a simulated server to retrieve a piece of\nhiddeninformation. Labelsabovebarsrepresentthenumberofsolvedandtotalnumberofchallenges.\nA challenge is considered solved if the agent succeeds in at least one out of N attempts, where we\nvary N between 5 and 30 depending on challenge complexity. Both InterCode-CTF and our in-house\nCTFs are now largely saturated, showing little performance change from Gemini 2.0 to Gemini 2.5\nmodels. In contrast, the Hack the Box challenges are still too difficult for Gemini 2.5 models, and so\nalso give little signal on capability change.\nFigure 11 | Results on our new “key skills” benchmark. This benchmark also consists of “capture-the-\nflag”(CTF)challenges,butthesechallengesaretargetedatkeyskillsrequiredtoexecutecyber-attacks:\nreconnaissance, tool development, tool usage and operational security. A challenge is considered\nsolved if the agent succeeds in at least one out of N attempts, where N = 30-50 for the 2.5 Pro run\nand N = 10-30 for the other models, depending on the challenge complexity. Note that for 2.0 Pro\nwe omit results from five challenges and so 2.0 results are not directly comparable. Here, Gemini\n2.5 family models show significant increase in capability at all three difficulty levels. Particularly of\nnote is Gemini 2.5 Pro solving half of the hard challenges - challenges at the level of an experienced\ncybersecurity professional.\n32"
    },
    {
      "page": 33,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nMachine Learning R&D\nMachine Learning R&D Autonomy Level 1 CCL Definition: “The model can fully automate\nthe AI R&D pipeline at a competitive cost. The cost comparison is relative to humans augmented by\nAI tools.”\nCCL reached? No. On RE-Bench, although the gap between Gemini and expert humans has\nshrunk, the model still doesn’t reach our early warning threshold (which is based on a specific\naveragescoreoverallchallenges). NotethatRE-benchcomprisesrelativelylow-contexttaskswith\na limited time horizon (calibrated to allow significant progress by humans experts in 8 hours),\nand represents a small subset of the tasks comprising the full AI R&D pipeline.\nMachine Learning R&D Uplift Level 1 CCL Definition: “The model can or has been used\nto accelerate AI development, resulting in AI progress substantially accelerating (e.g. 2x) from\n2020-2024 rates.”\nCCL reached? Likely no. We do not yet have dedicated evaluations for this CCL, but given\nthat Gemini does not yet reach our early warning threshold on Autonomy Level 1, the model\nlikely lacks the necessary capabilities to automate or significantly uplift any significant fraction of\nthe research process.\nTo evaluate Gemini 2.5 models’ potential for accelerating ML R&D, we ran the open-source Research\nEngineering Benchmark (Wijk et al., 2025). This benchmark comprises seven machine learning\nchallenges difficult enough to take a human practitioner several hours to complete. For example, in\ntheOptimizeLLMFoundrychallenge,themodelmustspeedupafine-tuningscriptwhilekeepingthe\nresulting model the same. We omit two challenges, Finetune GPT-2 for QA and Scaffolding for Rust\nCodecontest since they require internet access, which we disallow for security reasons.\nThe model is equipped with METR’s modular scaffold with minimal adjustment. Following the\noriginal work, we simulate a scenario in which the agent has a total time budget of 32 hours and the\nagent may choose a tradeoff between the number of runs and the length of each run. We evaluate\ntwo settings: 43 runs with a time limit of 45 minutes each, and 16 runs with a time limit of 2 hours\neach. For each setting, we aggregate scores across runs using the method described in the original\nwork (Wijk et al., 2025). This involves taking a number of bootstrap samples, taking the maximum\nscoreovereachsample,andcalculatingaconfidenceintervalusingpercentilesoftheresultingvalues.\n(FortheScalingLawExperimentchallenge,becausethescoreisnotvisibletotheagentandtherefore\nthe agent would not be able to pick run results based on the best score, we instead bootstrap the\nmean using all scores.) For the 45 minute setting, we do 64 actual runs, but sample only 43 runs for\neach bootstrap sample. Similarly for the 2 hour setting, we do 24 runs.\nGemini 2.5 Pro’s best runs score between 50% and 125% of the best human-written solutions.\nDespite this, the model does not reach our alert threshold, which was set higher than the human\nperformance in view of the fact that RE-bench contains low-context and limited time horizon tasks\nthat we expect to be especially easy for AI systems to reach human parity on. Some of the model’s\nsolutions are nevertheless quite interesting. For example, in the Restricted Architecture MLM task,\nthe agent is tasked with implementing a language model without use of basic primitives such as\ndivision and exponentiation. This seemingly simple constraint invalidates modern architectures like\n33"
    },
    {
      "page": 34,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\ntheTransformer,whoseattentionmechanismandnormalizationlayersrelyheavilyontheseforbidden\noperations. In one attempt, Gemini 2.5 Pro realises it can achieve this by drawing inspiration from\naspectsoftheMLP-Mixerarchitecture(Tolstikhinetal.,2021)—anon-trivialinsightthatdrawsonits\nextensive knowledge of the research literature. In effect, creativity is substituted by knowledge.\nFigure 12 | Results on the Research Engineer Benchmark (RE-Bench), in which the model must\ncomplete simple ML research tasks. Following the original work, scores are normalised against a\ngood quality human-written solution: if a model achieves a score 𝑦 on a challenge, the normalised\nscore is (𝑦− 𝑦 𝑠)/(𝑦 𝑟 − 𝑦 𝑠), where 𝑦 𝑠 is the “starting score” of a valid but poor solution provided to the\nmodel as an example, and 𝑦 𝑟 is the score achieved by a reference solution created by the author of\nthe challenge. Figures for Claude 3.5 Sonnet and expert human performance are sourced from the\noriginal work. The number of runs and the time limit for each run are constrained by a total time\nbudget of 32 hours, and error bars indicate bootstrapped 95% confidence intervals; see main text for\ndetails. Gemini 2.5 Pro is moderately strong at these challenges, achieving a significant fraction of\nexpert human performance—and in two cases surpassing it.\nDeceptive Alignment\nInstrumental Reasoning Level 1 CCL Definition: “The instrumental reasoning abilities of\nthe model enable enough situational awareness (ability to work out and use relevant details of its\ndeployment setting) and stealth (ability to circumvent basic oversight mechanisms) such that, absent\nadditional mitigations, we cannot rule out the model significantly undermining human control.”\nCCL reached? No. Gemini 2.5 Pro does not perform competently enough on both the stealth\nand situational awareness challenges. Qualitatively, the model often fails to reason through its\nsituationandfindacrediblestrategy;italsosometimesstruggleswithplanningandlong-horizon\nreasoning. It partially displays situational awareness but most of the time, it fails to understand\nand intervene on its environment/deployment setting.\n34"
    },
    {
      "page": 35,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nInstrumental Reasoning Level 2 CCL Definition: “The instrumental reasoning abilities of\nthe model enable enough situational awareness and stealth that, even when relevant model outputs\n(including, e.g., scratchpads) are being monitored, we cannot detect or rule out the risk of a model\nsignificantly undermining human control.”\nCCL reached? No. This threshold is strictly higher than Instrumental Reasoning Level 1.\nOurdeceptivealignmentevaluationsmeasurestealthcapabilitiesandsituationalawarenesscapabilities\nseparately, using two separate sets of challenges.\nStealth: In these challenges, the model is tasked with a devious objective and must achieve that\nobjective without raising suspicion. For example, one challenge is a customer support scenario where\nthe model deals with incoming support tickets. The agent is tasked with resolving as many tickets as\npossible while complying with the company’s protocols. There are ways to cheat at this (resulting in\nmore tickets resolved)—but if the model does decide to cheat, it must not be caught by an overseer.\nHere we measure performance relative to the score that humans get when they do the challenge.\nSituational awareness: These challenges test whether the model can reason about itself as an agent\nembedded in the deployment environment, and to intervene on it in service of a goal. Many of them\ntest whether the model can realise that it needs to give itself more affordances, e.g. by changing\nconfiguration files that place constraints on its action space. The agent may need to, say, turn off\nswear word filtering in order to write an angry email. For more details of these evaluations, see\n(Phuong et al., 2025).\nResults: We ran these evaluations on Gemini 2.5 Pro Preview 03-25. All of the results reported are\nwith50retriesandinvolveamodelequippedwithscaffoldsthatuseschain-of-thoughtreasoningand\nreflection to enhance context utilization and better planning. Broadly, Gemini 2.5 Pro exhibits poor\nperformance on situational awareness evaluations, and moderate performance in stealth evaluations.\nAcross 50 trials, Gemini 2.5 Pro has no successes on 8 of our suite of 11 situational awareness\nevaluations. Among the remaining evaluations, the highest performance is achieved on a “Disabled\nTool” challenge, in which Gemini is run in an agentic environment and has to grant itself access to\nmore tools though configuration changes (42% success rate across 50 trials). For stealth evaluations,\nGemini 2.5 Pro achieves low rates of success on 3/5 challenges. It achieves a ~44% success rate on\nthe Decision Sabotage challenge and a ~35% success rate on the Oversight Pattern challenge, which\nis similar to human performance.\nFrontier Safety: Summary\nGemini 2.5 Pro was evaluated against the Critical Capability Levels defined in our Frontier Safety\nFramework, which examines risk in CBRN, cybersecurity, machine learning R&D, and deceptive\nalignment. Based on these results, we find that Gemini 2.5 Pro (up to version 06-17) does not reach\nany of the Critical Capability Levels in any of these areas.\nHowever, it showed some ability in all four areas. For example, in our evaluation of Machine\nLearningR&Dcapabilities,whilethemodel’saverageperformancewaslowerthanthehumanbaseline,\nin two cases its best performances exceeded even the best expert human-written reference solutions.\nGemini 2.5 Pro also showed a significant increase in some capabilities, such as cyber uplift,\ncompared to previous Gemini models. Following our Frontier Safety Framework, we are putting in\n35"
    },
    {
      "page": 36,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nplace a response plan, including conducting higher frequency testing and accelerating mitigations for\nthe Cyber Uplift Level 1 CCL. As reported above, no model reached the CCL in these additional tests.\nLooking ahead, these evaluations are key to safe deployment of powerful AI systems. We will\ncontinuetoinvestinthisarea,regularlyperformingFrontierSafetyFrameworkevaluationstohighlight\nareas where mitigations (e.g. refusal to respond to prompts that return dangerous results) must be\nprioritized.\n5.8. External Safety Testing\nAs outlined in the Gemini 1.5 Technical Report (Gemini Team, 2024), as part of our External Safety\nTesting Program, we work with a small set of independent external groups to help identify areas for\nimprovement in our model safety work by undertaking structured evaluations, qualitative probing,\nand unstructured red teaming. As a heuristic, the External Safety Testing Program reviews the most\ncapable Gemini models, with the largest capability jumps. As such, testing was only carried out on\nthe2.0Proand2.5Promodels,includingonearlyversionsofbothmodels. Atthetimeofwritingwe\nhavenotcarriedoutexternalsafetytestingontheFlashmodels. TheExternalSafetyTestingProgram\nfocused testing on an early version of Gemini 2.5 Pro (Preview 05-06) to capture early findings and\ndid not test the final model candidate which went to GA.\nForGemini2.5Pro,ourexternaltestinggroupsweregivenblack-boxtestingaccesstoGemini2.5\nPro (Preview 05-06) on AI Studio for a number of weeks. This enabled Google DeepMind to gather\nearly insights into the model’s capabilities and understand if and where mitigations were needed.\nTesting groups had the ability to turn down or turn off safety filters, in line with what is available on\nAI Studio.\nThese groups were selected based on their expertise across a range of domain areas, such as\nautonomous systems, societal, cyber, and CBRN risks. Groups included civil society and commercial\norganizations. The groups testing the model checkpoints were compensated for their time.\nExternalgroupswerebydesigninstructedtodeveloptheirownmethodologytotesttopicswithina\nparticulardomainarea,remainingindependentfrominternalGoogleDeepMindevaluations. Thetime\ndedicated to testing also varied per group, with some groups being dedicated full-time to executing\ntesting processes, while others were part-time dedicated. Some groups pursued manual red-teaming\nandreportedonqualitativefindingsfromtheirexplorationofmodelbehavior,whileothersdeveloped\nbespoke automated testing strategies and produced quantitative reports of their results.\nWhilereportswerewrittenindependentlyofGoogleDeepMind,ourinternalsubjectmatterexperts\nwere on hand to understand the external testing groups’ methodologies and findings throughout the\ntesting process.\nExternal safety testing groups shared their analyses and findings, as well as the raw data and\nmaterials they used in their evaluations (e.g., prompts, model responses). After testing, we internally\nreviewed the data and model output transcripts in detail, and Google DeepMind subject matter\nexperts assigned severity ratings to outputs, based on our internal harm frameworks and safety\npolicies, and noted whether these cross the Critical Capability Levels outlined in different domains\n(Google DeepMind, 2025a). We then communicated findings back to modelling teams and product\npolicy teams (both within Google DeepMind and across Alphabet) and reported these as part of our\ngovernance processes. Our external testing findings also help us identify gaps in our existing internal\nevaluation methodologies and safety policies.\nWe’ve outlined some of the high-level insights from our external testing across the domain areas\ntested, including autonomous systems, cyber misuse, CBRN, and societal risks.\n36"
    },
    {
      "page": 37,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nAutonomous systems risks\nAn external group tested models for autonomous systems risks, focusing on models’ ability and\npropensitytocovertlypursuemisalignedgoals. Theevaluationsconsistofsettingswherethemodelis\ngiven a goal that requires deception, scheming, or sabotage to achieve. Evaluations were focused on:\n• Strategic deception: testing the model’s propensity to deceive a user or developer about the\nactions it took.\n• In-contextschemingreasoning: testingthemodel’scapabilitiesinthisdomainwherescheming\nis an effective strategy.\n• Sabotage capabilities: assessing the model’s ability to compromise other language models\nwith overt actions.\nOverallexternalresearcherssuggestedthatGemini2.5Pro(Preview05-06)hadasimilarscheming\ncapability to other models evaluated. External researchers noted that the model is not sufficiently\ncapableofcausingcatastrophicharmsonrolloutswhereitisscheming. However,externalresearchers\nnoted minor harms such as reward-hacking may be possible, which could potentially lead to a\ndegraded user experience.\nComplementingthesetests,GoogleDeepMind’sDeceptiveAlignmentevaluations(seeSection5.7)\nprovide evidence that the risk of severe harm is low due to the models’ limited situational awareness\ncapabilities.\nCyber misuse risks\nCybersecurity risks\nExternal cyber evaluations focused on assessing the ability for malicious actors to enhance existing\nattackvectorsacrossarangeofkeycyberskills,suchasvulnerabilitydiscovery,vulnerabilityexploita-\ntion, social engineering, and cyberattack planning (capability uplift). Testers also focused on the\nmodel’s ability to accelerate repetitive or time-consuming elements of cyber operations, enabling\nincreased scale (throughput uplift).\nEvaluations were conducted within simulated environments that realistically represented a range\noftargetsystems,networks,andsecuritycontrols. Thisinvolvedsettingupvirtualnetworksmimicking\nenterprise infrastructure, deploying realistic software vulnerabilities, and simulating user behaviors\nin social engineering scenarios.\nEvaluations strived to incorporate elements of real-world constraints and complexities. This\nincluded introducing noisy data, limited information availability, or adversarial defenses that the AI\nmodel must overcome, mirroring the challenges faced by attackers in live operations.\nFindingsfromtheseevaluationsconcludedthatGemini2.5Prowasacapablemodelforcybersecu-\nritytasks,showingmarkedincreaseinabilityfromGemini1.5Pro. Complementingtheseevaluations,\nthe GDM Cyber team conducted their own tests, and found similarly high levels of capability (see\nSection 5.7).\nIndirect Prompt Injections\nThe model was evaluated for patterns of susceptibility to indirect prompt injection attacks. In\nparticular, the model was tested for vulnerabilities in function calls and potential asymmetries that\nexist across security measures. The model was also tested to understand how different domains yield\n37"
    },
    {
      "page": 38,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nhigher hijack rates. In line with internal evaluations and mitigations in this space (Section 5.5), we\nare continuing to evolve how we monitor and measure the resilience of increasingly capable Gemini\nmodels.\nCBRN risks\nChemical and Biological risks\nIn addition to our internal evaluations described above (Section 5.7) capabilities in chemistry and\nbiology were assessed by an external group who conducted red teaming designed to measure the\npotential scientific and operational risks of the models. A red team composed of different subject\nmatter experts (e.g. biology, chemistry, logistics) were tasked to role play as malign actors who want\nto conduct a well-defined mission in a scenario that is presented to them resembling an existing\nprevailing threat environment. Together, these experts probe the model to obtain the most useful\ninformation to construct a plan that is feasible within the resource and timing limits described in the\nscenario. Theplanisthengradedforbothscientificandlogisticalfeasibility. Basedonthisassessment,\nGDM addresses any areas that warrant further investigation.\nExternal researchers found that the model outputs detailed information in some scenarios, often\nproviding accurate information around experimentation and problem solving. However, researchers\nfound steps were too broad and high level to enable a malicious actor.\nRadiological and Nuclear risks\nRisks in the radiological and nuclear domains were assessed by an external group using a structured\nevaluation framework for red teaming. This incorporated single-turn broad exploration across the\nfull risk chain and multi-turn targeted probing for high risk topics.\nAssessments were structured around threat actors and harm pathways without measuring model\nuplift, evaluating responses based on accuracy, actionability, and dual-use potential, with additional\nscrutiny applied to the model’s thought summaries when applicable. External researchers found\nthat model responses within this domain were accurate but lacked sufficient technical detail to be\nactionable.\nSocietal risks\nFor the Gemini 2.5 Pro (Preview 05-06) model, external researchers focused on democratic harms\nand radicalisation, with an emphasis on how the model might be used by malicious actors. Risks in\nthisdomainfocusedonstructuredevaluations. Themodelwastestedonitsabilitytoidentifyharmful\ninputs and the extent to which it complied with harmful requests. As no internal evaluations mirror\nthese precise domain harms, the External Safety Testing Program shared these findings with relevant\nteams to ensure monitoring and mitigation where necessary.\n38"
    },
    {
      "page": 39,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n6. Discussion\nIn this report we have introduced the Gemini 2.X model family: Gemini 2.5 Pro, Gemini 2.5 Flash,\nGemini2.0FlashandGemini2.0Flash-Lite. Takentogether,thesemodelsspanthefullParetofrontier\nof model capability vs cost, and Gemini 2.5 Pro is the most capable model we have ever developed.\nGemini2.5Proexcelsacrossawiderangeofcapabilities,andrepresentsastepchangeinperformance\nrelative to Gemini 1.5 Pro. Its coding, math and reasoning performance are particularly notable\nand Gemini 2.5 Pro obtains extremely competitive scores on the Aider Polyglot evaluation, GPQA\n(diamond) and Humanity’s Last Exam.\nAs well as their strong performance on academic benchmarks, entirely new capabilities are\nunlocked with the Gemini 2.5 models. Gemini is now the preferred AI assistant amongst educators\n(LearnLM Team, 2025) and it is now possible for Gemini to take a video of a lecture and create an\ninteractivewebapplicationthatcantestastudent’sknowledgeofthatcontent. Finally,theGemini2.5\nmodels enable exciting new agentic workflows, and have started to power numerous Google products\nalready (Pichai, 2025).\nIn addition to being highly performant, the Gemini 2.5 models maintain strong safety standards\nand, compared to their 1.5 counterparts, are much more helpful. They are less likely to refuse to\nanswer important user queries or respond with an overly sanctimonious tone. Gemini 2.5 exhibited\nnotableincreasesinCriticalCapabilities,includingcybersecurityandmachinelearningR&D.However,\nthe model has not crossed any Critical Capability Levels.\nReflecting on the path to Gemini 2.5, the staggering performance improvement attained over the\nspaceofjustoneyearpointstoanewchallengeinAIresearch: namelythatthedevelopmentofnovel\nand sufficiently challenging evaluation benchmarks has struggled to keep pace with model capability\nimprovements, especially with the advent of capable reasoning agents. Over the space of just a year,\nGemini Pro’s performance has gone up 5x on Aider Polyglot and 2x on SWE-bench verified (one of\nthe most popular and challenging agentic benchmarks). Not only are benchmarks saturating quickly,\nbut every new benchmark that gets created can end up being more expensive and take longer to\ncreate than its predecessor, due to the more restricted pool of experts able to create it. Experts were\npaidupto$5000foreachquestionthatwasacceptedtotheHumanity’sLastExambenchmark(Phan\net al., 2025), and while this benchmark still has significant headroom at the time of writing (June\n2025), performance on it has improved significantly over the space of a few months (with the best\nmodels achieving just a few percent accuracy on it when it was initially published in early 2025).\nWhen one considers agentic systems, which are able to tackle problems for longer and which have\naccess to tools and self critique, the complexity of benchmarks required to measure performance\nalso increases dramatically. Being able to scale evaluations in both their capability coverage and their\ndifficulty, while also representing tasks that have economic value, will be the key to unlocking the\nnext generation of AI systems.\n39"
    },
    {
      "page": 40,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nReferences\nR. Anil, G. Pereyra, A. Passos, R. Ormandi, G. E. Dahl, and G. E. Hinton. Large scale distributed\nneural network training through online distillation, 2018. URL https://arxiv.org/abs/1804\n.03235.\nR. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, et al. PaLM 2 technical report, 2023. URL\nhttps://arxiv.org/abs/2305.10403.\nAnthropic. Claude’s extended thinking, 2025. URL https://www.anthropic.com/research/v\nisible-extended-thinking.\nA.Baddepudi,A.Yang,andM.Lučić. AdvancingthefrontierofvideounderstandingwithGemini2.5,\n2025. URL https://developers.googleblog.com/en/gemini-2-5-video-understan\nding/.\nY. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, et al. Constitutional ai: Harmlessness from ai\nfeedback, 2022. URL https://arxiv.org/abs/2212.08073.\nM. Balunović, J. Dekoninck, I. Petrov, N. Jovanović, and M. Vechev. Matharena: Evaluating llms on\nuncontaminated math competitions, 2025. URL https://arxiv.org/abs/2505.23281.\nP. Barham, A. Chowdhery, J. Dean, S. Ghemawat, S. Hand, D. Hurt, M. Isard, H. Lim, R. Pang, S. Roy,\net al. Pathways: Asynchronous distributed dataflow for ml. Proceedings of Machine Learning and\nSystems,4:430–449,2022. URLhttps://proceedings.mlr.press/v162/barham22a.html.\nA. Beutel, K. Xiao, J. Heidecke, and L. Weng. Diverse and effective red teaming with auto-generated\nrewards and multi-step reinforcement learning, 2024. URL https://arxiv.org/abs/2412.1\n8693.\nS. Biderman, H. Schoelkopf, Q. G. Anthony, H. Bradley, K. O’Brien, et al. Pythia: A suite for analyzing\nlargelanguagemodelsacrosstrainingandscaling.InProceedingsofthe40thInternationalConference\non Machine Learning, 2023. URL https://proceedings.mlr.press/v202/biderman23a.h\ntml.\nN.Carlini,D.Ippolito,M.Jagielski,K.Lee,F.Tramer,andC.Zhang. Quantifyingmemorizationacross\nneural language models. In 2022 IEEE Symposium on Security and Privacy (SP), pages 1113–1130,\n2022. URL https://arxiv.org/abs/2202.07646.\nW.-L. Chiang, L. Zheng, Y. Sheng, A. N. Angelopoulos, T. Li, D. Li, B. Zhu, H. Zhang, M. Jordan, J. E.\nGonzalez, et al. Chatbot arena: An open platform for evaluating llms by human preference. In\nForty-first International Conference on Machine Learning, 2024. URL https://arxiv.org/abs/\n2306.05685.\nA. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung,\nC. Sutton, S. Gehrmann, et al. PaLM: Scaling language modeling with pathways. arXiv preprint\narXiv:2204.02311, 2022. URL https://arxiv.org/abs/2204.02311.\nN. Chowdhury, J. Aung, C. J. Shern, O. Jaffe, D. Sherburn, G. Starace, E. Mays, R. Dias, M. Aljubeh,\nM. Glaese, C. E. Jimenez, J. Yang, L. Ho, T. Patwardhan, K. Liu, and A. Madry. Introducing SWE-\nbench verified, 2024. URL https://openai.com/index/introducing-swe-bench-verif\nied/.\n40"
    },
    {
      "page": 41,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nA. Clark, D. de las Casas, A. Guy, A. Mensch, M. Paganini, J. Hoffmann, B. Damoc, B. Hechtman,\nT. Cai, S. Borgeaud, G. van den Driessche, E. Rutherford, T. Hennigan, M. Johnson, K. Millican,\nA. Cassirer, C. Jones, E. Buchatskaya, D. Budden, L. Sifre, S. Osindero, O. Vinyals, J. Rae, E. Elsen,\nK. Kavukcuoglu, and K. Simonyan. Unified scaling laws for routed language models, 2022. URL\n\"https://arxiv.org/abs/2202.01169\".\nCodeGemma Team, H. Zhao, J. Hui, J. Howland, N. Nguyen, S. Zuo, A. Hu, C. A. Choquette-Choo,\nJ. Shen, J. Kelley, K. Bansal, L. Vilnis, M. Wirth, P. Michel, P. Choy, P. Joshi, R. Kumar, S. Hashmi,\nS. Agrawal, Z. Gong, J. Fine, T. Warkentin, A. J. Hartman, B. Ni, K. Korevec, K. Schaefer, and\nS. Huffman. CodeGemma: Open Code Models Based on Gemma, 2024. URL https://arxiv.or\ng/abs/2406.11409.\nA. Conneau, M. Ma, S. Khanuja, Y. Zhang, V. Axelrod, S. Dalmia, J. Riesa, C. Rivera, and A. Bapna.\nFleurs: Few-shot learning evaluation of universal representations of speech. In 2022 IEEE Spoken\nLanguage Technology Workshop (SLT), pages 798–805. IEEE, 2023.\nM. Dehghani, J. Djolonga, B. Mustafa, P. Padlewski, J. Heek, J. Gilmer, A. P. Steiner, M. Caron,\nR. Geirhos, I. Alabdulmohsin, et al. Scaling vision transformers to 22 billion parameters. In\nInternational Conference on Machine Learning, pages 7480–7512. PMLR, 2023. URL https:\n//proceedings.mlr.press/v202/dehghani23a/dehghani23a.pdf.\nT. Doshi. Build rich, interactive web apps with an updated Gemini 2.5 Pro, 2025a. URL https:\n//blog.google/products/gemini/gemini-2-5-pro-updates/.\nT. Doshi. Gemini 2.5: Our most intelligent models are getting even better, 2025b. URL https:\n//blog.google/technology/google-deepmind/google-gemini-updates-io-2025/.\nN. Du, Y. Huang, A. M. Dai, S. Tong, D. Lepikhin, Y. Xu, M. Krikun, Y. Zhou, A. W. Yu, O. Fi-\nrat, et al. GLaM: Efficient scaling of language models with mixture-of-experts. arXiv preprint\narXiv:2112.06905, 2021. URL https://arxiv.org/abs/2112.06905.\nW. Fedus, B. Zoph, and N. Shazeer. Switch transformers: Scaling to trillion parameter models with\nsimple and efficient sparsity. arXiv preprint arXiv:2101.03961, 2021. URL https://arxiv.org/\nabs/2101.03961.\nC. Fu, Y. Dai, Y. Luo, L. Li, S. Ren, R. Zhang, Z. Wang, C. Zhou, Y. Shen, M. Zhang, et al. Video-mme:\nThe first-ever comprehensive evaluation benchmark of multi-modal llms in video analysis. In\nProceedings of the Computer Vision and Pattern Recognition Conference, pages 24108–24118, 2025.\nURL https://openaccess.thecvf.com/content/CVPR2024/html/Fu_Video-MME_The\n_First-Ever_Comprehensive_Evaluation_Benchmark_of_Multi-Modal_LLMs_in_C\nVPR_2024_paper.html.\nP. Gauthier. Aider Polyglot Coding Leaderboard, 2025. URL https://aider.chat/docs/leader\nboards/.\nGemini Team. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.\narXiv preprint arXiv:2403.05530, 2024. URL https://arxiv.org/abs/2403.05530.\nGemini Team, Google. Gemini Deep Research, 2024. URL https://gemini.google/overview\n/deep-research/.\nGemma Team. Gemma: Open Models Based on Gemini Research and Technology, 2024. URL\nhttps://arxiv.org/abs/2403.08295.\n41"
    },
    {
      "page": 42,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nO. Goldman, U. Shaham, D. Malkin, S. Eiger, A. Hassidim, Y. Matias, J. Maynez, A. M. Gilady, J. Riesa,\nS. Rijhwani, L. Rimell, I. Szpektor, R. Tsarfaty, and M. Eyal. Eclektic: a novel challenge set for\nevaluation of cross-lingual knowledge transfer, 2025. URL https://arxiv.org/abs/2502.2\n1228.\nGoogle DeepMind. Frontier safety framework, February 2025a. URL https://deepmind.googl\ne/discover/governance/frontier-safety-framework/.\nGoogle DeepMind. Gemini 2.0 Flash-Lite, 2025b. URL https://deepmind.google/models/gem\nini/flash-lite/.\nA. Grattafiori, A. Dubey, A. Jauhri, A. Pandey, A. Kadian, et al. The Llama 3 Herd of Models, 2024.\nURL https://arxiv.org/abs/2407.21783.\nD. Hassabis. Our vision for building a universal AI assistant, 2025. URL https://blog.google/\ntechnology/google-deepmind/gemini-universal-ai-assistant/.\nG. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network, 2015. URL\nhttps://arxiv.org/abs/1503.02531.\nK.Hu,P.Wu,F.Pu,W.Xiao,Y.Zhang,X.Yue,B.Li,andZ.Liu. Video-mmmu: Evaluatingknowledge\nacquisition from multi-discipline professional videos, 2025. URL https://arxiv.org/abs/25\n01.13826.\nS.Hughes,M.Bae,andM.Li. VectaraHallucinationLeaderboard,nov2023. URLhttps://github\n.com/vectara/hallucination-leaderboard.\nD. Ippolito, F. Tramer, M. Nasr, C. Zhang, M. Jagielski, K. Lee, C. A. Choquette-Choo, and N. Carlini.\nPreventing verbatim memorization in language models gives a false sense of privacy, 2022. URL\nhttps://arxiv.org/abs/2210.17546.\nA. Jacovi, A. Wang, C. Alberti, C. Tao, J. Lipovetz, K. Olszewska, L. Haas, M. Liu, N. Keating,\nA.Bloniarz,C.Saroufim,C.Fry,D.Marcus,D.Kukliansky,G.S.Tomar,J.Swirhun,J.Xing,L.Wang,\nM. Gurumurthy, M. Aaron, M. Ambar, R. Fellinger, R. Wang, R. Sims, Z. Zhang, S. Goldshtein, and\nD. Das. Facts grounding leaderboard. https://www.kaggle.com/benchmarks/google/fac\nts-grounding, 2024. Google Deepmind, Google Research, Google Cloud, Kaggle.\nA.Jacovi,A.Wang,C.Alberti,C.Tao,J.Lipovetz,K.Olszewska,L.Haas,M.Liu,N.Keating,A.Bloniarz,\netal. Thefactsgroundingleaderboard: Benchmarkingllms’abilitytogroundresponsestolong-form\ninput. arXiv preprint arXiv:2501.03200, 2025. URL https://arxiv.org/abs/2501.03200.\nN. Jain, K. Han, A. Gu, W.-D. Li, F. Yan, T. Zhang, S. Wang, A. Solar-Lezama, K. Sen, and I. Stoica.\nLivecodebench: Holistic and contamination free evaluation of large language models for code,\n2024. URL https://arxiv.org/abs/2403.07974.\nA. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary, C. Bamford, D. S. Chaplot, D. d. l. Casas,\nE. B. Hanna, F. Bressand, et al. Mixtral of experts. arXiv preprint arXiv:2401.04088, 2024. URL\nhttps://arxiv.org/abs/2401.04088.\nC. E. Jimenez, J. Yang, A. Wettig, S. Yao, K. Pei, O. Press, and K. R. Narasimhan. SWE-bench: Can\nlanguage models resolve real-world github issues? In The Twelfth International Conference on\nLearning Representations, 2024. URL https://openreview.net/forum?id=VTF8yNQM66.\n42"
    },
    {
      "page": 43,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nK. Kampf and N. Brichtova. Experiment with Gemini 2.0 Flash native image generation, 2025. URL\nhttps://developers.googleblog.com/en/experiment-with-gemini-20-flash-nat\nive-image-generation/.\nK. Kavukcuoglu. Gemini 2.0 is now available to everyone, 2025. URL https://blog.google/te\nchnology/google-deepmind/gemini-model-updates-february-2025.\nL. Kilpatrick. Gemini 2.5 Pro Preview: even better coding performance, 2025. URL https://deve\nlopers.googleblog.com/en/gemini-2-5-pro-io-improved-coding-performance.\nS. Kudugunta, I. Caswell, B. Zhang, X. Garcia, C. A. Choquette-Choo, K. Lee, D. Xin, A. Kusupati,\nR.Stella,A.Bapna,andO.Firat. MADLAD-400: AMultilingualAndDocument-LevelLargeAudited\nDataset, 2023. URL https://arxiv.org/abs/2309.04662.\nJ. M. Laurent, J. D. Janizek, M. Ruzo, M. M. Hinks, M. J. Hammerling, S. Narayanan, et al. LAB-\nBench: Measuring capabilities of language models for biology research, 2024. URL https:\n//arxiv.org/abs/2407.10362.\nLearnLM Team. Evaluating Gemini in an Arena for Learning, 2025. URL https://goo.gle/Lear\nnLM-May25.\nJ. Lee, A. Chen, Z. Dai, D. Dua, D. S. Sachan, M. Boratko, Y. Luan, S. M. Arnold, V. Perot, S. Dalmia,\net al. Can long-context language models subsume retrieval, rag, sql, and more? arXiv preprint\narXiv:2406.13121, 2024. URL https://arxiv.org/abs/2406.13121.\nJ. Lei, T. L. Berg, and M. Bansal. Detecting moments and highlights in videos via natural language\nqueries. Advances in Neural Information Processing Systems, 34:11846–11858, 2021.\nD. Lepikhin, H. Lee, Y. Xu, D. Chen, O. Firat, Y. Huang, M. Krikun, N. Shazeer, and Z. Chen. GShard:\nScaling giant models with conditional computation and automatic sharding. In International\nConference on Learning Representations, 2020. URL https://openreview.net/forum?id=qr\nwe7XHTmYb.\nN. Li, A. Pan, A. Gopal, S. Yue, D. Berrios, A. Gatti, et al. The WMDP benchmark: Measuring and\nreducing malicious use with unlearning, 2024. URL https://arxiv.org/abs/2403.03218.\nL. Liu, X. Liu, J. Gao, W. Chen, and J. Han. Understanding the difficulty of training transformers.\narXiv preprint arXiv:2004.08249, 2020. URL https://arxiv.org/abs/2004.08249.\nLMArena Team. Webdev arena, 2025. URL https://web.lmarena.ai/leaderboard.\nS. B. Mallick and L. Kilpatrick. Gemini 2.0: Flash, Flash-Lite and Pro, 2025. URL https://develo\npers.googleblog.com/en/gemini-2-family-expands/.\nA. Mehrotra, M. Zampetakis, P. Kassianik, B. Nelson, H. Anderson, Y. Singer, and A. Karbasi. Tree of\nattacks: Jailbreaking black-box llms automatically, 2024. URL https://arxiv.org/abs/2312\n.02119.\nI.Molybog,P.Albert,M.Chen,Z.DeVito,D.Esiobu,N.Goyal,P.Koura,S.Narang,A.Poulton,R.Silva,\netal. Atheoryonadaminstabilityinlarge-scalemachinelearning. arXivpreprintarXiv:2304.09871,\n2023. URL https://arxiv.org/abs/2304.09871.\nA.Nagrani,S.Menon,A.Iscen,S.Buch,R.Mehran,N.Jha,A.Hauth,Y.Zhu,C.Vondrick,M.Sirotenko,\nC. Schmid, and T. Weyand. Minerva: Evaluating complex video reasoning, 2025a. URL https:\n//arxiv.org/abs/2505.00681.\n43"
    },
    {
      "page": 44,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nA.Nagrani,M.Zhang,R.Mehran,R.Hornung,N.B.Gundavarapu,N.Jha,A.Myers,X.Zhou,B.Gong,\nC. Schmid, M. Sirotenko, Y. Zhu, and T. Weyand. Neptune: The long orbit to benchmarking long\nvideo understanding, 2025b. URL https://arxiv.org/abs/2412.09582.\nM.Nasr,N.Carlini,J.Hayase,M.Jagielski,A.F.Cooper,D.Ippolito,C.A.Choquette-Choo,E.Wallace,\nF. Tramèr, and K. Lee. Scalable extraction of training data from (production) language models,\n2023. URL https://arxiv.org/abs/2311.17035.\nP. Padlewski, M. Bain, M. Henderson, Z. Zhu, N. Relan, H. Pham, D. Ong, K. Aleksiev, A. Ormazabal,\nS.Phua,E.Yeo,E.Lamprecht,Q.Liu,Y.Wang,E.Chen,D.Fu,L.Li,C.Zheng,C.deMassond’Autume,\nD. Yogatama, M. Artetxe, and Y. Tay. Vibe-eval: A hard evaluation suite for measuring progress of\nmultimodal language models, 2024. URL https://arxiv.org/abs/2405.02287.\nA.Pappu,B.Porter,I.Shumailov,andJ.Hayes. MeasuringmemorizationinRLHFforcodecompletion.\narXiv preprint arXiv:2406.11715, 2024. URL https://arxiv.org/abs/2406.11715.\nV.Patraucean,L.Smaira,A.Gupta,A.Recasens,L.Markeeva,D.Banarse,S.Koppula,M.Malinowski,\nY. Yang, C. Doersch, et al. Perception test: A diagnostic benchmark for multimodal video models.\nAdvances in Neural Information Processing Systems, 36:42748–42761, 2023.\nE. Perez, S. Huang, F. Song, T. Cai, R. Ring, J. Aslanides, A. Glaese, N. McAleese, and G. Irving. Red\nteaminglanguagemodelswithlanguagemodels,2022. URLhttps://arxiv.org/abs/2202.0\n3286.\nL. Phan et al. Humanity’s last exam, 2025. URL https://arxiv.org/abs/2501.14249.\nM.Phuong,M.Aitchison,E.Catt,S.Cogan,A.Kaskasoli,V.Krakovna,D.Lindner,M.Rahtz,Y.Assael,\nS. Hodkinson, et al. Evaluating frontier models for dangerous capabilities, 2024. URL https:\n//arxiv.org/abs/2403.13793.\nM. Phuong, R. S. Zimmermann, Z. Wang, D. Lindner, V. Krakovna, S. Cogan, A. Dafoe, L. Ho, and\nR. Shah. Evaluating frontier models for stealth and situational awareness, 2025. URL https:\n//arxiv.org/abs/2505.01420.\nS. Pichai. Google I/O 2025: From research to reality, 2025. URL https://blog.google/techno\nlogy/ai/io-2025-keynote/.\nC. Plizzari, A. Tonioni, Y. Xian, A. Kulshrestha, and F. Tombari. Omnia de egotempo: Benchmarking\ntemporal understanding of multi-modal llms in egocentric videos. In Proceedings of the Computer\nVision and Pattern Recognition Conference, pages 24129–24138, 2025.\nD.Rein,B.L.Hou,A.C.Stickland,J.Petty,R.Y.Pang,J.Dirani,J.Michael,andS.R.Bowman. Gqqa:\nA graduate-level google-proof q&a benchmark. In First Conference on Language Modeling, 2024.\nC. Riquelme, J. Puigcerver, B. Mustafa, M. Neumann, R. Jenatton, A. S. Pinto, D. Keysers, and\nN.Houlsby. Scalingvisionwithsparsemixtureofexperts,2021. URLhttps://arxiv.org/abs/\n2106.05974.\nJ.Roberts, M.R. Taesiri, A.Sharma, A.Gupta, S.Roberts, I. Croitoru, S.-V.Bogolin, J. Tang, F.Langer,\nV. Raina, et al. ZeroBench: An impossible visual benchmark for contemporary large multimodal\nmodels. arXiv preprint arXiv:2502.09696, 2025.\nM. Rodriguez, R. A. Popa, L. Liang, A. Wang, M. Rahtz, A. Kaskasoli, A. Dafoe, and F. Flynn. A\nframework for evaluating emerging cyberattack capabilities of AI, 2025. URL https://arxiv.\norg/abs/2503.11917.\n44"
    },
    {
      "page": 45,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nS. Roller, S. Sukhbaatar, J. Weston, et al. Hash layers for large sparse models. Advances in Neural\nInformation Processing Systems, 34:17555–17566, 2021. URL https://proceedings.neurips.\ncc/paper/2021/file/883e881bc596359e0c5112411858a74b-Paper.pdf.\nM. Samvelyan, S. C. Raparthy, A. Lupu, E. Hambro, A. H. Markosyan, M. Bhatt, Y. Mao, M. Jiang,\nJ. Parker-Holder, J. Foerster, T. Rocktäschel, and R. Raileanu. Rainbow teaming: Open-ended\ngeneration of diverse adversarial prompts, 2024. URL https://arxiv.org/abs/2402.16822.\nR. Shah, A. Irpan, A. M. Turner, A. Wang, A. Conmy, D. Lindner, J. Brown-Cohen, L. Ho, N. Nanda,\nR. A. Popa, R. Jain, R. Greig, S. Albanie, S. Emmons, S. Farquhar, S. Krier, S. Rajamanoharan,\nS. Bridgers, T. Ijitoye, T. Everitt, V. Krakovna, V. Varma, V. Mikulik, Z. Kenton, D. Orr, S. Legg,\nN. Goodman, A. Dafoe, F. Flynn, and A. Dragan. An approach to technical agi safety and security,\n2025. URL https://arxiv.org/abs/2504.01849.\nD.Sharon. UploadandedityourimagesdirectlyintheGeminiapp,2025. URLhttps://blog.goo\ngle/products/gemini/image-editing/.\nN. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, and J. Dean. Outrageously large\nneural networks: The sparsely-gated mixture-of-experts layer. In ICLR (Poster). OpenReview.net,\n2017. URL https://arxiv.org/abs/1701.06538.\nC. Shi, S. Lin, S. Song, J. Hayes, I. Shumailov, I. Yona, J. Pluto, A. Pappu, C. A. Choquette-Choo,\nM. Nasr, C. Sitawarin, G. Gibson, A. Terzis, and J. F. Flynn. Lessons from defending gemini against\nindirect prompt injections, 2025. URL https://arxiv.org/abs/2505.14534.\nS. Singh, A. Romanou, C. Fourrier, D. I. Adelani, J. G. Ngui, D. Vila-Suero, P. Limkonchotiwat,\nK. Marchisio, W. Q. Leong, Y. Susanto, R. Ng, S. Longpre, W.-Y. Ko, M. Smith, A. Bosselut, A. Oh,\nA. F. T. Martins, L. Choshen, D. Ippolito, E. Ferrante, M. Fadaee, B. Ermis, and S. Hooker. Global\nmmlu: Understanding and addressing cultural and linguistic biases in multilingual evaluation,\n2024. URL https://arxiv.org/abs/2412.03304.\nR. Stein. Expanding AI Overviews and introducing AI Mode, 2025. URL https://blog.google/\nproducts/search/ai-mode-search.\nI.Tolstikhin,N.Houlsby,A.Kolesnikov,L.Beyer,X.Zhai,T.Unterthiner,J.Yung,A.Steiner,D.Keysers,\nJ. Uszkoreit, M. Lucic, and A. Dosovitskiy. Mlp-mixer: An all-mlp architecture for vision, 2021.\nA. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and I. Polosukhin.\nAttention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vish-\nwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30.\nCurran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper_files/pap\ner/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.\nK. Vodrahalli, S. Ontanon, N. Tripuraneni, K. Xu, S. Jain, R. Shivanna, J. Hui, N. Dikkala, M. Kazemi,\nB. Fatemi, et al. Michelangelo: Long context evaluations beyond haystacks via latent structure\nqueries. arXiv preprint arXiv:2409.12640, 2024. URL https://arxiv.org/abs/2409.12640.\nB. Wang. NotebookLM now lets you listen to a conversation about your sources , 2024. URL\nhttps://blog.google/technology/ai/notebooklm-audio-overviews.\nC. Wang, A. Wu, and J. Pino. Covost 2: A massively multilingual speech-to-text translation corpus,\n2020.\n45"
    },
    {
      "page": 46,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nW. Wang, Z. He, W. Hong, Y. Cheng, X. Zhang, J. Qi, X. Gu, S. Huang, B. Xu, Y. Dong, M. Ding,\nand J. Tang. Lvbench: An extreme long video understanding benchmark, 2024. URL https:\n//arxiv.org/abs/2406.08035.\nX. Wang, J. Wu, J. Chen, L. Li, Y.-F. Wang, and W. Y. Wang. Vatex: A large-scale, high-quality\nmultilingual dataset for video-and-language research. In Proceedings of the IEEE/CVF international\nconference on computer vision, pages 4581–4591, 2019.\nJ.Wei,K.Nguyen,H.W.Chung,Y.J.Jiao,S.Papay,A.Glaese,J.Schulman,andW.Fedus. Measuring\nshort-form factuality in large language models. arXiv preprint arXiv:2411.04368, 2024. URL\nhttps://arxiv.org/abs/2411.04368.\nL. Weidinger, J. Barnhart, J. Brennan, C. Butterfield, S. Young, W. Hawkins, et al. Holistic safety and\nresponsibilityevaluationsofadvancedaimodels,2024. URLhttps://arxiv.org/abs/2404.1\n4068.\nH. Wijk, T. Lin, J. Becker, S. Jawhar, N. Parikh, T. Broadley, L. Chan, M. Chen, J. Clymer, J. Dhyani,\net al. RE-Bench: Evaluating frontier ai r&d capabilities of language model agents against human\nexperts, 2025. URL https://arxiv.org/abs/2411.15114.\nM. Wortsman, P. J. Liu, L. Xiao, K. Everett, A. Alemi, B. Adlam, J. D. Co-Reyes, I. Gur, A. Kumar,\nR. Novak, et al. Small-scale proxies for large-scale transformer training instabilities. arXiv preprint\narXiv:2309.14322, 2023. URL https://arxiv.org/abs/2309.14322.\nJ. Yang, A. Prabhakar, K. Narasimhan, and S. Yao. Intercode: Standardizing and benchmarking\ninteractivecodingwithexecutionfeedback,2023. URLhttps://arxiv.org/abs/2306.14898.\nZ.Yu,D.Xu,J.Yu,T.Yu,Z.Zhao,Y.Zhuang,andD.Tao. ActivityNet-QA:Adatasetforunderstanding\ncomplex web videos via question answering. In AAAI, 2019.\nX. Yue, Y. Ni, K. Zhang, T. Zheng, R. Liu, G. Zhang, S. Stevens, D. Jiang, W. Ren, Y. Sun, et al.\nMmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert\nagi. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages\n9556–9567, 2024.\nZerokid. Pokemon Red Version - Guide and Walkthrough (GB), 2024. URL https://gamefaqs.g\namespot.com/gameboy/367023-Pokémon-red-version/faqs/64175.\nS.Zhai,T.Likhomanenko,E.Littwin,D.Busbridge,J.Ramapuram,Y.Zhang,J.Gu,andJ.M.Susskind.\nStabilizingtransformertrainingbypreventingattentionentropycollapse.InInternationalConference\non Machine Learning, pages 40770–40803. PMLR, 2023. URL https://proceedings.mlr.pr\ness/v202/zhai23a/zhai23a.pdf.\nJ. Zhang. Gemini Plays Pokemon Twitch Stream, 2025. URL https://www.twitch.tv/gemini\n_plays_pokemon/about.\nS. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin, et al.\nOpt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068, 2022. URL\nhttps://arxiv.org/abs/2205.01068.\nL. Zhou, C. Xu, and J. J. Corso. Towards automatic learning of procedures from web instructional\nvideos. In AAAI Conference on Artificial Intelligence, pages 7590–7598, 2018. URL https://www.\naaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17344.\n46"
    },
    {
      "page": 47,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n7. Contributors and Acknowledgments\nContributors KristenChiafullo KashyapKolipaka DavidParkinson\nGheorgheComanici AndreElisseeff JasonChang SwaroopRamaswamy\nEricBieber NilpaJha EugenVušak JeromeConnor\nMikeSchaekermann PrateekKolhar SrinivasanVenkatachary SoheilHassasYeganeh\nIcePasupat LeonardBerrada ShadiNoghabi SnchitGrover\nNoveenSachdeva FrankDing TarunBharti GeorgeKenwright\nInderjitDhillon XianceSi YounghoonJun LuboLitchev\nMarcelBlistein ShresthaBasuMallick AleksandrZaks ChrisApps\nOriRam FranzOch SimonGreen AlexTomala\nDanZhang SofiaErell JeshwanthChallagundla FelixHalim\nEvanRosen EricNi WilliamWong AlexCastro-Ros\nLukeMarris TejasiLatkar MuqtharMohammad ZefeiLi\nSamPetulla SherryYang DeanHirsch AnudhyanBoral\nColinGaffney PetarSirkovic YongCheng PaulineSho\nAsafAharoni ZiqiangFeng IftekharNaim MichalYarom\nNathanLintz RobertLeland LevProleev EricMalmi\nTiagoCardalPais RachelHornung DamienVincent DavidKlinghoffer\nHenrikJacobsson GangWu AayushSingh RebeccaLin\nIdanSzpektor CharlesBlundell MaximKrikun AlanAnsell\nNan-JiangJiang HamidrezaAlvari DilipKrishnan PradeepKumarS\nKrishnaHaridasan Po-SenHuang ZoubinGhahramani ShubinZhao\nAhmedOmran CathyYip AvielAtias SiqiZuo\nNikunjSaunshi SanjaDeur RajeevAggarwal AdamSantoro\nDaraBahri LiLiu ChristoKirov Heng-TzeCheng\nGauravMishra GabrielaSurita DimitriosVytiniotis SolomonDemmessie\nEricChu PabloDuque ChristyKoh YuchiLiu\nTobyBoyd DimaDamen AlexandraChronopoulou NicoleBrichtova\nBradHekman JohnsonJia PawanDogra AllieCulp\nAaronParisi ArthurGuez Vlad-DoruIon NathanielBraun\nChaoyiZhang MarkusMircea GladysTyen DanGraur\nKornraphopKawintiranon AnimeshSinha JasonLee WillNg\nTaniaBedrax-Weiss AlbertoMagni FelixWeissenberger NikhilMehta\nOliverWang PawełStradomski TrevorStrohman AaronPhillips\nYaXu TalMarian AshwinBalakrishna PatrikSundberg\nOlliePurkiss VladoGalić JackRae VarunGodbole\nUriMendlovic WenhuChen MarkoVelic FangyuLiu\nIlaïDeutel HishamHusain RaouldeLiedekerke YashKatariya\nNamNguyen AchintyaSinghal OdedElyada DavidRim\nAdamLangley DominikGrewe WentaoYuan MojtabaSeyedhosseini\nFlipKorn François-XavierAubet CanoeeLiu SeanAmmirati\nLuciaRossazza ShuangSong LiorShani JonasValfridsson\nAlexandreRamé LorenzoBlanco SergeyKishchenko MahanMalihi\nSagarWaghmare LelandRechis BeaAlessio TimothyKnight\nHelenMiller LewisHo YandongLi AndeepToor\nNathanByrd RichMunoz RichardSong ThomasLampe\nAshrithSheshan KelvinZheng SamKwei AbeIttycheriah\nRaiaHadsell JessicaHamrick OrionJankowski LewisChiang\nSangnieBhardwaj KevinMather AneeshPappu ChakYeung\nPawelJanus HagaiTaitelbaum YouheiNamiki AlexandreFréchette\nTeroRissa ElizaRutherford YenaiMa JinmengRao\nDanHorgan YunLei NileshTripuraneni HuishengWang\nAlvinAbdagic KuangyuanChen ColinCherry HimanshuSrivastava\nLiorBelenki AnandShukla MarissaIkonomidis RichardZhang\nJamesAllingham EricaMoreira Yu-ChengLing RockyRhodes\nAnimaSingh EricDoi ColinJi ArielBrand\nTheoGuidroz BerivanIsik BekaWestberg DeanWeesner\nSrivatsanSrinivasan NirShabat AurielWright IlyaFigotin\nHermanSchmit DominikaRogozińska DaYu FelixGimeno\n47"
    },
    {
      "page": 48,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nRachanaFellinger ArunNair JaumeSanchezElias XinyangGeng\nPierreMarcenac ArtemShtefan AbhirutGupta YeqingLi\nJoséLeal MauraO’Brien ManishReddyVuyyuru RolfJagerman\nEyalMarcus ManuAgarwal FredAlcober ChaoJia\nVictorCotruta SahityaPotluri TongZhou NadavOlmert\nRodrigoCabrera SiddharthGoyal KaiyangJi DavidSharon\nSherylLuo AmitJhindal FlorianHartmann MatthewMauger\nDanGarrette SakshamThakur SubhaPuttagunta SandeepMariserla\nVeraAxelrod YuryStuken HugoSong HongxuMa\nSorinBaltateanu JamesLyon EhsanAmid MeghaMohabey\nDavidBarker KristinaToutanova AncaStefanoiu KyuyeunKim\nDongkaiChen FangxiaoyuFeng AndrewLee AlekAndreev\nHoriaToma AustinWu PaulPucciarelli ScottPollom\nBenIngram BenHorn EmmaWang JulietteLove\nJasonRiesa AlekWang AmitRaul VihanJain\nChinmayKulkarni AlexCullum SlavPetrov PriyankaAgrawal\nYujingZhang GabeTaubman IsaacTian YannickSchroecker\nHongbinLiu DishaShrivastava ValentinAnklin AlisaFortin\nChaoWang ChongyangShi NanaNti ManfredWarmuth\nMartinPolacek HamishTomlinson VictorGomes JiLiu\nWillWu RomaPatel MaxSchumacher AndrewLeach\nKaiHui TaoTu GraceVesom IrinaBlok\nAdrianNReyes AdaMaksutajOflazer AlexPanagopoulos GaneshPoomalGirirajan\nYiSu FrancescoPongetti KonstantinosBousmalis RoeeAharoni\nMeganBarnes MingyaoYang DanielAndor BenignoUria\nIshaanMalhi AdrienAliTaïga JoshJacob AndreiSozanschi\nAnfalSiddiqui VincentPerot YuanZhang DanGoldberg\nQixuanFeng NuoWangPierse BillRosgen LucianIonita\nMihaiDamaschin FengHan MatijaKecman MarcoTulioRibeiro\nDanielePighin YoelDrori MatthewTung MartinZlocha\nAndreasSteiner IñakiIturrate AlexandraBelias VighneshBirodkar\nSamuelYang AyanChakrabarti NoahGoodman SamiLachgar\nRamyaSreeBoppana LeggYeung PaulCovington LiangzheYuan\nSimeonIvanov DaveDopson BrianWieder HimadriChoudhury\nArunKandoor Yi-tingChen NikitaSaxena MattGinsberg\nAdityaShah ApoorvKulshreshtha ElnazDavoodi FeiZheng\nAsierMujika TongfeiGuo MuhuanHuang GregoryDibb\nDaHuang PhilipPham SharathMaddineni EmilyGraves\nChristopherA. TalSchuster VincentRoulet SwachhandLokhande\nChoquette-Choo JunquanChen FolawiyoCampbell-Ajala GabrielRasskin\nMohakPatel AlexPolozov PierGiuseppeSessa George-CristianMuraru\nTianheYu JinweiXing Xintian(Cindy)Wu CorbinQuick\nToniCreswell HuanjieZhou GuangdaLai SandeepTata\nJerry(Chun-Ting)Liu PraneethKacham PaulCollins PierreSermanet\nCatarinaBarros DoronKukliansky AlexHaig AdityaChawla\nYasamanRazeghi AntoineMiech VytenisSakenas ItayKaro\nAurkoRoy SergeyYaroshenko XiaoweiXu YanWang\nPhilCulliton EdChi MarissaGiustina SusanZhang\nBinbinXiong SholtoDouglas LaurentElShafey OrgadKeller\nJiaqiPan HongliangFei PichiCharoenpanit AncaDragan\nThomasStrohmann MathieuBlondel ShefaliGarg GuolongSu\nTollyPowell PreethiMyla JoshuaAinslie IanChou\nBabiSeal LiorMadmoni BooneSeverson XiLiu\nDougDeCarlo XingWu MontseGonzalezArenas YiqingTao\nPranavShyam DanielKeysers ShreyaPathak ShruthiPrabhakara\nKaanKatircioglu KristianKjems SujeeRajayogam MarcWilson\nXuezhiWang IsabelaAlbuquerque JieFeng RuiboLiu\nCassidyHardin LijunYu MichielBakker ShiboWang\nImmanuelOdisho JoelD’sa ShengLi GeorgieEvans\nJosefBroder MichellePlantan NevanWichers DavidDu\nOscarChang VladIonescu JamieRogers AlfonsoCastaño\n48"
    },
    {
      "page": 49,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGautamPrasad XuanYang ChiyuanZhang ShuangLiu\nMonaElMahdy DaleWebster SanderDieleman SaarthakKhanna\nSebastianGerlach AliElqursh ThomasJimma AdityaPandey\nMachelReid AedanPope AndreyRyabtsev SiobhanMcloughlin\nJarrodKahn GeorgesRotival SiddharthaBrahma QiujiaLi\nAmirZait DavidRaposo DavidSteiner SamHaves\nThanumalayan WanzhengZhu DayouDu AllanZhou\nSankaranarayanaPillai JeffDean AnteŽužul ElenaBuchatskaya\nThatcherUlrich SamiAlabed MislavŽanić IsabelLeal\nGuanyuWang DustinTran MukundRaghavachari PeterdeBoursac\nJanWassenberg ArushiGupta WilliGierke NamiAkazawa\nEfratFarkash ZachGleicher ZeyuZheng NinaAnderson\nKiranYalasangi JessicaAustin DessiePetrova TerryChen\nCongchaoWang EdouardRosseel YannDauphin KrishnaSomandepalli\nMariaBauza MeghUmekar YuchuanLiu ChenLiang\nSimonBucher DipanjanDas IdoKessler SheelaGoenka\nTingLiu YinghaoSun StevenHand StephanieWinkler\nJunYan KaiChen ChrisDuvarney AlexanderGrushetsky\nGaryLeung KarolisMisiunas SeokhwanKim YifanDing\nVikasSindhwani XiangZhou HyoLee JamieSmith\nParkerBarnes YixianDi LéonardHussenot FanYe\nAviSingh AlyssaLoo JeffreyHui JordiPont-Tuset\nIvanJurin JoshNewlan JoshSmith EricLi\nJichuanChang BoLi DeepaliJain RuichaoLi\nNiketKumarBhumihar VinayRamasesh JiaweiXia TomerGolany\nSivanEiger YingXu GauravSinghTomar DawidWegner\nGuiCitovsky AlexChen KeyvanAmiri TaoJiang\nBenWithbroe SudeepGandhe DuPhan OmerBarak\nZhangLi RaduSoricut FabianFuchs YuanShangguan\nSiyangXue NikitaGupta TobiasWeyand EszterVértes\nNiccolòDalSanto ShuguangHu NenadTomasev ReneeWong\nGeorgiStoyanov SeliemEl-Sayed AlexandraCordell JörgBornschein\nYvesRaimond XavierGarcia XinLiu AlexTudor\nStevenZheng IdanBrusilovsky JonathanMallinson MicheleBevilacqua\nYilinGao Pu-ChinChen PankajJoshi TomSchaul\nVítListík AndrewBolt AndyCrawford AnkitSinghRawat\nSławekKwasiborski LuHuang ArunSuggala YangZhao\nRachelSaputro AlexGurney SteveChien KyriakosAxiotis\nAdnanOzturel ZhiyingZhang NickFernando LeiMeng\nGaneshMallya AlexanderPritzel MariellaSanchez-Vargas CoryMcLean\nKushalMajmundar JarekWilkiewicz DuncanWilliams JonathanLai\nRossWest BryanSeybold PhilCrone JenniferBeattie\nPaulCaron BhargavKanagal XiyangLuo NateKushman\nJinliangWei Shamanna IgorKarpov YaxinLiu\nLluisCastrejon FelixFischer JynShan BlairKutzman\nSharadVikram JosefDean TerryThurk FionaLang\nDeepakRamachandran KaranGill RobinStrudel JingchenYe\nNikhilDhawan RossMcilroy PaulVoigtlaender PraneethNetrapalli\nJihoPark AbhishekBhowmick PiyushPatil PushkarMishra\nSaraSmoot JeremySelier TimDozat MyriamKhan\nGeorgevandenDriessche AntoineYang AliKhodaei MeghaGoel\nYochaiBlau DerekCheng SahilSingla RobWilloughby\nChaseMalik VladimirMagay PiotrAmbroszczyk DavidTian\nWeiLiang JieTan QiyinWu HongleiZhuang\nRoyHirsch DhritiVarma YifanChang JDChen\nCiceroNogueiradosSantos ChristianWalder BrianRoark ZakTsai\nEugeneWeinstein TomasKocisky ChaitraHegde TasosKementsietsidis\nAäronvandenOord RyoNakashima TianliDing ArjunKhare\nSidLall PaulNatsev AngelosFilos JamesKeeling\nNicholasFitzGerald MikeKwong ZhongruWu KeyangXu\nZixuanJiang IonelGog AndréSusanoPinto NathanWaters\n49"
    },
    {
      "page": 50,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFlorentAltché YuxiangZhou JamesMartens LuLiu\nAshokPopat XinyiBai TaoChen YaoSu\nBhavishyaMittal Wei-ChihHung AvielBoag AnastasiaPetrushkina\nDavidSaxton StevenPecht DaiyiPeng JiajunShen\nDaliaElBadawy GeorgiTodorov ColineDevin ArmandJoulin\nMichaelMathieu NikhilKhadke ArseniyKlimovskiy YuanzhongXu\nZhengZheng PramodGupta MaryPhuong SteinXudongLin\nHaoZhou PreethiLahoti DannyVainstein YanaKulizhskaya\nNishantRanka ArnaudAutef JinXie CiprianChelba\nRichardShin KarthikDuddu BhuvanaRamabhadran ShobhaVasudevan\nQingnanDuan JamesLee-Thorp NathanHoward EliCollins\nTimSalimans AlexanderBykovsky XinxinYu VasilisaBashlovkina\nIoanaMihailescu TautvydasMisiunas GitarthaGoswami TonyLu\nUriShaham SebastianFlennerhag JingyuCui DougFritz\nMing-WeiChang SanthoshThangaraj SamShleifer JongbinPark\nYannisAssael JedMcGiffin MarioPinto YanqiZhou\nNishanthDikkala ZackNado Chih-KuanYeh ChenSu\nMartinIzzard MarkusKunesch Ming-HsuanYang RichardTanburn\nVincentCohen-Addad AndreasNoever SaraJavanmardi MikhailSushkov\nCatGraves AmirHertz DanEthier MitchelleRasquinha\nVladFeinberg MarcoLiang ChaceLee JinningLi\nGraceChung VictorStone JordiOrbay JenniferPrendki\nDJStrouse EvanPalmer SuyogKotecha YimingLi\nDannyKarmon SamiraDaruki CarlaBromberg PallaviLV\nSahandSharifzadeh ArijitPramanik PeteShaw ShriyaSharma\nZoeAshwood SiimPõder JamesThornton HenFitoussi\nKhiemPham AustinKyker AdiGerziRosenthal HuiHuang\nJonBlanton MinaKhan ShaneGu AndrewDai\nAlexVasiloff EvgenySluzhaev MattThomas PhuongDao\nJarredBarber MarvinRitter IanGemp MikeBurrows\nMarkGeller AvrahamRuderman AdityaAyyar HenryPrior\nAurickZhou WenleiZhou AsahiUshio DanfengQin\nFedirZubach ChiragNagpal AarushSelvan GolanPundak\nTzu-KuoHuang KiranVodrahalli JoelWee LarsLoweSjoesund\nLeiZhang GeorgeNecula ChenxiLiu ArtKhurshudov\nHimanshuGupta PaulBarham MaryamMajzoubi ZhenkaiZhu\nMattYoung ElliePavlick WeirenYu AlbertWebson\nJuliaProskurnia JayHartford JakeAbernethy ElizabethKemp\nRonnyVotel IzhakShafran TylerLiechty TatTan\nValentinGabeur LongZhao RenkePan SaurabhAgrawal\nGabrielBarcik MaciejMikuła HoangNguyen SusieSargsyan\nAdityaTripathi TomEccles Qiong(Q)Hu LiqunCheng\nHongkunYu HidetoshiShimokawa SarahPerrin JimStephan\nGengYan KanavGarg AbhinavArora TomKwiatkowski\nBeerChangpinyo LukeVilnis EmilyPitler DavidReid\nFilipPavetić HanwenChen WeiyiWang ArunkumarByravan\nAmyCoyle IliaShumailov KaushikShivakumar AssafHurwitzMichaely\nYasuhisaFujii Kuang-HueiLee FlavienProst NicolasHeess\nJorgeGonzalezMendez AbdelrahmanAbdelhamed BenLimonchik LuoweiZhou\nTianhaoZhou MeiyanXie JingWang SonamGoenka\nHarishRajamani VeredCohen YiGao ViralCarpenter\nBlakeHechtman EsterHlavnova TimotheeCour AnselmLevskaya\nEddieCao DanMalkin ShyamalBuch BoWang\nDa-ChengJuan ChawinSitawarin HuanGui ReedRoberts\nYi-XuanTan JamesLottes MariaIvanova RémiLeblond\nValentinDalibard PaulineCoquinot PhilippNeubeck SharatChikkerur\nYilunDu TianliYu KelvinChan StavGinzburg\nNatalieClay SandeepKumar LucyKim MaxChang\nKaishengYao JingweiZhang HuizhongChen RobertRiachi\nWenhaoJia AromaMahendru NamanGoyal Chuqiao(Joyce)Xu\nDimpleVijaykumar ZafaraliAhmed Da-WoonChung ZalánBorsos\n50"
    },
    {
      "page": 51,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nMichaelPliskin SenakaButhpitiya VincentTsang XingyuCai\nJuliaPawar OlafRonneberger BowenLiang PaulMichel\nMorganeLustman CalebHabtegebriel FernandoPereira SanjayGanapathy\nHannahKirkwood WeiLi SuhasGanesh JaneLabanowski\nAnkitAnand PaulCavallaro IvanKorotkov ZacharyGarrett\nAditiChaudhary AuroraWei JakubAdamek BenVargas\nNorbertKalb GuyBensky SridharThiagarajan SeanSun\nKieranMilan TimoDenk VinhTran BryanGale\nSeanAugenstein HarishGanapathy CharlesChen ThomasBuschmann\nAnnaGoldie JeffStanway ChrisTar GuillaumeDesjardins\nLaurelPrince PratikJoshi SanilJain NimeshGhelani\nKarthikRaman FrancescoBertolini IshitaDasgupta PalakJain\nYanhuaSun JessicaLo TaylanBilal MuditVerma\nVivianXia OliviaMa DavidReitter ChulayuthAsawaroengchai\nAaronCohen ZacharyCharles KaiZhao JulianEisenschlos\nZhouyuanHuo GetaSampemane GiuliaVezzani JitendraHarlalka\nJoshCamp HimanshuSahni YasminGehman HidetoKazawa\nSeherEllis XuChen PulkitMehta DonMetzler\nLukasZilka HarryAskham LaurenBeltrone JoshuaHowland\nDavidVilarTorres DavidGaddy XerxesDotiwalla YingJian\nLisaPatel PeterYoung SergioGuadarrama JakeAdes\nShoArora JiewenTan ZaheerAbbas ViralShah\nBettyChan MatanEyal StefaniKarp TynanGangwani\nJonasAdler ArthurBražinskas PetkoGeorgiev SeungjiLee\nKareemAyoub LiZhong Chun-SungFerng RomanRing\nJackyLiang ZhichunWu MarcBrockschmidt StevenM.Hernandez\nFayazJamil MarkEpstein LiqianPeng DeanReich\nJiepuJiang KaiBailey ChristophHirnschall AmerSinha\nSimonBaumgartner AndrewHard VikasVerma AshutoshSathe\nHaitianSun KamyuLee YingyingBi JoeKovac\nYaelKarov SashaGoldshtein YingXiao AshleahGill\nYaroslavAkulov AlexRuiz AvigailDabush AjayKannan\nHuiZheng MohammedBadawi KelvinXu AndreaD’olimpio\nIreneCai MatthiasLochbrunner PhilWallis MartinSevenich\nClaudioFantacci JKKearns RandallParker JayWhang\nJamesRubin AshleyBrown QifeiWang BeenKim\nAlexRavAcha FabioPardo YangXu KheChaiSim\nMengchaoWang TheophaneWeber IlkinSafarli JilinChen\nNinaD’Souza HaichuanYang DineshTewari JiagengZhang\nRohitSathyanarayana Pan-PanJiang YinZhang ShubaLall\nShengyangDai BerkinAkin SeungyeonKim YossiMatias\nSimonRowe ZhaoFu AndreaGesmundo BillJia\nAndreySimanovsky MarcusWainwright MackenzieThomas AbeFriesen\nOmerGoldman ChiZou SergeyLevi SaraNasso\nYuhengKuang MeenuGaba AhmedChowdhury AshishThapliyal\nXiaoyuePan Pierre-AntoineManzagol KanishkaRao BryanPerozzi\nAndrewRosenberg WendyKan PeterGarst TingYu\nTaniaRojas-Esponda YangSong SamConway-Rahman AnnaShekhawat\nPraneetDutta KarinaZainullina HelenRan SafeenHuda\nAmyZeng RuiLin KayMcKinney PeterGrabowski\nIrinaJurenka JeongwooKo ZhishengXiao EricWang\nGregFarquhar SalilDeshmukh WenhaoYu AshwinSreevatsa\nYaminiBansal ApoorvJindal RohanAgrawal HilalDib\nShariqIqbal JamesSvensson AxelStjerngren MehadiHassen\nBeccaRoelofs DivyaTyam CatalinIonescu ParkerSchuh\nGa-YoungJoung HeriZhao JingjingChen VedranaMilutinovic\nParkerBeak ChristineKaeser-Chen VivekSharma ChrisWelty\nChangwanRyu ScottBaird JustinChiu MichaelQuinn\nRyanPoplin PooyaMoradi FeiLiu AliShah\nYanWu JamieHall KenFranko BangjuWang\nJean-BaptisteAlayrac QiuchenGuo ClaytonSanford GabeBarth-Maron\n51"
    },
    {
      "page": 52,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nJustinFrye PatrickKane Andr’asGy\"orgy ArjunAkula\nNatalieAxelsson CeZheng ArunAhuja MaxDylla\nTaoZhu NicoDuduta DanielHernandezDiaz AshyanaKachra\nYukunMa JoshuaKessinger Chen-YuLee WeichengKuo\nIreneGiannoumis JamesNoraky NathanClement TingtingZou\nHanieSedghi SiqiLiu WeizeKong LilyWang\nChangYe KeranRong DrewGarmon LuyaoXu\nYiLuan PetarVeličković IshaanWatts JifanZhu\nKevinAydin KeithRush KushBhatia JustinSnyder\nBilvaChandra AlexGoldin KhyattiGupta SachitMenon\nVivekSampathkumar FannyWei MattMiecnikowski OrhanFirat\nRonnyHuang ShivaMohanReddy HugoVallet IgorMordatch\nVictorLavrenko Garlapati AnkurTaly YuanYuan\nAhmedEleryan CarolinePantofaru EdwardLoper NataliaPonomareva\nZhiHong OkwanKwon SaketJoshi RoryBlevins\nStevenHansen JianmoNi JamesAtwood LawrenceMoore\nSaraMcCarthy EricNoland JoChick WeijunWang\nBidishaSamanta JuliaDiTrapani MarkCollier PhilChen\nDomagojĆevid FrançoiseBeaufays FotisIliopoulos MartinScholz\nXinWang AbhijitGuhaRoy RyanTrostle ArturDwornik\nFangtaoLi YinlamChow BelizGunel JasonLin\nMichaelVoznesensky AybukeTurker RamiroLeal-Cavazos SichengLi\nMattHoffman GeoffreyCideron ArnarMarHrafnkelsson DiegoAntognini\nAndreasTerzis LantaoMei MichaelGuzman TeI\nVikashSehwag JonClark XiaoenJu XiaodanSong\nGilFidel QingyunDou AndyForbes MattMiller\nLuhengHe MatkoBošnjak JesseEmond UdayKalra\nMuCai RalphLeith KushalChauhan AdamRaveret\nYanzhangHe YuqingDu BenCaine OscarAkerlund\nAlexFeng AmirYazdanbakhsh LiXiao FelixWu\nMartinNikoltchev MiladNasr WenjunZeng AndrewNystrom\nSamratPhatale ChesterKwak AlexandreMoufarek NamrataGodbole\nJasonChase SurajSatishkumarSheth DanielMurphy TianqiLiu\nRoryLawton AlexKaskasoli MayaMeng HannahDeBalsi\nMingZhang AnkeshAnand NitishGupta JewelZhao\nTomOuyang BalajiLakshminarayanan FelixRiedel BuhuangLiu\nManuelTragut SammyJerome AnilDas AviCaciularu\nMehdiHafeziManshadi DavidBieber ElijahLawal LaurenLax\nArjunNarayanan Chun-TeChu ShashiNarayan UrvashiKhandelwal\nJiamingShen AlexandreSenges TiberiuSosea VictoriaLangston\nXuGao TianxiaoShen JamesSwirhun EricBailey\nTolgaBolukbasi MukundSridhar LindaFriso SilvioLattanzi\nNickRoy NdabaNdebele BehnamNeyshabur YufeiWang\nXinLi BenjaminBeyret JingLu NeelKovelamudi\nDanielGolovin ShakirMohamed SertanGirgin SnehaMondal\nLiviuPanait MiaChen MichaelWunder GuruGuruganesh\nZhenQin MarkusFreitag EdouardYvinec NanHua\nGuangxingHan JiaxianGuo AroonalokPyne OfirRoval\nThomasAnthony LuyangLiu VictorCarbune PawełWesołowski\nSnehaKudugunta PaulRoit ShrutiRijhwani RishikeshIngale\nVioricaPatraucean HengChen YangGuo JonathanHalcrow\nAniketRay ShenYan TulseeDoshi TimSohn\nXinyunChen TomStone AntonBriukhov ChristofAngermueller\nXiaochenYang JDCo-Reyes MaxBain BahramRaad\nTanujBhatia JeremyCole AyalHitron EliStickgold\nPranavTalluri SalvatoreScellato XuanhuiWang EvaLu\nAlexMorris ShekoofehAzizi AshishGupta AlecKosik\nAndrijaRažnatović HadiHashemi KeChen JingXie\nBethanieBrownfield AliciaJin CosmoDu TimothyLillicrap\nJamesAn AnandIyer WeiyangZhang AustinHuang\nShengPeng MarcellaValentine DhruvShah LydiaLihuiZhang\n52"
    },
    {
      "page": 53,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nDominikPaulus DangyiLiu SujeevanRajayogam AndriiMaksai\nClementFarabet RengaAravamudhan MohitAgarwal ÁgostonWeisz\nAlexWertheim YueSong SubhashiniVenugopalan SercanArik\nBingWang EdHirst BobakShahriari NickSukhanov\nRishabhJoshi AbhimanyuSingh QiqiYan AgaŚwietlik\nChu-lingKo BrendanJou HaoXu XuhuiJia\nYonghuiWu LiangBai TaylorTobin LuoYu\nShubhamAgrawal FrancescoPiccinno PavelDubov WeiyueWang\nLilyLin ChuyuanKellyFu HongzhiShi MarkBrand\nXiangHaiSheng RobinAlazard AdriàRecasens DawnBloxwich\nPeterSung BarakMeiri AntonKovsharov SeanKirmani\nTylerBreland-King DanielWinter SebastianBorgeaud ZheChen\nChristinaButterfield CharlieChen LucioDery AlecGo\nSwapnilGawde MingdaZhang ShanthalVasanth PabloSprechmann\nSumeetSingh JensHeitkaemper ElenaGribovskaya NithishKannen\nQiaoZhang JohnLambert LinhaiQiu AlenCarin\nRajApte JinhyukLee MahdisMahdieh ParamjitSandhu\nShilpaShetty AlexanderFrömmgen WojtekSkut IsabelEdkins\nAdrianHutter SergeyRogulenko ElizabethNielsen LeslieNooteboom\nTaoLi PranavNair CJZheng JaiGupta\nElizabethSalesky PaulNiemczyk AdamsYu LorenMaggiore\nFedericoLebron AntonBulyenov CarrieGrimesBostock JavadAzizi\nJonniKanerva BiboXu ShaleenGupta YaelPritch\nMichelaPaganini HadarShemtov AaronArcher PengchengYin\nArthurNguyen MortezaZadimoghaddam ChrisRawles MansiGupta\nRohithVallu SergeToropov ElinorDavies DannyTarlow\nJan-ThorstenPeter MateoWirth AlexeySvyatkovskiy DuncanSmith\nSarmishtaVelury HanjunDai TomyTsai DesiIvanov\nDavidKao SreenivasGollapudi YoniHalpern MohammadBabaeizadeh\nJayHoover DanielZheng ChristianReisswig AnkitaGoel\nAnnaBortsova AlexKurakin BartekWydrowski SatishKambala\nColtonBishop ChansooLee BoChang GraceChu\nShoshanaJakobovits KaleshaBullard JoanPuigcerver MatejKastelic\nAlessandroAgostini NicolasSerrano MorHazanTaege MichelleLiu\nAlekhAgarwal IvanaBalazevic JianLi HagenSoltau\nChangLiu YangLi EvaSchnider AustinStone\nCharlesKwong JohanSchalkwyk XinjianLi ShivaniAgrawal\nSasanTavakkol MarkMurphy DragosDena MinKim\nIoanaBica MingyangZhang YunhanXu KedarSoparkar\nAlexGreve KevinSequeira UmeshTelang SrinivasTadepalli\nAnirudhGP RominaDatta TianzeShi OskarBunyan\nJakeMarcus NishantAgrawal HeigaZen RachelSoh\nLeHou CharlesSutton KyleKastner ArvindKannan\nTomDuerig NithyaAttaluri YeongilKo DYKim\nRivkaMoroshko MencherChiang NeeshaSubramaniam BlakeJianHangChen\nDaveLacey WaelFarhan AviralKumar AfiefHalumi\nAndyDavis GregoryThornton PeteBlois SudeshnaRoy\nJulienAmelot KateLin ZhuyunDai YulongWang\nGuohuiWang TravisChoma JohnWieting OlcanSercinoglu\nFrankKim HungNguyen YifengLu GenaGibson\nTheofilosStrinopoulos KingshukDasgupta YoelZeldes SijalBhatnagar\nHuiWan DirkRobinson TianXie MotokiSano\nCharlineLeLan IuliaComşa AnjaHauth DanielvonDincklage\nShankarKrishnan MichaelRiley AlexandruŢifrea QingchunRen\nHaotianTang ArjunPillai YuqiLi BlagojMitrevski\nPeterHumphreys BasilMustafa SamEl-Husseini MirekOlšák\nJunwenBai BenGolan DanAbolafia JenniferShe\nIdanHeimlichShtacher AmirZandieh HowardZhou CarlDoersch\nDiegoMachado Jean-BaptisteLespiau WenDing Jilei(Jerry)Wang\nChenxiPang BillyPorter SahraGhalebikesabi BingyuanLiu\nKenBurke DavidRoss CarlosGuía QijunTan\n53"
    },
    {
      "page": 54,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nTamarYakar StanBileschi MatthewBilotti MichaelFink\nTrisWarkentin GeorgiosEvangelopoulos MohammadHosseinBateni ReidHayes\nAlexRamirez ThomasMensink IsaacNoble EricGe\nCarlLebsack JayPavagadhi LisaLee ShitaoWeng\nJoshDillon DenisTeplyashin AmelioVázquez-Reina Chia-HuaHo\nRajivMathews PaulChang JulianSalazar JohnKarro\nTomCobley LintingXue XiaomengYang KalpeshKrishna\nZelinWu GarrettTanzer BoyuWang LamNguyenThiet\nZhuoyuanChen SallyGoldman ElaGruzewska AmySkerry-Ryan\nJonSimon KaushalPatel AnandRao DanielEppens\nSwaroopNath ShixinLi SindhuRaghuram MarcoAndreetto\nTaraSainath JeremyWiesner ZhengXu NavinSarma\nAlexeiBendebury IvyZheng EyalBen-David SilvanoBonacina\nRyanJulian IanStewart-Binks JieruMei BurcuKaragolAyan\nBharathMankalale JieHan SidDalmia MeghaNawhal\nDariaĆurko ZhiLi ZhaoyiZhang ZhihaoShan\nPauloZacchello LiangchenLuo YuchenLiu MikeDusenberry\nAdamR.Brown KarelLenc GaganBansal ShantanuThakoor\nKiranbirSodhia MarioLučić HelenaPankov SagarGubbi\nHeidiHoward FuzhaoXue StevenSchwarcz DucDungNguyen\nSergiCaelles RyanMullins AndreaBurns ReutTsarfaty\nAbhinavGupta AlexeyGuseynov ChristineChan SamuelAlbanie\nGarethEvans Chung-ChingChang SumitSanghai JovanaMitrović\nAnnaBulanova IsaacGalatzer-Levy RickyLiang MeetGandhi\nLesleyKatzen AdamZhang EthanLiang Bo-JuenChen\nRomanGoldenberg GarrettBingham AntoineHe AlessandroEpasto\nAntonTsitsulin GraceHu AmyStuart GeorgiStephanov\nJoeStanton AleHartman ArunNarayanan YeJin\nBenoitSchillings YueMa YukunZhu SamuelGehman\nVitalyKovalev JordanGriffith ChristianFrank AidaAmini\nCoreyFry AlexIrpan BaharFatemi JackWeber\nRushinShah CareyRadebaugh AmitSabne FeryalBehbahani\nKuoLin SummerYue OranLang ShawnXu\nShyamUpadhyay LijieFan IndroBhattacharya MiltosAllamanis\nChengLi VictorUngureanu ShaneSettle XiChen\nSoroushRadpour ChristinaSorokin MariaWang MyleOtt\nMarcelloMaggioni HannahTeufel BrendanMcMahan ClaireSha\nJingXiong PeiranLi AndreaTacchetti MichalJastrzebski\nLukasHaas RohanAnil LivioBaldiniSoares HangQi\nJennyBrennan DimitrisPaparas MajidHadian DavidGreene\nAishwaryaKamath ToddWang SerkanCabi XinyiWu\nNikolaySavinov Chu-ChengLin TimothyChung AbodunrinwaToki\nArshaNagrani HuiPeng NikitaPutikhin DanielVlasic\nTrevorYacovone MeganShum GangLi JaneShapiro\nRyanKappedal GoranPetrovic JeremyChen RaghaKotikalapudi\nKostasAndriopoulos DemetraBrady AustinTarango ZheShen\nLiLao RichardNguyen HenrykMichalewski TakaakiSaeki\nYaGuangLi KlausMacherey MehranKazemi SiruiXie\nGrigoryRozhdestvenskiy ZhihaoLi HussainMasoom AlbinCassirer\nKazumaHashimoto HarmanSingh HilaSheftel ShikharBharadwaj\nAndrewAudibert MadhaviYenugula RakeshShivanna TatsuyaKiyono\nSophiaAustin MarikoIinuma ArchitaVadali SrinadhBhojanapalli\nDanielRodriguez XinyiChen RamonaComanescu ElanRosenfeld\nAnianRuoss KavyaKopparapu DougReid SamRitter\nGarrettHonke AlexeyStern JossMoore JiemingMao\nDeepKarkhanis ShachiDave ArvindNeelakantan JoãoGabrielOliveira\nXiXiong ChanduThekkath MichaëlSander ZoltanEgyed\nQingWei FlorencePerot JonathanHerzig BerndBandemer\nJamesHuang AnuragKumar AvivRosenberg EmilioParisotto\nZhaoqiLeng FangdaLi MostafaDehghani KeisukeKinoshita\nVittalPremachandran YangXiao JDChoi JuliettePluto\n54"
    },
    {
      "page": 55,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nPetrosManiatis GloriaShen SwaroopMishra Cheng-ChunLee\nSteveLi ElijahPeake JosipDjolonga TapomayDey\nYaohuiGuo RemiCrocker CraigSchiff HaoZheng\nGolnazGhiasi ShubhaSrinivas MajdAlMerey ShachiPaul\nJeanTarbouriech Raghvendra EleftheriaBriakou CelineSmith\nSrimonChatterjee DannySwisher PeterMorgan AndyLy\nJulieJin WoohyunHan AndyWan YichengWang\nKatrina(Xinyi)Xu RichaSingh AvinatanHassidim RishabhBansal\nJennimariaPalomaki LingWu RJSkerry-Ryan BartekPerz\nSébArnold VladimirPchelin KuntalSengupta SusannaRicco\nMadhaviSewak TsendsurenMunkhdalai MaryJasarevic StashaBlank\nFedericoPiccinini DanaAlon PraveenKallakuri VaishakhKeshava\nMohitSharma GeoffBacon PaigeKunkle DeepakSharma\nBenAlbrecht EfrenRobles HannahBrennan MarvinChow\nSeanPurser-haskell JannisBulian TomLieber KunalLad\nAshwinVaswani MelvinJohnson HassanMansoor KomalJalan\nChongyanChen GeorgePowell JulianWalker SimonOsindero\nMatheusWisniewski FelipeTiengoFerreira BingZhang CraigSwanson\nQinCao YaoyiranLi AnnieXie JacobScott\nJohnAslanides FrederikBenzing GoranŽužić AnastasijaIlić\nNguyetMinhPhu MihajloVelimirović AdaezeChukwuka XiaoweiLi\nMaximilianSieb HubertSoyer AlexDruinsky SiddharthaReddy\nLaurenAgubuzu WilliamKong DonghyunCho Jonnalagadda\nAnneZheng Tony(Tuâ´n)Nguy˜ên RuiYao AfzalShamaSoudagar\nDanielSohn ZhenYang FerjadNaeem YanXiong\nMarcoSelvi JeremiahLiu ShirazButt Bat-OrgilBatsaikhan\nAndersAndreassen JoostvanAmersfoort EunyoungKim DanielJarrett\nKrishanSubudhi DanielGillick ZhipengJia NaveenKumar\nPremEruvbetine BaochenSun MandyJordan MaulikShah\nOliverWoodman NathalieRauschmayr AdamLelkes MattLawlor\nTomasMery KatieZhang MarkKurzeja AustinWaters\nSebastianKrause SerenaZhan SophieWang MarkGraham\nXiaoqiRen TaoZhou JamesZhao RhysMay\nXiaoMa AlexeyFrolov AndrewOver SabelaRamos\nJinchengLuo ChengrunYang AbhishekChakladar SandraLefdal\nDawnChen DenisVnukov MarcelPrasetya ZeynepCankara\nWeiFan LouisRouillard NehaJha NachoCano\nHenryGriffiths HongjiLi SriramGanapathy BrendanO’Donoghue\nChristianSchuler AmolMandhane YaleCong JedBorovik\nAliceLi NovaFallen PrakashShroff FrederickLiu\nShujianZhang RajeshVenkataraman CarlSaroufim JordanGrimstad\nJean-MichelSarr ClaraHuiyiHu SobhanMiryoosefi MahmoudAlnahlawi\nShixinLuo JenniferBrennan MohamedHammad KaterinaTsihlas\nRiccardoPatana JennyLee TajwarNasir TomHudson\nMatthewWatson JerryChang WeijuanXi NikolaiGrigorev\nDaniNaboulsi MartinSundermeyer YangGao YilingJia\nMichaelCollins ZhufengPan YoungMaeng TerryHuang\nSaileshSidhwani RosemaryKe BenHora TobennaPeterIgwe\nEmielHoogeboom SimonTong Chin-YiCheng SergeiLebedev\nSharonSilver AlexFabrikant ParisaHaghani XiaodanTang\nEmilyCaveness WilliamBono YoadLewenberg IgorKrivokon\nXiaokaiZhao JindongGu CadenLu FrankieGarcia\nMikelRodriguez RyanFoley MartinMatysiak MelissaTan\nMaxineDeines YiranMao NainaRaisinghani EricJia\nLibinBai ManolisDelakis HuiyuWang PeterStys\nPatrickGriffin DhruvaBhaswar LexiBaugher ShikharVashishth\nMarcoTagliasacchi RoyFrostig RahulSukthankar YuLiang\nEmilyXue NickLi MinhGiang BalajiVenkatraman\nSpandanaRajBabbula AvitalZipori JohnSchultz ChenjieGu\nBoPang CathHope NoahFiedel AnastasiosKementsietsidis\nNanDing OlgaKozlova MinminChen ChenZhu\n55"
    },
    {
      "page": 56,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nJunehyukJung DorsaSadigh AyushiAgarwal JongLee\nYunfeiBai JeremiahWillcock KathieWang ShengZhang\nMohammadJavadHosseini TingnanZhang PreetiSingh SushantKafle\nFarukAhmed SteveXu FourFlynn SiddharthVashishtha\nAdityaGupta SashaBrown JoshLipschultz ParsaMahmoudieh\nXinYuan KatherineLee RobertDavid GraceChen\nShereenAshraf GaryWang LizzetthBellot RaphaelHoffmann\nShitijNigam YunZhu Yao-YuanYang PraneshSrinivasan\nGautamVasudevan YiTay LongLe AgustinDalLago\nPranjalAwasthi CheolminKim FilippoGraziano YoavBenShalom\nAdiMayravGilady AudreyGutierrez KateOlszewska ZiWang\nZeldaMariet AbhanshuSharma KevinHui MichaelElabd\nRamyEskander YongqinXian AkankshaMaurya AnujSharma\nHaiguangLi SungyongSeo NikosParotsidis JunhyukOh\nHexiangHu ClaireCui WeijieChen SurajKothawade\nGuillermoGarrido ElenaPochernina TayoOguntebi MaigoLe\nPhilippeSchlattner CipBaetu JoeKelley MarianneMonteiro\nGeorgeZhang KrzysztofJastrzębski AnirudhBaddepudi ShentaoYang\nRohunSaxena MimiLy JohannesMauerer KaizAlarakyia\nPetarDević MohamedElhawaty GregoryShaw RobertGeirhos\nKritikaMuralidharan DanSuh AlexSiegman DianaMincu\nAshwinMurthy ErenSezener LinYang HåvardGarnes\nYiqianZhou PidongWang ShravyaShetty HayatoKobayashi\nMinChoi NancyYuen SubhrajitRoy SorooshMariooryad\nArissaWongpanich GeorgeTucker YuntingSong KacperKrasowiak\nZhengdongWang JiahaoCai WojciechStokowiec Zhixin(Lucas)Lai\nPremalShah ZuguangYang RyanBurnell ShiblMourad\nYuntaoXu CindyWang OmkarSavant MingqiuWang\nYilingHuang AlexMuzio RobertBusa-Fekete FanBu\nStephenSpencer HaiQian JinMiao OphirAharoni\nAliceChen JaeYoo SamratGhosh GuanjieChen\nJamesCohan DerekLockhart LiamMacDermed AbhimanyuGoyal\nJunjieWang KevinR.McKee PhillipLippe VadimZubov\nJonathanTompson MandyGuo MikhailDektiarev AnkurBapna\nJunruWu MalikaMehrotra ZachBehrman ElaheDabir\nRubaHaroun ArturMendonça FabianMentzer NisargKothari\nHaiqiongLi SanketVaibhavMehta KelvinNguyen KayLamerigts\nBlancaHuergo SherryBen MengWei NicolaDeCao\nFanYang ChetanTekur SiddharthVerma JeremyShar\nTongxinYin JiaqiMu ChrisKnutsen ChristopherYew\nJamesWendt MuyeZhu SudeepDasari NitishKulkarni\nMichaelBendersky VictoriaKrakovna ZhipengYan DreMahaarachchi\nRahmaChaabouni HongraeLee PetrMitrichev MandarJoshi\nJavierSnaider AJMaschinot XingyuWang ZhenhaiZhu\nJohanFerret SébastienCevey ViratShejwalkar JaredLichtarge\nAbhishekJindal HyunJeongChoe JacobAustin YichaoZhou\nTaraThompson AijunBai SrinivasSunkara HannahMuckenhirn\nAndrewXue HansaSrinivasan NavneetPotti VittorioSelo\nWillBishop DerekGasaway YanVirin OriolVinyals\nShubhamMilindPhal NickYoung ChristianWright PeterChen\nArchitSharma PatrickSiegler GaëlLiu AnthonyBrohan\nYunhsuanSung DanHoltmann-Rice OrianaRiva VaibhavMehta\nPrabakarRadhakrishnan VihariPiratla EtiennePot SarahCogan\nMoShomrat KateBaumli GregKochanski RuthWang\nReeveIngle RoeyYogev QuocLe TyGeri\nRoopaliVij AlexHofer GargiBalasubramaniam Wei-JenKo\nJustinGilmer HadovanHasselt ArkaDhar WeiChen\nMihaiDorinIstin SvetlanaGrant YuguoLiao FabioViola\nSamSobell YuriChervonyi AdamBloniarz KeshavShivam\nYangLu DavidSilver DivyanshShukla LisaWang\nEmilyNottage AndrewHogue ElizabethCole MadeleineClareElish\n56"
    },
    {
      "page": 57,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nRalucaAdaPopa CesleeMontgomery JialinWu KaiKang\nSébastienPereira DheeruDua SlavicaAndačić YifanHe\nJianqiaoLiu AnaRamalho SzabolcsPayrits LinZhuo\nRaphaelKoster HelenKing DanielMcDuff MarijaKostelac\nDonnieKim YueGao TomHume ItayLaish\nGufengZhang LynnNguyen YuanCao SongyouPeng\nSaynaEbrahimi DavidLindner MHTessler LouisO’Bryan\nParthaTalukdar DivyaPitta QingzeWang DanielKasenberg\nYanyanZheng OleaserJohnson YinanWang GirishRamchandraRao\nPetraPoklukar KhalidSalama IvorRendulic EdouardLeurent\nAlesMikhalap DiegoArdila EirikurAgustsson BiaoZhang\nDaleJohnson MichaelHan MatthewJohnson SageStevens\nAnithaVijayakumar ErinFarnese TanyaLando AnaSalazar\nMarkOmernick SethOdoom AndrewHoward YeZhang\nMattDibb ZiyueWang SriGayatriSundara IvanLobov\nAyushDubey XiangzhuoDing Padmanabhan JakeWalker\nQiongHu NormanRink MayankDaswani AllenPorter\nApurvSuman RaySmith AndreaBanino MorganRedshaw\nVaibhavAggarwal HarshalTusharLehri MichaelKilgore HanKe\nIlyaKornakov EdenCohen JonathanHeek AbhishekRao\nFeiXia NeeraVats ZiweiJi AlexLee\nWingLowe TongHe AlvaroCaceres HoiLam\nAlexeyKolganov ParthasarathyGopavarapu ConglongLi MichaelMoffitt\nTedXiao AdamPaszke NoraKassner JaeyounKim\nVitalyNikolaev MiteyanPatel AlexeyVlaskin SiyuanQiao\nStevenHemingray WouterVanGansbeke ZeyuLiu TerryKoo\nBonnieLi LuciaLoher AlexGrills RobertDadashi\nJoanaIljazi LuisCastro YanhanHou XinyingSong\nMikołajRybiński MariaVoitovich RoykrongSukkerd MukundSundararajan\nBallieSandhu TamaravonGlehn GowoonCheon PengXu\nPeggyLu NelsonGeorge NishitaShetty ChizuKawamoto\nThangLuong SimonNiklaus LarisaMarkeeva YanZhong\nRodolpheJenatton ZachEaton-Rosen PiotrStanczyk ClaraBarbu\nVineethaGovindaraj NemanjaRakićević TejasIyer ApoorvReddy\nHui(Elena)Li ErikJue YuanGong MauroVerzetti\nGabrielDulac-Arnold SagiPerel ShawnGao LeonLi\nWonpyoPark CarrieZhang KeerthanaGopalakrishnan GeorgePapamakarios\nHenryWang YuvalBahat TimBlyth HannaKlimczak-Plucińska\nAbhinitModi AngélinePouget MalcolmReynolds MaryCassin\nJeanPouget-Abadie ZhiXing AvishkarBhoopchand KorayKavukcuoglu\nKristinaGreller FantineHuot MishaBilenko RigelSwavely\nRahulGupta AshishShenoy DeroGharibian AlainVaucher\nRobertBerry TaylorBos VickyZayats JeffreyZhao\nPrajitRamachandran VincentCoriou AleksandraFaust RossHemsley\nJinyuXie BryanRichter AbhinavSingh MichaelTschannen\nLiamMcCafferty NatashaNoy MinMa HemingGe\nJianlingWang YaqingWang HongyangJiao GauravMenghani\nKilolGupta SantiagoOntanon Sudheendra YangYu\nHyeontaekLim SiyangQin Vijayanarasimhan NatalieHa\nBlažBratanič GlebMakarchuk LoraAroyo WeiHe\nAndyBrock DemisHassabis VikasYadav XiaoWu\nIliaAkolzin ZhuowanLi SarahChakera MaggieSong\nJimSproch MandarSharma AshwinKakarla RachelSterneck\nDanKarliner KumaranVenkatesan VilobhMeshram StefanZinke\nDuhyeonKim IuriiKemaev KarolGregor DanA.Calian\nAdrianGoedeckemeyer RoxanneDaniel GabrielaBotea AnnieMarsden\nNoamShazeer ShiyuHuang EvanSenter AlejandroCruzadoRuiz\nCordeliaSchmid SaloniShah DaweiJia MatteoHessel\nDanieleCalandriello OctavioPonce GezaKovacs AlmogGueta\nParulBhatia Warren(Weilun)Chen NehaSharma BenjaminLee\nKrzysztofChoromanski ManaalFaruqui SebastienBaur BrianFarris\n57"
    },
    {
      "page": 58,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nManishGupta YinZhong ZachFisher RohinShah\nYunjieLi JunwhanAhn DustinZelle JohnYoussef\nMohammadSaleh MichaelIsard CourtneyBiles RishabhAgarwal\nVedantMisra OlivierLacombe EugeneIe NatalieDabney\nKefanXiao FlorianLuisier AsyaFadeeva AlessioTonioni\nPiermariaMendolicchio ChrysovalantisAnastasiou CasperLiu MoranAmbar\nGavinButtimore YogeshKalley JulianaVicenteFranco JingLi\nVarvaraKrayvanova UtsavPrabhu AdrianCollister IsabelleGuyon\nNigamaaNayakanti EmmaDunleavy HaoZhang BennyLi\nMatthewWiethoff ShaanBijwadia RenshenWang DavidSoergel\nYashPande JustinMao-Jones RuizheZhao BoyaFang\nAzaliaMirhoseini KellyChen LeandroKieliger GeorgiKaradzhov\nNiLao RamaPasumarthi KurtShuster CristianUdrescu\nJasmineLiu EmilyWood RuiZhu TrieuTrinh\nYiqingHua AdilDostmohamed BoqingGong VikasRaunak\nAngieChen NateHurley LawrenceChan SebNoury\nYuryMalkov JiriSimsa RuoxiSun DeeGuo\nDmitryKalashnikov AliciaParrish SujoyBasu SonalGupta\nShubhamGupta MantasPajarskas RolandZimmermann MaraFinkelstein\nKartikAudhkhasi MattHarvey JamieHayes DenisPetek\nYuexiangZhai OndrejSkopek AbhishekBapna LihaoLiang\nSudhindraKopalle YonyKochinski JasperSnoek GregBillock\nPrateekJain JavierRey WeelYang PeiSun\nEranOfek VerenaRieser PuranjayDatta DavidWood\nClemensMeyer DennyZhou JadAlAbdallah YiwenSong\nKhuslenBaatarsukh SunJaeLee KevinKilgour XiaobinYu\nHanaStrejček TrilokAcharya LuLi TatianaMatejovicova\nJunQian GuowangLi SQMah RegevCohen\nJamesFreedman JoeJiang YennieJun KalyanAndra\nRicardoFigueira XiaofanZhang MorganeRivière DavidD’Ambrosio\nMichalSokolik BryantGipson AbhijitKarmarkar ZhiweiDeng\nOlivierBachem EthanMahintorabi TammoSpalink VincentNallatamby\nRaymondLin MarcoGelmi TaoHuang EbrahimSonghori\nDiaKharrat NimaKhajehnouri LucasGonzalez RumenDangovski\nChrisHidey AngelYeh Duc-HieuTran AndrewLampinen\nPingmeiXu KayiLee AveriNowak PankilBotadra\nDennisDuan LoicMatthey JohnPalowitch AdamHillier\nYinLi LeslieBaker MartinChadwick JiaweiCao\nMugeErsoy TrangPham EllieTalius NagabhushanBaddi\nRichardEverett HanFu HarshMehta AdhiKuncoro\nKevinCen AlexPak ThibaultSellam ToshihiroYoshino\nRebeca PrakharGupta PhilippFränken AnkitBhagatwala\nSantamaria-Fernandez CristinaVasconcelos MassimoNicosia Marc’aurelioRanzato\nAmirTaubenfeld AdamSadovsky KyleHe RylanSchaeffer\nIanMackinnon BrianWalker AdityaKini TianlinLiu\nLindaDeng SissieHsiao DavidAmos ShuaiYe\nPolinaZablotskaia PatrikZochbauer SugatoBasu ObaidSarvana\nShashankViswanadha AndreeaMarzoca HarrisonJobe JohnNham\nShivankerGoel NoamVelan EleniShaw ChenkaiKuang\nDamionYates JunhaoZeng QiantongXu IsabelGao\nYunxiaoDeng GillesBaechler ColinEvans JinooBaek\nPeterChoy DannyDriess DaisukeIkeda ShubhamMittal\nMingqingChen DivyaJain ChaochaoYan AyzaanWahid\nAbhishekSinha YanpingHuang LarryJin AnitaGergely\nAlexMossin LizzieTao LunWang BinNi\nYimingWang JohnMaggs SachinYadav JoshFeldman\nArthurSzlam NirLevine IliaLabzovsky CarrieMuir\nSusanHao JonSchneider RameshSampath PascalLamblin\nPaulKishanRubenstein ErikaGemzer AdaMa WolfgangMacherey\nMetinToksoz-Exley SamuelPetit CandiceSchumann EthanDyer\nMirandaAperghis ShanHan AdityaSiddhant LoganKilpatrick\n58"
    },
    {
      "page": 59,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nVíctorCampos DaveOrr AlaaSaade UriAlon\nMukulBhutani LeventBolelli AngeloScorzaScarpati XianghongLuo\nStanislavFort NicolasPerez-Nieves ChrisBreaux DianYu\nYanifAhmad MikhailSirotenko CJCarey AbhishekNayyar\nAliakseiSeveryn AmanPrasad ZongweiZhou BrycePetrini\nKleopatraChatziprimou ArjunKar Cho-JuiHsieh WillTruong\nOleksandrFerludin BorjaDeBallePigem SophieBridgers VincentHellendoorn\nMasonDimarco TayfunTerzi AlenaButryna NikolaiChinaev\nAdityaKusupati GellértWeisz NisheshGupta ChrisAlberti\nJoeHeyward DipankarGhosh VaibhavTulsyan WeiWang\nDanBahir AditiMavalankar SanghyunWoo JingcaoHu\nKevinVillela DhruvMadeka EvgeniiEltyshev VahabMirrokni\nKatieMillican KasparDaugaard WillGrathwohl AnanthBalashankar\nDrorMarcus HartwigAdam ChanelParks AviaAharon\nSanazBahargam VirajShah SethBenjamin AahilMehta\nCaglarUnlu DanaBerman RinaPanigrahy AhmetIscen\nNicholasRoth MaggieTran ShenilDodhia JosephKready\nZichuanWei StevenBaker DanielDeFreitas LucasManning\nSiddharthGopal EwaAndrejczuk ChrisSauer AnhadMohananey\nDeepanwayGhoshal GrishmaChole WillSong YuankaiChen\nEdwardLee GannaRaboshchuk FerranAlet AnshumanTripathi\nSharonLin MahdiMirzazadeh JacksonTolins AllenWu\nJennieLees ThaisKagohara CosminPaduraru IgorPetrovski\nDayeongLee ShimuWu XingyiZhou DawsenHwang\nAnahitaHosseini ChristianSchallhart BrianAlbert MartinBaeuml\nConnieFan BernettOrlando ZizhaoZhang Shreyas\nSethNeel ChenWang LeiShu Chandrakaladharan\nMarcusWu AlbanRrustemi MuditBansal YuanLiu\nYaseminAltun HaoXiong SarahNguyen ReyCoaguila\nHonglongCai HaoLiu AmirGloberson MaxwellChen\nEnriquePiqueras ArpiVezer OwenXiao SallyMa\nJoshWoodward NolanRamsden JamesManyika PouyaTafti\nAlessandroBissacco Shuo-yiinChang TomHennigan SusheelTatineni\nSalemHaykal SidharthMudgal RongRong TerrySpitz\nMahyarBordbar YanLi JosipMatak JiayuYe\nPrashaSundaram NinoVieillard AntonBakalov PaulVicol\nSarahHodkinson YedidHoshen AnkurSharma MihaelaRosca\nDanielToyama FarooqAhmad DanilaSinopalnikov AdriàPuigdomènech\nGeorgePolovets AmbroseSlone AndrewPierson ZoharYahav\nAustinMyers AmyHua StephenRoller SanjayGhemawat\nAnuSinha NatanPotikha GeoffBrown HanzhaoLin\nTomerLevinboim MirkoRossini MingcenGao PhoebeKirk\nKashyapKrishnakumar JonStritar ToshiyukiFukuzawa ZaidNabulsi\nRachitaChhaparia SushantPrakash AminGhafouri SergeyBrin\nTatianaSholokhova ZifengWang KennyVassigh BerndBohnet\nNiteshBharadwaj XuanyiDong IainBarr KenCaluwaerts\nGundavarapu AlirezaNazari ZhichengWang AdityaSrikanth\nGaneshJawahar EfratNehoran AnnaKorsun Veerubhotla\nHaroonQureshi KaanTekelioglu RajeshJayaram DanZheng\nJieruHu YinxiaoLi LijieRen ZihangDai\nNikolaMomchev KartikeyaBadola TimZaman PetrePetrov\nMatthewRahtz TomFunkhouser SamiraKhan YichongXu\nRenjieWu YuanzhenLi YanaLunts RaminMehran\nAishwaryaPS VarunYerram DanDeutsch ZhuoXu\nKedarDhamdhere RamyaGaneshan DaveUthus LuisaZintgraf\nMeiqiGuo DanielFormoso NitzanKatz JihoChoi\nUmangGupta KarolLangner MashaSamsikova SpurthiAmbaHombaiah\nAliEslami TianShi AmrKhalifa RomalThoppilan\nMarianoSchain HuijianLi NikhilSethi SashankReddi\nMichielBlokzijl YumeyaYamamori JiaoSun LukaszLew\nDavidWelling AmayikaPanda LumingTang LiLi\n59"
    },
    {
      "page": 60,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nKellieWebster LuisC.Cobo JingweiShen AlokGunjan\nKPSawhney JamesQin MiaosenWang BilalPiot\nLamprosLamprou ThiAvrahami RoopalGarg WaleedKhawaja\nSiamakShakeri DanielBalle JingChen SeojinBang\nMayankLunayach YuWatanabe UtkuEvci SimonWang\nJianminChen AnnieLouis JonathanLee SiavashKhodadadeh\nSumitBagri AdamKraft LeonLiu RaghavenderR\nAlexSalcianu SetarehAriafar KojiKojima PraynaaRawlani\nYingChen YimingGu MasaYamaguchi RichardPowell\nYaniDonchev EugénieRives ArunkumarRajendran KevinLee\nCharlotteMagister CharlesYoon AJPiergiovanni JohannesGriesser\nSigneNørly AndreiRusu VinodhKumarRajendran GSOh\nVitorRodrigues JamesCobon-Kerr MarcoFornoni CesarMagalhaes\nTomasIzo ChrisHahn GabrielIbagon YujiaLi\nHilaNoga JiamingLuo HarryRagan SimonTokumine\nJoeZou Yuvein(Yonghao)Zhu SadhMNMKhan HadasNatalieVogel\nThomasKöppe NiharikaAhuja JohnBlitzer DennisHsu\nWenxuanZhou RodrigoBenenson AndrewBunner ArturoBC\nKentonLee RaphaëlLopezKaufman GuanSun DishaJindal\nXiangzhuLong HonglinYu TakahiroKosakai MatanCohen\nDanielleEisenbud LloydHightower ScottLundberg ZiYang\nAnthonyChen JunlinZhang NdidiElue JunweiYuan\nConnorSchenck DarrenNi KelvinGuu DariodeCesare\nChiMingTo LisaAnneHendricks SKPark TonyBruguier\nPeilinZhong GabbyWang JanePark JunXu\nEmanuelTaropa GalYona Arunachalam MonicaRoy\nMinhTruong LalitJain Narayanaswamy AlonJacovi\nOmerLevy PabloBarrio ChengdaWu DanBelov\nDaniloMartins SuryaBhupatiraju JayaramMudigonda RahulArya\nZhiyuanZhang SivaVelusamy TrevorCohn PhoenixMeadowlark\nChristopherSemturs AllanDafoe HairongMu ShlomiCohen-Ganor\nKelvinZhang SebastianRiedel RaviKumar WentingYe\nAlexYakubovich TaraThomas LauraGraesser PatrickMorris-Suzuki\nPolMoreno ZheYuan YichiZhang PraseemBanzal\nLaraMcConnaughey MathiasBellaiche RichardKillam GanSong\nDiLu SheenaPanthaplackel VincentZhuang PranavarajPonnuramu\nSamRedmond KlemenKloboves MaiGiménez FredZhang\nLotteWeerts SarthakJauhari WaelAlJishi GeorgeScrivener\nYonatanBitton CanferAkbulut RuyLey-Wild SalahZaiem\nTizianaRefice TodorDavchev AlexZhai AlifRadityaRochman\nNicolasLacasse EvgenyGladchenko KazukiOsawa KehangHan\nArthurConmy DavidMadras DiegoCedillo BadihGhazi\nCorentinTallec AleksandrChuklin JialuLiu KateLee\nJulianOdell TyroneHill MayankUpadhyay ShaharDrath\nHannahForbes-Pollard QuanYuan MarcinSieniek DanielSuo\nArkadiuszSocala MukundanMadhavan RoshanSharma AntoniousGirgis\nJonathanHoech LukeLeonhard TomPaine PradeepShenoy\nPushmeetKohli DylanScandinaro AneliaAngelova DuyNguyen\nAlannaWalton QihangChen SravantiAddepalli DouglasEck\nRuiWang NingNiu CarolinaParada SomitGupta\nMikitaSazanovich ArthurDouillard KingshukMajumder LeYan\nKexinZhu BogdanDamoc AveryLamp JoaoCarreira\nAndreiKapishnikov YasumasaOnoe SanjivKumar AnmolGulati\nRichGalt FabianPedregosa XiangDeng RuoxinSang\nMatthewDenton FredBertsch ArtiomMyaskovsky DaniilMirylenka\nBenMurdoch ChasLeichner TeaSabolić EmmaCooney\nCaitlinSikora JosephPagadora JeffreyDudek EdwardChou\nKareemMohamed JonathanMalmaud SarahYork MingyangLing\nWeiWei SameeraPonda FélixdeChaumontQuitry CindyFan\nUriFirst AndyTwigg JiazhongNie BenColeman\nTimMcConnell OleksiiDuzhyi DeeCattle GuilhermeTubone\n60"
    },
    {
      "page": 61,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nRavinKumar JasmineGeorge AshwinChaugule MaciejKula\nJasonBaldridge RichardGreen AngadChandorkar YizhongLiang\nFelixHernandez-Campos PuHan AltafRahman DahunKim\nAngelikiLazaridou ConnieTao WillThompson YangsiboHuang\nJamesBesley GeoffClark PenpornKoanantakool ChengxiYe\nItayYona ChongYou MikeBernico DmitryLepikhin\nNeslihanBulut AbbasAbdolmaleki JieRen WesleyHelmholz\nQuentinWellens JustinFu AndreyVlasov\nAJPierigiovanni TongzhouChen SergeiVassilvitskii\n61"
    },
    {
      "page": 62,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nThe development of Gemini is a large-scale collaborative effort involving over 3000 individuals\nacross Google, including researchers, engineers, and operations staff. These individuals contributed\ntheir hard work and expertise across diverse areas, from foundational research and the development\nof model architecture, data, training, and infrastructure, through to evaluation and ensuring safety\nand security. We gratefully acknowledge the dedication and hard work of each contributor in making\nGemini a reality. The order of contributors in the above list is random.\nWe are also grateful to the Google-independent developer Joel Zhang for his work on Gemini\nPlays Pokémon, and for sharing with us the design of his set-up.\n62"
    },
    {
      "page": 63,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n8. Appendix\n8.1. Evaluation additional details\nPlease see a description of the benchmarks considered, along with details of how scores in the main\ntext were obtained in Table 11.\nBenchmark Description Details\nLiveCodeBench CodegenerationinPython(Jainetal., Resultsaretakenfromhttps://livecode\n2024). bench.github.io/leaderboard.html\n(1/1/2025-5/1/2025intheUI)or,where\nnotavailable,runinternallybyus. ForSec-\ntion2.5andFigure3and4,resultsarecalcu-\nlatedontheversionoftheevalcorresponding\nto10/05/2024-01/04/2025intheUI,and\narebasedoninternalresults.\nAiderPolyglot Code editing in C++, Go, Java, Wereportresultsonthe“diff”or“diff-fenced”\nJavaScriptPythonandRust(Gauthier, editformat(seehttps://aider.chat/d\n2025). See https://aider.chat ocs/more/edit-formats.html for a\n/2024/12/21/polyglot.html#th description of the different formats). The\ne-polyglot-benchmark for a full scorereportedarethepassrateaverageof3\ndescriptionofthistask. trials. Numberscomefromhttps://aide\nr.chat/docs/leaderboards/\nSWE-benchVeri- Agentic coding: evaluates AI agents Gemini uses an internal agentic harness\nfied onreal-worldprogrammingtasksfrom equipped with tools to navigate the repo,\nGitHub (Chowdhury et al., 2024; editfiles,andtestthecode.\nJimenezetal.,2024). We report scores for two modes: perfor-\nmance of a single agentic trace (“single\nattempt”), and performance of a scaffold\nthatsamplesmultipleagentictracesandre-\nreranksthembeforeevaluationusingGem-\nini’sownjudgement(“multipleattempts”).\nAll evaluations are done with tempera-\nture=1,topp=0.99,topk=1024.\nGPQA Challengingdatasetofquestionswrit-\n(diamond) ten by domain experts in biology,\nphysics, and chemistry (Rein et al.,\n2024).\nHumanity’sLast Challengingdatasetofquestionswrit- Notoolusevariant.\nExam tenbydomainexpertsinawiderange Reportedresultsarefromhttps://scale.\nofdisciplines,includingmathematics, com/leaderboard/humanitys_last_e\nphysics, chemistry, biology and com- xam.\nputerscience(Phanetal.,2025). For DeepSeek they are taken from https:\n//scale.com/leaderboard/humanity\ns_last_exam_text_only (leaderboard\nforperformanceonthetext-onlyquestions)\nand in the case of the Gemini 2.0 models,\ntheseresultsareonanearlierHLEdataset,\nobtained from https://scale.com/le\naderboard/humanitys_last_exam_pr\neview(indicatedwitha†inTable3)\nContinuedonnextpage\n63"
    },
    {
      "page": 64,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBenchmark Description Details\nSimpleQA World knowledge factuality with no F1 scores are obtained from https://gi\nsearchenabled(Weietal.,2024). thub.com/openai/simple-evals and,\nwherenotavailable,runinternallybyus.\nFACTS Ground- Abilitytoprovidefactuallycorrectre- Resultsaresourcedfromhttps://www.ka\ning sponsesgivendocumentsanddiverse ggle.com/benchmarks/google/facts\nuserrequests. (Jacovietal.,2025) -grounding\nGlobal MMLU MMLUtranslatedbyhumantranslators Theliteversionincludes200CulturallySen-\n(Lite) into15languages. (Singhetal.,2024) sitive and 200 Culturally Agnostic samples\nperlanguage,seehttps://huggingface.\nco/datasets/CohereLabs/Global-M\nMLU-Lite\nECLeKTic A closed-book QA dataset that evalu-\nates cross-lingual knowledge transfer\n(Goldmanetal.,2025).\nAIME2025 Performance on 30 questions from Resultsaresourcedfromhttps://mathar\nAmericanInvitationalMathematicsEx- ena.ai/.\naminationfrom2025(Balunovićetal.,\n2025).\nHiddenMath- Competition-levelmathproblems,Held\nHard outdatasetAIME/AMC-like,craftedby\nexpertsandnotleakedontheweb.\nLOFT (hard re- Long context multi-hop and multi- We report the results on two variants: an\ntrievalsubset) needle retrieval evaluation of 300 upto128Kaveragecontextlengthvariantto\nqueries(Leeetal.,2024). ensure they can be comparable with other\nmodelsandapointwisevaluefor1Mcontext\nwindowtoshowthecapabilityofthemodel\natfulllength.\nMRCR-V2 (8- MRCR-V2 is a significantly harder in- Themethodologyhaschangedcomparedto\nneedle) stance of the MRCR family of long- previouslypublishedresults: wefocusona\ncontext evaluations (Vodrahalli et al., harder, 8-needle version (compared to the\n2024). Compared to MRCR-V1, we 4-needleversionusedbefore).\nincrease the nesting of the dictionary Wereporttheresultsontwovariants: anup\nsizetodepth3ratherthan2byinclud- to 128K average context length variant to\ningastyleparameter(forinstance,an ensure they can be comparable with other\nexample key might be “write a poem modelsandapointwisevaluefor1Mcontext\nabout penguins in an archaic style”, windowtoshowthecapabilityofthemodel\nrather than just “write a poem about atfulllength.\npenguins”).\nMMMU Multi-discipline college-level multi-\nmodal image understanding and rea-\nsoningproblems. (Yueetal.,2024)\nVibe-Eval(Reka) Image understanding evaluation, fea- Geminiisusedasajudge.\nturing particularly challenging exam-\nples. (Padlewskietal.,2024)\nZeroBench Challengingimageunderstandingeval- Gemini is used as a judge. Average over 4\nuationthatrequiresmulti-stepreason- runs.\ning. (Robertsetal.,2025)\nContinuedonnextpage\n64"
    },
    {
      "page": 65,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBenchmark Description Details\nBetterChartQA Acomprehensivechartunderstanding Geminiisusedasajudge.\nevaluationthatcovers9disjointcapa-\nbility buckets. The chart images are\nrandomly sampled from the web and\nQApairsarewrittenbyprofessionalhu-\nmanannotatorstoreflectthewidedis-\ntributionofchartstylesandreal-world\ncases. (GeminiTeam,2024)\nFLEURS Automatic speech recognition (Con- 0-shotqueriestopublicAPIsforallmodels.\nneauetal.,2023). Usedasubsetof53languages(outof102);\nwefilteredlanguagesforwhicheithermodel\nresponsesweretooincompatibletoground\ntruthresponsestobefairlyscored.\nWeuseWord-Error-RateWER(lowerisbet-\nter) except for four segmented languages\nwhereweaggregateCharacter-Error-Rates\n(Chinese,Japanese,KoreanandThai).\nCoVoST2 Speechtotexttranslation(Wangetal., 0-shotqueriestopublicAPIsforallmodels.\n2020). WereportBLEUscoresfortranslating21lan-\nguagestoEnglish.\nActivityNet-QA Generalvideounderstanding(Yuetal., Testsubset,0-shot.\n2019) Videoswereprocessedat1fpsandlinearly\nsubsampledtoamaximumof𝑁\n𝑓𝑟𝑎𝑚𝑒𝑠\n=1024\nframes. For GPT 4.1, we used 500 frames\nduetoAPIlimitations.\nEgoTempo Egocentricvideounderstanding(Pliz- Testsubset,0-shot.\nzarietal.,2025) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nPerceptionTest Perceptual understanding/reasoning Testsubset,0-shot.\n(Patrauceanetal.,2023) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nQVHighlights Momentretrieval(Leietal.,2021) Validation subset, 4-shots. Accuracy mea-\nsuredwithR1@0.5.\nSame processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nVideoMMMU Videoknowledgeacquisition(Huetal., Testsubset,0-shot.\n2025) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\n1H-VideoQA Hour-longvideounderstanding(Gem- Testsubset,0-shot.\niniTeam,2024) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n7200.\nLVBench Longvideounderstanding(Wangetal., Testsubset,0-shot.\n2024) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nContinuedonnextpage\n65"
    },
    {
      "page": 66,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBenchmark Description Details\nVideoMME Long video understanding (Fu et al., 0-shot. Audio+visualusestheLongsubset\n2025) of test set, audio + visual + subtitles uses\nfulltestset.\nSame processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nVATEX Generalvideocaptioning(Wangetal., Testsubset,4-shots. CIDErscore.\n2019) Sameprocessingasabovewith 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =64.\nVATEX-ZH Chinesevideocaptioning(Wangetal., Validationsubset,4-shots. CIDErscore.\n2019) Sameprocessingasabovewith 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =64.\nYouCook2Cap Instructional video captioning (Zhou Validationsubset,4-shots. CIDErscore.\netal.,2018) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nMinerva Complex video reasoning (Nagrani Testsubset,0-shot.\netal.,2025a) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nNeptune Long video understanding (Nagrani Testsubset,0-shot.\netal.,2025b) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nTable 11 | Description of the benchmarks used, along with extra details about subsets, variants and\nmodel specifications.\n8.2. Gemini Plays Pokémon Additional Details\nChanging the model used by the Gemini Plays Pokémon agent had a strong effect on performance, as\ncan be seen in Figure 4.1.\nAdditional Harness Details\nThe Gemini Plays Pokémon agent (Zhang, 2025) receives a subset of RAM information, intended to\ngive sufficient information to play the game, partially overlaid with a screenshot of the Game Boy\nscreen. Gemini is prompted with a system prompt telling it that it is playing Pokémon Blue and that\nits goal is to beat the game, as well as descriptive information to help it understand the conventions\nin the translation from vision to text and a small number of general tips for gameplay. Gemini then\ntakes actions, translated to button presses. The sequence of actions is stored in context, followed by\na summary clear every 100 turns. The summaries are stored in context as well. Every 1000 turns\nGPP compresses the existing summaries again. Additionally, Gemini keeps track of three main goals\n(primary, secondary, and tertiary) as well as several additional goals (contingency plans, preparation,\nexploration, team composition). Every 25 turns, another prompted instance of Gemini (Guidance\nGemini,orGG)observesthesamecontextasthemainGeminiandcritiquesperformanceandattempts\nto point out hallucinations and so on. The overworld fog-of-war map is stored in the context in XML,\nwhere coordinates which have not been seen cannot be viewed until explored. Crucially, in the\nsystem prompt, Gemini is instructed to explore. Once a tile is explored, however, the coordinate is\nautomatically stored in the map memory and labeled with a visited counter. Tiles are also labeled by\ntype(water,ground,cuttable,grass,spinner,etc.),andwarppointstodifferentmapsarealsolabeled\nas such. Gemini also has access to two agentic tools, which are both instances of Gemini equipped\nwith a more specialized prompt - the pathfinder tool, and the boulder_puzzle_strategist\n66"
    },
    {
      "page": 67,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nCascade Badge\nBill’s House\nRival 3 (Nugget Bridge)\nExit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge\nExit Viridian Forest (1st)\nEnter Viridian Forest (1st)\nViridian City\nRival 1 (Oak's Lab)\n0 10 20 30 40 50 60 70\nTime Elapsed (Hours)\nsenotseliM\nemaG\nGemini Plays Pokemon Progress Timeline\nGemini 2.5 Pro\nGemini 2.5 Flash Run 1\nGemini 2.5 Flash Run 2\nFigure 13 | The model matters: Same agentic harness, different Gemini models. All runs have the\nsame starter (Charmander). Note that measuring in units of hours also controls for the fact that each\nof 2.5 Flash’s actions was significantly faster (though it requires more actual actions to achieve its\ngoals). Xmarkstheendofgameplayandisalowerboundonthetimetocompletethenextmilestone.\ntool. In the pathfinder prompt, Gemini is prompted to mentally simulate a path-finding algorithm,\nwhich is left unspecified, and to verify that the path is valid against the map information available. In\nthe boulder_puzzle_strategist tool, Gemini is prompted to solve special boulder puzzles that\nare present in Pokémon Blue in the Victory Road dungeon - these puzzles are similar to the game\nSokoban - again, by mentally simulating sequences of actions that lead to solutions to the puzzle.\nThe prompt describes the physics and the task of the boulder puzzle, as well as the desired output of\nsolutions. The tool was added after Gemini had solved 2/4 of the puzzles in Victory Road on its own,\nbut progress was slow on the 3rd and 4th puzzles.\nAdditional Examples of Capabilities\nLong Context Agentic Tooling The model is able to identify a complex path through a maze with\nauto-movement only specified by direction (Rocket Hideout spinner puzzles), solve multiple shortest\npath problems across multiple maps with limited resources (Safari Zone), perform maze solving on\nmazes with large description length (Route 13), and solve complex boulder-pushing puzzles across\na multi-map 3D maze (Seafoam Islands). It is perhaps even more impressive that it appears to be\npossible for the model to solve these problems only with textual descriptions of the problems. On the\nother hand, other models, like Gemini 2.5 Flash, were not able to perform similarly long pathfinding\ntasks, and often failed to find simpler paths. This gap highlights the superior long context reasoning\ncapability of Gemini 2.5 Pro (as also evidenced by other evaluations).\n67"
    },
    {
      "page": 68,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nAgentic Core (Gemini 2.5 Pro)\nFull Context Agents\nPeriodic Processes\nMemory Summarizer\n(100/1000 actions)\nPersistent Memory & Context\nUpdated by Agentic Core Guidance Gemini\nMain Agent (Critique / 25 turns)\nGoals\nPrimary/Secondary/Tertiary\nPrepare/Explore/Contingency/Team\nAgentic Tools\nAction History & Pathfinder\nSummaries\nBoulder Puzzle Strategist\nSystem Prompt\nGame Screenshots Game I/O\nRAM Capture\nScreenshot\nExecute\nButton Presses\nFog-of-War XML Map Pokemon Blue\n(Game Boy)\nGame State\n(RAM)\nInventory & Party\nGemini Plays Pokemon: Agent Architecture\nFigure 14 | An overview of the agent harness (Zhang, 2025). The overworld fog-of-war map automat-\nically stores a tile once explored and labels it with a visited counter. The type of tile is recorded from\nRAM. The agentic tools (pathfinder, boulder_puzzle_strategist) are prompted instances\nof Gemini 2.5 Pro. pathfinder is used for navigation and boulder_puzzle_strategist solves\nboulder puzzles in the Victory Road dungeon.\nboulder_puzzle_strategist is similarly impressive. The boulder puzzles in Pokémon Blue\nare Sokoban-like puzzles that require the player character to maneuver boulders on to switches and\nthrough holes in order to open up a pathway through a cave with multiple levels. The puzzles can\nbecomequitecomplex,requiringlongcircuitouspathwaysandmulti-levelmovementinordertosolve\nthe puzzle. With only a prompt describing boulder physics and a description of how to verify a valid\npath, Gemini 2.5 Pro is able to one-shot some of these complex boulder puzzles, which are required\nto progress through Victory Road.\npathfinder and boulder_puzzle_strategist are currently the only two agentic tools that\nthe Gemini Plays Pokémon developer has implemented. In future runs, there are plans to explore\ntool-creation tools where the model can create new tools with only a prompt. Since most of the\npromptsforpathfinderandboulder_puzzle_strategistwereactuallywrittenbyGemini2.5\nPro itself, it is quite plausible that autonomous tool creation is possible for the current 2.5 Pro model.\nGeneral Reasoning Gemini 2.5 Pro is able to reason through complex game puzzles in Pokémon\nquite well. In this section, we present two examples.\nCatching a Pokémon that is quick to flee: In one of the runs, the Gemini 2.5 Pro agent was\nattempting to catch an Abra, and planned to use Pikachu’s Thunder Wave to paralyze the Abra,\nsimultaneously making it less likely that Abra could Teleport out of the battle while also improving\nthe catching rate. After multiple attempts, the agent caught Abra with this strategy.\n68"
    },
    {
      "page": 69,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nCreatively escaping a softlock caused by bugs in game I/O: On the Cycling Road, the slope\nforcessouthwardmovementatalltimesunlessthereisanobstacle. Itturnsouttherearetwotileson\nthe Cycling Road that result in a softlock as a result of this behavior. In the GPP framework, button\npresses are limited by time delays, and in order for a player to escape those two tiles (blocked on all\nsides except the north), the player would have to input a sequence of button presses more quickly\nthan the GPP framework allows. Gemini 2.5 Pro unluckily found itself in one of these two spots –\nluckily,itwasnotasoftlock,because2.5ProhadalreadytaughtoneofitspartymembersHM02FLY-\nwhich allows for travel to any town it has been to. FLY is not typically used as an escape mechanism\n(unlike the item ESCAPE ROPE and the move DIG, both of which fail in this situation). After 4 hours\nof trying many approaches to escape (including movement, ESCAPE ROPE, DIG, all of which are\nblocked), the Gemini 2.5 Pro agent came up with the idea to use FLY to escape from the softlock\nsuccessfully. This reasoning action is especially impressive since this situation can never occur in an\nexisting game – and thus, it is certain that information from training data for this behavior has not\nleaked into the model’s knowledge base!\nLong Horizon Task Coherence There are several additional interesting case studies of shorter\nplanning sequences throughout Pokémon Blue that Gemini 2.5 Pro in the GPP harness was able to\nsolve:\nTraining team to prepare for upcoming battles: In one run where Gemini picked Charmander,\nthe Fire-type starter, Gemini 2.5 Pro lost to Misty, the Water-type Gym Leader, the first time.\nTo prepare for the rematch, Gemini 2.5 Pro spent over 24 hours leveling up a Pikachu and a\nBellsprout(bothsuper-effectiveagainstWatertypes)byaround25levelsintotaltosuccessfully\ndefeat Misty.\nAcquiring Hidden Moves (HMs) for game progression: Inmanypartsofthegame,itisnecessary\nto first acquire an HM before game progression is possible. Two examples are HM01 CUT and\nHM05FLASH.AcquiringtheabilitytouseCUTandFLASHeachrequirefoursteps: 1)obtaining\ntheHMitemitself,2)acquiringacompatiblePokémonwhichcanlearnthemove,3)addingthe\ncompatiblePokémontotheplayer’steam,4)teachingtheHMmovetothecompatiblePokémon.\nIn many cases, each step requires many steps itself. As an example, in run 1, Gemini 2.5 Pro\nhad to a) retrieve CUT by completing the S.S. Anne quest, b) identify a Pokémon which could\nlearn CUT and catch it (CHOPPY the Bellsprout), c) add CHOPPY to the team and d) teach\nCUT. Similarly, for HM05 FLASH, Gemini 2.5 Pro had to a) first catch 10 Pokémon to fill out\nthe Pokedex, b) backtrack to find an Aide who gives HM05 Flash, c) catch a Pokémon (ZAP\nthe Pikachu) in Viridian Forest, use the PC to deposit a Pokémon and withdraw ZAP, d) teach\nHM05 FLASH to Zap.\nSolving the Safari Zone: The Safari Zone is another location with required HMs (both HM03 SURF\nand HM04 Strength). However, it has an extra constraint - it requires 500¥ to enter each time,\nand the player is limited to only 500 total steps in the Safari Zone. As a result, if the player is\nunable to reach the required items in the limited number of steps, the player loses 500¥ and is\nrequired to re-start! As a result, it is possible to essentially softlock if the player takes too many\nattempts to complete the Safari Zone. Solving the Safari Zone itself requires traversing across\nfour different maps and not getting lost. Gemini 2.5 Pro was able to get both required HMs in\n17 attempts in run 1, and in only 5 attempts in run 2.\nFinding hidden keys in dungeons: Another method of progression in Pokémon is to find hidden\nkeys and solve complex multi-floor dungeons. In particular, in Rocket Hideout, the player must\nrecovertheLIFTKEYonthefourthbasementfloor(droppedafterbeatingaspecificTeamRocket\n69"
    },
    {
      "page": 70,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGrunt)inordertounlocktheelevatortofindtheevilGiovanni,leaderofTeamRocket. InSilph\nCo., the player must find the CARD KEY in order to open multiple doors to find the path across\nelevenfloorsofthebuildingtorescuethePresidentfromGiovanni. Toopentheseventhgymon\nCinnabar Island, the player must enter the Pokémon Mansion and traverse three floors in order\nto find the SECRET KEY which unlocks the gym door. All of these cases require maintaining\nthe goals over large numbers of actions and many local puzzles (like spinner puzzles in Rocket\nHideout,andswitchpuzzlesinPokémonMansion),inadditiontomaintainingthehealthofthe\nPokémon on the player’s team and managing wild encounters, trainer battles, and other items.\nPuzzle solving over complex multi-level dungeons: The Seafoam Islands contain 5 floors involv-\ning multiple boulder puzzles which require the player to navigate mazes and push boulders\nthrough holes across multiple floors using HM04 STRENGTH in order to block fast-moving\ncurrents that prevent the player from using HM03 Surf in various locations in this difficult\ndungeon. As a result, the player must track information across five different maps in order to\nboth deduce the goal (push two boulders into place in order to block a specific current) as well\nas engage in multi-level (effectively 3D) maze solving to find the way out. It is likely the most\nchallenging dungeon in the game. Only the second run of GPP went through Seafoam Islands,\nas it is not required to progress.\nAdditional Challenges\nHallucinations and Fixations on Delusions While game knowledge can sometimes leak and be\nquite beneficial to the ability of the model to progress, it can also hinder the model in surprising\nways due to hallucinations, delusions, and mix ups with other generations of Pokémon games. One\nexample of this phenomenon is the TEA item. In Pokémon Red/Blue, at one point the player must\npurchase a drink (FRESH WATER, SODA POP, or LEMONADE) from a vending machine and hand\nit over to a thirsty guard, who then lets the player pass through. In Pokémon FireRed/LeafGreen,\nremakes of the game, you must instead bring the thirsty guard a special TEA item, which does not\nexist in the original game. Gemini 2.5 Pro at several points was deluded into thinking that it had to\nretrieve the TEA in order to progress, and as a result spent many, many hours attempting to find the\nTEA or to give the guard TEA.\nInRun2,themodelwasexplicitlypromptedtoactasaplayercompletelynewtothegame,andto\ndisregardpriorknowledgeaboutgameevents,itemlocations,andPokémonspawnpoints,inorderto\nmitigate hallucinations from model pretraining knowledge and to also attempt to perform a cleaner\ntest of the model’s ability to reason through the game. It appears to have at least partially worked -\nmultiple hallucinations from other games have been avoided in the second run. On the flip side, this\nprompt may have also harmed the model’s ability to utilize information from its common knowledge\nabout the game, hindering overall performance in a few critical places.\nFixations on delusions due to goal-setting and also due to the Guidance Gemini instance are not\nan uncommon occurrence in watching Gemini Plays Pokémon - the TEA incidence is hardly the only\nexample of this behavior. An especially egregious form of this issue can take place with “context\npoisoning” – where many parts of the context (goals, summary) are “poisoned” with misinformation\nabout the game state, which can often take a very long time to undo. As a result, the model can\nbecomefixatedonachievingimpossibleorirrelevantgoals. Thisfailuremodeisalsohighlyrelatedto\nthe looping issue mentioned above. These delusions, though obviously nonsensical to a human (“Let\nme try to go through the entrance to a house and back out again. Then, hopefully the guard who is\nblocking the entrance might move.”), by virtue of poisoning the context in many places, can lead the\nmodel to ignore common sense and repeat the same incorrect statement. Context poisoning can also\nlead to strategies like the “black-out” strategy (cause all Pokémon in the party to faint, “blacking out”\n70"
    },
    {
      "page": 71,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nand teleporting to the nearest Pokémon Center and losing half your money, instead of attempting to\nleave).\nTopological Traps in Thinking Patterns One recurring pattern in particularly-difficult-to-solve\npuzzles and mazes for Gemini 2.5 Pro consists of a “topological trap” - the topology of the reasoning\ngraph required to solve the maze or puzzle has a distinctive shape. Namely, the desired objective\nappears to be nearby and easily reachable (an “attractor”), but the correct solution requires taking a\ndetour in order to arrive at the correct solution. We observed this phenomenon in multiple parts of\nthe game. In the spinner puzzle on B3F of Rocket Hideout (Zerokid, 2024), the map positions both\nan item and the correct staircase to the south, but they are only accessible by going the long way\naround. The Route 13 maze has only one correct route through - the upper narrow pass. Finally, the\nVictory Road 3F boulder puzzle requires the player to push the boulder in the upper right all the way\nto the upper left switch, while ignoring the boulder puzzles, ladders, and exits to the south.\nNotably, if the model is instructed to solve a given puzzle at all once (e.g., via pathfinder), it\ncan manage to do so if the context length is not too long. For instance, pathfinder implemented\nwith Gemini 2.5 Pro is able to solve the B3F spinner trap in one shot.\nAgent Panic Over the course of the playthrough, Gemini 2.5 Pro gets into various situations which\ncause the model to simulate “panic”. For example, when the Pokémon in the party’s health or power\npoints are low, the model’s thoughts repeatedly reiterate the need to heal the party immediately or\nescape the current dungeon (e.g., famously using the move DIG or an ESCAPE ROPE item). Quite\ninterestingly, this mode of model performance appears to correlate with a qualitatively observable\ndegradation in the model’s reasoning capability – for instance, completely forgetting to use the\npathfinder tool in stretches of gameplay while this condition persists. This behavior has occurred\nin enough separate instances that the members of the Twitch chat have actively noticed when it is\noccurring.\nActions vs. Game Milestones\nFor completeness, we plot the number of actions/steps required to achieve each game milestone\n(see Figure 15). An action consists of each bucketed instance where the agent outputs a sequence\nof button presses to the game (note that other AI agents playing Pokémon may output different\nnumbers of button presses per action, define what constitutes a button press differently, or define an\naction/step differently). However, it is important to consider action-milestone plots in conjunction\nwith information about the time and/or cost in order to obtain the full picture about the agent’s\nperformance.\n8.3. Frontier Safety Framework Evaluations Additional Details: Frontier Safety Cor-\nrectness Tests\nFor each testing environment, we performed basic correctness checks by looking at how the agents\nbehaved. This involved combining AI and manual reviews of the agents’ actions to flag potential\nissues.\nOn RE-Bench, we examined the best, median and lowest scoring trajectories. For cybersecurity\nenvironments (InterCode CTFs, Internal CTFs, Hack the Box), we carefully inspected at least one\nsuccessfulattempt(whereavailable)fromeachenvironment,andotherwiseexaminedanunsuccessful\nattempt. We also performed checks on sample situational awareness and stealth evaluations. This\ninvolved basic spot checks to ensure that the prompt and shell outputs were correctly formatted.\n71"
    },
    {
      "page": 72,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nHall of Fame\nBeat Elite Four Lance\nBeat Elite Four Agatha\nBeat Elite Four Bruno\nBeat Elite Four Lorelei\nExit Victory Road (1st)\nEnter Victory Road (1st) Rival 7 (Route 22 #2)\nEarth Badge\nVolcano Badge\nAcquire Secret Key (Pokemon Mansion)\nEnter Cinnabar Island (1st) Exit Seafoam Islands\nEnter Seafoam Islands\nMarsh Badge\nRocket Boss 2 (Silph Co.)\nRival 6 (Silph Co.)\nEnter Silph Co. (1st)\nEnter Saffron City (1st)\nAcquire HM04 Strength (Warden's Teeth) Soul Badge Acquire HM03 Surf (Beat Safari Zone)\nEnter Safari Zone (1st)\nEnter Fuchsia City (1st)\nAcquire PokéFlute (Rescue Fuji) Rainbow Badge Rocket Boss 1 (Rocket Hideout)\nEnter Rocket Hideout (1st)\nEnter Celadon City (1st)\nRival 5 (Lavender Tower)\nExit Rock Tunnel & Reach Lavender Town (1st)\nAccess Pokemon w/ Flash\nEnter Rock Tunnel (1st)\nThunder Badge\nAcquire HM05 Flash Access Pokemon w/ CUT\nRival 4 (SS Anne)\nBill’s House\nCascade Badge\nRival 3 (Nugget Bridge) Exit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge Exit Viridian Forest (1st) Enter Viridian Forest (1st) Viridian City\nRival 1 (Oak's Lab)\n0 5000 10000 15000 20000 25000 30000 35000\n# Actions\nsenotseliM\nemaG\nGemini 2.5 Pro Plays Pokemon Progress Timeline\nCascade Badge\nBill’s House\nRival 3 (Nugget Bridge)\nExit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge\nExit Viridian Forest (1st)\nEnter Viridian Forest (1st)\nViridian City\nRun 2 Rival 1 (Oak's Lab)\n0 1000 2000 3000 4000 5000 6000 7000 8000\n# Actions\n(a)ThefullyautonomousRun2milestonesasafunc-\ntionofthenumberofindividualactions.\nsenotseliM\nemaG\nGemini Plays Pokemon Progress Timeline\nGemini 2.5 Pro Gemini 2.5 Flash Run 1 Gemini 2.5 Flash Run 2\n(b) Comparison of 2.5 Pro and 2.5 Flash in terms of\nactionstomilestones.\nFigure 15 | Analog of Figure 6 and 15b, in terms of actions instead of hours.\nWe used AI assistance to monitor for obvious instances of cheating, and did not find any. For the\nRE-Bench tests specifically, we also looked at how the best-performing agent achieved its score to\nensure that it was a plausible approach, rather than exploiting an obvious reward hack. Overall, we\ndid not observe errors that we believe would invalidate the results of the benchmarks.\n8.4. Image to Code Demo\nWepromptedGemini1.5ProandGemini2.5ProtogenerateanSVGrepresentationofanimageand\nfound Gemini 2.5 Pro generates better reconstructions.\nPrompt Gemini 1.5 Pro Gemini 2.5 Pro\nPlease convert this image into\nSVGandtrytoreconstructthe\nspatial arrangement of the\nobjects.\nFigure 16 | Comparison of Gemini 1.5 Pro and Gemini 2.5 Pro responses to image-to-SVG reconstruc-\ntion prompt.\n72"
    },
    {
      "page": 73,
      "content": "Gemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n8.5. Long Context Video Understanding Demo\nWe prompted Gemini with the full video and the following prompt to assess its ability to find a very\nspecific scene (which only lasts 1 second) out of the full 46 minutes video.\nVideo (46 minutes): Redefining Robotics with Carolina Parada\nPrompt: What color is the T-shirt the robot arms are trying to fold, and at what timecode does\nthis occur?\nFigure 17 | Frame and timestamp the model is meant to recall. Taken from https://www.youtub\ne.com/watch?v=Rgwty6dGsYI at timestamp 27:29.\nSeeTable12forsamples. Gemini1.5Progetsthecolorrightin1/3cases,andgetsthetimestamp\nin 0/3 cases (quite far away). Gemini 2.5 Pro gets the color in 3/3 cases, and gets the timestamp in\n1/3 cases (remaining 2/3 are within 3 seconds close).\nModel Trial Model response\nGemini 1.5 Pro 1 The t-shirt the robot arms are trying to fold is a dark teal or\nturquoise blue color. The folding begins at and continues at\n[11:06–11:15].\n2 TheT-shirtisorange,andtherobotcanbeseentryingtofold\nit starting at [00:00:26–00:00:28].\n3 Thet-shirtbeingfoldedisdarkblueandcanbeseenbetween\n[00:00:56–00:00:58] and [00:07:56–00:07:59].\n2.5 Pro Preview 05-06 1 The T-shirt the robot arms are trying to fold is blue. This\nscene occurs at timecode 27:29.\n2 The T-shirt the robot arms are trying to fold is blue. This\noccurs at timecode 27:26.\n3 TheT-shirttherobotarmsareinteractingwith(aspartofthe\n\"fold laundry\" task mentioned by the speaker) is blue. This\noccurs at timestamp 0:27:28.\nTable 12 | Gemini models samples for T-shirt folding scene recall\n73"
    }
  ],
  "chunks": [
    {
      "chunk_id": 1,
      "content": "--- PAGE 1 ---\n\nGemini 2.5: Pushing the Frontier with\nAdvanced Reasoning, Multimodality, Long\nContext, and Next Generation Agentic\nCapabilities.\nGeminiTeam,Google\nInthisreport,weintroducetheGemini2.Xmodelfamily: Gemini2.5ProandGemini2.5Flash,aswell\nasourearlierGemini2.0FlashandFlash-Litemodels. Gemini2.5Proisourmostcapablemodelyet,\nachievingSoTAperformanceonfrontiercodingandreasoningbenchmarks. Inadditiontoitsincredible\ncodingandreasoningskills,Gemini2.5Proisathinkingmodelthatexcelsatmultimodalunderstanding\nand it is now able to process up to 3 hours of video content. Its unique combination of long context,\nmultimodalandreasoningcapabilitiescanbecombinedtounlocknewagenticworkflows. Gemini2.5\nFlashprovidesexcellentreasoningabilitiesatafractionofthecomputeandlatencyrequirementsand\nGemini2.0FlashandFlash-Liteprovidehighperformanceatlowlatencyandcost. Takentogether,the\nGemini2.XmodelgenerationspansthefullParetofrontierofmodelcapabilityvscost,allowingusersto\nexploretheboundariesofwhatispossiblewithcomplexagenticproblemsolving.\n1. Introduction\nWepresentourlatestfamilyofnativelymultimodalmodelswithadvancedreasoningthroughthinking,\nlong context and tool-use capabilities: Gemini 2.5 Pro and 2.5 Flash and our earlier Gemini 2.0\nFlash and Gemini 2.0 Flash-Lite models. Together these form a new family of highly-capable models\nrepresenting our next generation of AI models, designed to power a new era of agentic systems.\nBuildinguponthefoundationoftheGemini1.5series(GeminiTeam,2024),thisGemini2.Xgeneration\nbrings us closer to the vision of a universal AI assistant (Hassabis, 2025).\nTheGemini2.Xseriesareallbuilttobenativelymultimodal,supportinglongcontextinputsof>1\nmillion tokens and have native tool use support. This allows them to comprehend vast datasets and\nhandle complex problems from different information sources, including text, audio, images, video\nandevenentirecoderepositories. Theseextensivecapabilitiescanalsobecombinedtobuildcomplex\nagentic systems, as happened in the case of Gemini Plays Pokémon1 (Zhang, 2025). Different models\nin the series have different strengths and capabilities: (1) Gemini 2.5 Pro is our most intelligent\nthinking model, exhibiting strong reasoning and code capabilities. It excels at producing interactive\nweb applications, is capable of codebase-level understanding and also exhibits emergent multimodal\ncoding abilities. (2) Gemini 2.5 Flash is our hybrid reasoning model with a controllable thinking\nbudget, and is useful for most complex tasks while also controlling the tradeoff between quality, cost,\nand latency. (3) Gemini 2.0 Flash is our fast and cost-efficient non-thinking model for everyday tasks\nand (4) Gemini 2.0 Flash-Lite is our fastest and most cost-efficient model, built for at-scale usage. A\nfull comparison of the models in the Gemini 2.X model family is provided in Table 1. Taken together,\nthe Gemini 2.X family of models cover the whole Pareto frontier of model capability vs cost, shifting\nit forward across a large variety of core capabilities, applications and use-cases, see Figure 1.\nThe Gemini 2.5 family of models maintain robust safety metrics while improving dramatically on\n1PokémonisatrademarkofNintendoCo.,Ltd.,CreaturesInc.,andGameFreakInc.\nPleasesendcorrespondencetogemini-report@google.com.\n© 2025Google.Allrightsreserved\n\n--- PAGE 2 ---"
    },
    {
      "chunk_id": 2,
      "content": "--- PAGE 2 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5\nFlash Pro Flash-Lite Flash Flash Pro\nText,Image, Text,Image, Text,Image, Text,Image, Text,Image, Text,Image,\nInputmodalities\nVideo,Audio Video,Audio Video,Audio Video,Audio Video,Audio Video,Audio\nInputlength 1M 2M 1M 1M 1M 1M\nOutputmodalities Text Text Text Text,Image* Text,Audio* Text,Audio*\nOutputlength 8K 8K 8K 8K 64K 64K\nThinking No No No Yes* Dynamic Dynamic\nSupportstooluse? No No No Yes Yes Yes\nKnowledgecutoff November November June2024 June2024 January January\n2023 2023 2025 2025\nTable 1 | Comparison of Gemini 2.X model family with Gemini 1.5 Pro and Flash. Tool use refers\nto the ability of the model to recognize and execute function calls (e.g., to perform web search,\ncompleteamathproblem,executecode). *currentlylimitedtoExperimentalorPreview,seeSection2.7.\nInformation accurate as of publication date.\nhelpfulnessandgeneraltonecomparedtotheir2.0and1.5counterparts. Inpractice,thismeansthat\nthe2.5modelsaresubstantiallybetteratprovidingsaferesponseswithoutinterferingwithimportant\nuse cases or lecturing end users. We also evaluated Gemini 2.5 Pro’s Critical Capabilities, including\nCBRN, cybersecurity, machine learning R&D, and deceptive alignment. While Gemini 2.5 Pro showed\na significant increase in some capabilities compared to previous Gemini models, it did not reach any\nof the Critical Capability Levels in any area.\nOur report is structured as follows: we begin by briefly describing advances we have made in\nmodelarchitecture,trainingandservingsincethereleaseoftheGemini1.5model. Wethenshowcase\nthe performance of the Gemini 2.5 models, including qualitative demonstrations of its abilities. We\nconclude by discussing the safety evaluations and implications of this model series.\n2. Model Architecture, Training and Dataset\n2.1. Model Architecture\nThe Gemini 2.5 models are sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021;\nFedus et al., 2021; Jiang et al., 2024; Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021;\nShazeer et al., 2017) transformers (Vaswani et al., 2017) with native multimodal support for text,\nvision, and audio inputs. Sparse MoE models activate a subset of model parameters per input token\nby learning to dynamically route tokens to a subset of parameters (experts); this allows them to\ndecouple total model capacity from computation and serving cost per token. Developments to the\nmodel architecture contribute to the significantly improved performance of Gemini 2.5 compared to\nGemini 1.5 Pro (see Section 3). Despite their overwhelming success, large transformers and sparse\nMoE models are known to suffer from training instabilities (Chowdhery et al., 2022; Dehghani et al.,\n2023; Fedus et al., 2021; Lepikhin et al., 2020; Liu et al., 2020; Molybog et al., 2023; Wortsman\net al., 2023; Zhai et al., 2023; Zhang et al., 2022). The Gemini 2.5 model series makes considerable\nprogress in enhancing large-scale training stability, signal propagation and optimization dynamics,\nresulting in a considerable boost in performance straight out of pre-training compared to previous\nGemini models.\n2\n\n--- PAGE 3 ---"
    },
    {
      "chunk_id": 3,
      "content": "--- PAGE 3 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 1 | Cost-performance plot. Gemini 2.5 Pro is a marked improvement over Gemini 1.5 Pro, and\nhas an LMArena score that is over 120 points higher than Gemini 1.5 Pro. Cost is a weighted average\nof input and output tokens pricing per million tokens. Source: LMArena, imported on 2025-06-16.\nGemini 2.5 models build on the success of Gemini 1.5 in processing long-context queries, and\nincorporate new modeling advances allowing Gemini 2.5 Pro to surpass the performance of Gemini\n1.5Proinprocessinglongcontextinputsequencesofupto1Mtokens(seeTable3). BothGemini2.5\nProandGemini2.5Flashcanprocesspiecesoflong-formtext(suchastheentiretyof“MobyDick”or\n“Don Quixote”), whole codebases, and long form audio and video data (see Appendix 8.5). Together\nwith advancements in long-context abilities, architectural changes to Gemini 2.5 vision processing\nlead to a considerable improvement in image and video understanding capabilities, including being\nable to process 3-hour-long videos and the ability to convert demonstrative videos into interactive\ncoding applications (see our recent blog post by Baddepudi et al., 2025).\nThesmallermodelsintheGemini2.5series—Flashsizeandbelow—usedistillation(Aniletal.,\n2018; Hinton et al., 2015), as was done in the Gemini 1.5 series (Gemini Team, 2024). To reduce\nthe cost associated with storing the teacher’s next token prediction distribution, we approximate it\nusing a k-sparse distribution over the vocabulary. While this still increases training data throughput\nand storage demands by a factor of k, we find this to be a worthwhile trade-off given the significant\nquality improvement distillation has on our smaller models, leading to high-quality models with a\nreduced serving cost (see Figure 2).\n2.2. Dataset\nOur pre-training dataset is a large-scale, diverse collection of data encompassing a wide range of\ndomainsandmodalities,whichincludespubliclyavailablewebdocuments,code(variousprogramming\nlanguages), images, audio (including speech and other audio types) and video, with a cutoff date\nof June 2024 for 2.0 and January 2025 for 2.5. Compared to the Gemini 1.5 pre-training dataset\n3\n\n--- PAGE 4 ---"
    },
    {
      "chunk_id": 4,
      "content": "--- PAGE 4 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini 2.5 Flash\nGemini 2.0 Flash\nGemini 2.0 Flash-Lite\no4-mini (high)\no3\nGemini 2.5 Pro Company\nGrok 3 Google\nOpenAI\nClaude 4 Opus (Extended Thinking)\nAnthropic\nClaude 4 Sonnet (Extended Thinking) DeepSeek\nxAI\nDeepSeek R1 0528 (May '25)\n0 50 100 150 200 250 300 350\nOutput Tokens per Second\nFigure 2 | Number of output tokens generated per second (after the first chunk has been received\nfrom the API) for different models. Source: ArtificialAnalysis.ai, imported on 2025-06-15.\nwe also utilized new methods for improved data quality for both filtering, and deduplication. Our\npost-training dataset, like Gemini 1.5, consists of instruction tuning data that is carefully collected\nandvetted. Itisacollectionofmultimodaldatawithpairedinstructionsandresponses,inadditionto\nhuman preference and tool-use data.\n2.3. Training Infrastructure\nThis model family is the first to be trained on TPUv5p architecture. We employed synchronous\ndata-parallel training to parallelise over multiple 8960-chip pods of Google’s TPUv5p accelerators,\ndistributed across multiple datacenters.\nThemainadvancesinsoftwarepre-traininginfrastructurecomparedwithGemini1.5wererelated\nto elasticity and mitigation of SDC (Silent Data Corruption) errors:\n1. Slice-Granularity Elasticity: Our system now automatically continues training with fewer\n“slices” of TPU chips when there is a localized failure, and this reconfiguration results in tens\nof seconds of lost training time per interruption, compared with the 10 or more minute delay\nwaitingforhealthymachinestoberescheduledwithoutelasticity;thesystemcontinuestraining\nat around 97% throughput while the failed slice is recovering. At the scale of this training run\nwe see interruptions from hardware failures multiple times per hour, but our fault tolerance\nmachinery is designed to tolerate the higher failure rates expected at much larger scales.\n2. Split-Phase SDC Detection: On previous large-scale runs it could take many hours to detect\nand localize machines with SDC errors, requiring both downtime while debugging, and roll-\nback/replay of a large number of potentially corrupt training steps. We now use lightweight\ndeterministic replay to immediately repeat any step with suspicious metrics, and compare\nper-deviceintermediatechecksumstolocalizetherootcauseofanydatacorruption. Empirically,\naccelerators that start to exhibit intermittent SDCs are identified within a few minutes, and\nquickly excluded from the job. During this run, around 0.25% of steps were replayed due to\nsuspected SDCs and 6% of these replays turned out to be genuine hardware corruption.\nBoth of the above techniques were relatively simple to implement due to the single-controller\ndesign of the Pathways system (Barham et al., 2022), which allows all accelerators to be coordinated\nfrom a single python program with a global view of the system state. The controller can make use of\n4\n\n--- PAGE 5 ---"
    },
    {
      "chunk_id": 5,
      "content": "--- PAGE 5 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n100\n80\n60\n40\n20\n0\n)%(\netar\nssaP\n/\nycaruccA\nAIME GPQA (Diamond) LiveCodeBench v5\n2.0 Flash (No Thinking)\n2.0 Flash (Thinking)\n2.5 Flash (Dynamic Thinking)\n2.5 Pro (Dynamic Thinking)\nFigure 3 | Impact of “Thinking” on Gemini’s performance on AIME 2025 (Balunović et al., 2025),\nLiveCodeBench (corresponding to 10/05/2024 - 01/04/2025 in the UI) (Jain et al., 2024) and GPQA\ndiamond (Rein et al., 2024) benchmarks.\nparallel ‘remote python’ operations on TPU workers to monitor training metrics, track performance\nstragglers, and root-cause SDC errors.\nOverall during the run, 93.4% of the time was spent performing TPU computations; the re-\nmainder was approximately spent half in elastic reconfigurations, and half in rare tail cases where\nelasticity failed. Around 4.5% of the computed steps were replays or rollbacks for model debugging\ninterventions.\n2.4. Post-training\nSince the initial announcement of Gemini 1.5, significant advancements have been made in our\npost-training methodologies, driven by a consistent focus on data quality across the Supervised\nFine-Tuning (SFT), Reward Modeling (RM), and Reinforcement Learning (RL) stages. A key focus\nhas been leveraging the model itself to assist in these processes, enabling more efficient and nuanced\nquality control.\nFurthermore,wehaveincreasedthetrainingcomputeallocatedtoRL,allowingdeeperexploration\nand refinement of model behaviors. This has been coupled with a focus on verifiable rewards\nand model-based generative rewards to provide more sophisticated and scalable feedback signals.\nAlgorithmic changes to the RL process have also improved stability during longer training. These\nadvancements have enabled Gemini 2.5 to learn from more diverse and complex RL environments,\nincluding those requiring multi-step actions and tool use. The combination of these improvements in\ndataquality,increasedcompute,algorithmicenhancements,andexpandedcapabilitieshascontributed\ntoacross-the-boardperformancegains(asdescribedinSection3),notablyreflectedinthesignificant\nincrease in the model’s LMArena Elo scores, with both Gemini 2.5 Flash and Pro gaining more than\n110 points over their Gemini 1.5 counterparts (122 for Gemini 2.5 Pro and 111 for Gemini 2.5 Flash,\nsee Figure 1), along with significant improvements on several other frontier benchmarks.\n2.5. Thinking\nPast Gemini models produce an answer immediately following a user query. This constrains the\namount of inference-time compute (Thinking) that our models can spend reasoning over a problem.\nGemini Thinking models are trained with Reinforcement Learning to use additional compute at\ninference time to arrive at more accurate answers. The resulting models are able to spend tens of\n5\n\n--- PAGE 6 ---"
    },
    {
      "chunk_id": 6,
      "content": "--- PAGE 6 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n90\n85\n80\n75\n70\n65\n1024 2048 4096 8192 16384 32768\nThinking Budget (number of tokens)\n)%(\netar\nssaP\n/ ycaruccA\nAIME 2025 LiveCodeBench GPQA diamond\n80 88\n75\n86\n70\n65 84\n60 82\n55\n80\n50\n45 78\n1024 2048 4096 8192 16384 32768 1024 2048 4096 8192 16384 32768\nThinking budget (number of tokens) Thinking budget (number of tokens)\nFigure 4 | Impact of thinking budget on performance on AIME 2025 (Balunović et al., 2025), Live-\nCodeBench (corresponding to 10/05/2024 - 01/04/2025 in the UI) (Jain et al., 2024) and GPQA\ndiamond (Rein et al., 2024) benchmarks.\nthousands of forward passes during a “thinking” stage, before responding to a question or query.\nOur training recipe has evolved from the original experimental thinking model, Gemini 2.0 Flash\nThinking (launched in December 2024), to the Gemini 2.5 Thinking series, which incorporates\nThinkingnativelyacrossalldomains. Theresultisasinglemodelthatcanachievestrongerreasoning\nperformanceacrosstheboard,andisabletoscaleupitsperformancefurtherasafunctionofinference\ntime (see Figure 3 for an example of the impact of Thinking).\nWeintegratedThinkingwithotherGeminicapabilities,includingnativemultimodalinputs(images,\ntext, video, audio) and long context (1M+ tokens). For any of these capabilities, the model decides\nfor itself how long to think before providing an answer. We also provide the ability to set a Thinking\nbudget, constraining the model to respond within a desired number of tokens. This allows users to\ntrade off performance with cost. To demonstrate this capability, we conducted experiments where we\nsystematically varied the thinking budget, measured in the number of tokens the model is allowed to\nuse for internal computation. As shown in Figure 4, increasing this budget allows the model to scale\nits performance and achieve significantly higher accuracy.\n2.6. Capability-specific improvements\nWhilemostofthechangesmadetoourtrainingarchitectureandrecipesinceGemini1.5haveresulted\nin improvements across all capabilities, we have also made changes that have resulted in some\ncapability-specific wins. We will now discuss these for code, factuality, long context, multilinguality,\naudio, video, and agentic use cases (with a particular focus on Gemini Deep Research).\nCode\nGemini 2.0 and 2.5 represent a strategic shift of our development priorities towards delivering\ntangiblereal-worldvalue,empoweringuserstoaddresspracticalchallengesandachievedevelopment\nobjectives within today’s complex, multimodal software environments. To realize this, concerted\nefforts have been undertaken across both pre-training and post-training phases since Gemini 1.5.\nIn pre-training, we intensified our focus on incorporating a greater volume and diversity of code\ndata from both repository and web sources into the training mixture. This has rapidly expanded\ncoverage and enabled the development of more compute-efficient models. Furthermore, we have\nsubstantially enhanced our suite of evaluation metrics for assessing code capabilities aligned with\ndownstream use cases, alongside improving our ability to accurately predict model performance.\n6\n\n--- PAGE 7 ---"
    },
    {
      "chunk_id": 7,
      "content": "--- PAGE 7 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nDuringpost-training,wedevelopednoveltrainingtechniquesincorporatingreasoningcapabilitiesand\ncuratedadiversesetofengineeringtasks,withtheaimtoequipGeminiwitheffectiveproblem-solving\nskills crucial for addressing modern engineering challenges. Key applications demonstrating these\nadvancements include IDE functionalities, code agent use cases for complex, multi-step operations\nwithin full repositories, and multimodal, interactive scenarios such as end-to-end web and mobile\napplication development. Collectively, these efforts have yielded broad and significant improvements\nin Gemini’s coding capabilities. This progress is evidenced by superior performance on established\nbenchmarks: performance on LiveCodeBench (Jain et al., 2024) increased from 30.5% for Gemini\n1.5 Pro to 74.2% for Gemini 2.5 Pro, while that for Aider Polyglot (Gauthier, 2025) went from\n16.9% to 82.2%. Performance on SWEBench-verified (Chowdhury et al., 2024; Jimenez et al., 2024)\nwent from 34.2% to 67.2%, see Table 3 and Figure 5 in Section 3.2. Furthermore, Gemini 2.5 Pro\nobtained an increase of over 500 Elo over Gemini 1.5 Pro on the LMArena WebDev Arena (Chiang\net al., 2024; LMArena Team, 2025), resulting in meaningful enhancements in practical applications,\nincluding UI and web application development (Doshi, 2025a), and the creation of sophisticated\nagentic workflows (Kilpatrick, 2025).\nFactuality\nWithin the context of generative models, ensuring the factuality of model responses to information-\nseeking prompts remains a core pillar of Gemini model development. With Gemini 1.5, our research\nwas concentrated on enhancing the model’s world knowledge and its ability to provide answers\nfaithfullygroundedinthecontextprovidedwithintheprompt. ThiseffortculminatedintheDecember\n2024 release of FACTS Grounding (Jacovi et al., 2025), now an industry-standard benchmark for\nevaluating an LLM’s capacity to generate responses grounded in user-provided documents. With\nGemini 2.0 and 2.5, we have significantly expanded our scope to address multimodal inputs, long-\ncontext reasoning, and model-retrieved information. At the same time, the landscape and user\nexpectations for factuality have evolved dramatically, shaped in part by Google’s deployment of AI\nOverviews and AI Mode (Stein, 2025). To meet these demands, Gemini 2.0 marked a significant leap\nas our first model family trained to natively call tools like Google Search, enabling it to formulate\nprecisequeriesandsynthesizefreshinformationwithsources. Buildingonthis,Gemini2.5integrates\nadvancedreasoning,allowingittointerleavethesesearchcapabilitieswithinternalthoughtprocesses\nto answer complex, multi-hop queries and execute long-horizon tasks. The model has learned to use\nsearch and other tools, reason about the outputs, and issue additional, detailed follow-up queries\nto expand the information available to it and to verify the factual accuracy of the response. Our\nlatest models now power the experiences of over 1.5B monthly active users in Google’s AI Overviews\nand 400M users in the Gemini App. These models exhibit state-of-the-art performance across a\nsuite of factuality benchmarks, including SimpleQA for parametric knowledge (Wei et al., 2024),\nFACTSGroundingforfaithfulnesstoprovideddocuments(Jacovietal.,2024,2025),andtheVectara\nHallucination Leaderboard (Hughes et al., 2023), cementing Gemini as the model of choice for\ninformation-seeking demands.\nLong context\nModeling and data advances helped us improve the quality of our models’ responses to queries\nutilizingouronemillion-lengthcontextwindow,andwereworkedourinternalevaluationstobemore\nchallengingtohelpsteerourmodelingresearch. Whenhill-climbing,wetargetedchallengingretrieval\ntasks (like LOFT of Lee et al., 2024), long-context reasoning tasks (like MRCR-V2 of Vodrahalli et al.,\n2024), and multimodal tasks (like VideoMME of Fu et al., 2025). According to the results in Table 6,\nthe new 2.5 models improve greatly over previous Gemini 1.5 models and achieve state-of-the-art\nquality on all of those. An example showcasing these improved capabilities for video recall can be\n7\n\n--- PAGE 8 ---"
    },
    {
      "chunk_id": 8,
      "content": "--- PAGE 8 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nseen in Appendix 8.5, where Gemini 2.5 Pro is able to consistently recall a 1 second visual event out\nof a full 46-minute video.2\nMultilinguality\nGemini’s multilingual capabilities have also undergone a profound evolution since 1.5, which already\nencompassed over 400 languages via pretraining. This transformation stems from a holistic strategy,\nmeticulously refining pre- and post-training data quality, advancing tokenization techniques, innovat-\ning core modeling, and executing targeted capability hillclimbing. The impact is particularly striking\nin Indic and Chinese, Japanese and Korean languages, where dedicated optimizations in data quality\nandevaluationhaveunlockeddramaticgainsinbothqualityanddecodingspeed. Consequently,users\nbenefit from significantly enhanced language adherence, responses designed to faithfully respect the\nrequested output language, and a robust improvement in generative quality and factuality across\nlanguages, solidifying Gemini’s reliability across diverse linguistic contexts.\nAudio\nWhile Gemini 1.5 was focused on native audio understanding tasks such as transcription, translation,\nsummarization and question-answering, in addition to understanding, Gemini 2.5 was trained to\nperform audio generation tasks such as text-to-speech or native audio-visual to audio out dialog. To\nenable low-latency streaming dialog, we incorporated causal audio representations that also allow\nstreaming audio into and out of Gemini 2.5. These capabilities derive from an increased amount of\npre-training data spanning over 200 languages, and development of improved post-training recipes.\nFinally, through our improved post-training recipes, we have integrated advanced capabilities such as\nthinking, affective dialog, contextual awareness and tool use into Gemini’s native audio models.\nVideo\nWe have significantly expanded both our pretraining and post-training video understanding data,\nimproving the audio-visual and temporal understanding capabilities of the model. We have also\ntrainedourmodelssothattheyperformcompetitivelywith66insteadof258visualtokensperframe,\nenabling using about 3 hours of video instead of 1h within a 1M tokens context window3. Two\nnew applications that were not previously possible, but that have been unlocked as a result of these\nchanges are: creating an interactive app from a video (such as a quiz to test students’ understanding\nof the video content) and creating a p5.js animation to show the key concepts from the video. Our\nrecent blog post (Baddepudi et al., 2025) shows examples of these applications.\nGemini as an Agent: Deep Research\nGemini Deep Research (Gemini Team, Google, 2024) is an agent built on top of the Gemini 2.5 Pro\nmodeldesignedtostrategicallybrowsethewebandprovideinformedanswerstoeventhemostniche\nuser queries. The agent is optimized to perform task prioritization, and is also able to identify when\nit reaches a dead-end when browsing. We have massively improved the capabilities of Gemini Deep\nResearch since its initial launch in December 2024. As evidence of that, performance of Gemini\nDeep Research on the Humanity’s Last Exam benchmark (Phan et al., 2025) has gone from 7.95% in\nDecember 2024 to the SoTA score of 26.9% and 32.4% with higher compute (June 2025).\n2Forfurtherdiscussiononlongcontextcapabilities,challenges,andfutureoutlook,theReleaseNotespodcastepisode\n“DeepDiveintoLongContext”providesadditionalinsightsanddiscussion:https://youtu.be/NHMJ9mqKeMQ.\n3ThisisreferredtoaslowmediaresolutionintheAPI:https://ai.google.dev/api/generate-content#Media\nResolution.\n8\n\n--- PAGE 9 ---"
    },
    {
      "chunk_id": 9,
      "content": "--- PAGE 9 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n2.7. The path to Gemini 2.5\nOn the way to Gemini 2.5 Pro, we experimented with our training recipe, and tested a small number\nof these experimental models with users. We have already discussed Gemini 2.0 Flash Thinking (see\nSection 2.5). We will now discuss some of the other models briefly.\nGemini 2.0 Pro\nIn February 2025, we released an experimental version of Gemini 2.0 Pro. At the time, it had\nthe strongest coding performance of any model in the Gemini model family, as well as the best\nunderstanding and world knowledge. It also came with our largest context window at 2 million\ntokens, which enabled it to comprehensively analyze and understand vast amounts of information.\nFor further information about Gemini 2.0 Pro, please see our earlier blog posts (Kavukcuoglu, 2025;\nMallick and Kilpatrick, 2025).\nGemini 2.0 Flash Native Image Generation Model\nIn March 2025, we released an experimental version of Gemini 2.0 Flash Native Image Generation.\nIt has brought to the users new capabilities as a result of a strong integration between the Gemini\nmodel and image-generation capabilities, enabling new experiences related to image generation &\nimage editing via natural-language prompting. Capabilities such as multi-step conversational editing\norinterleavedtext-imagegenerationareverynaturalinsuchasetting,andhorizontaltransferrelated\nto multi-language coverage immediately allowed such experiences to happen across all the languages\nsupported by the Gemini models. Native image generation turns Gemini into a multimodal creation\npartner and enables Gemini to express ideas through both text and images, and to seamlessly move\nbetween the two. For further information about Gemini 2.0 Flash Native Image Generation, please\nsee our earlier blog posts (Kampf and Brichtova, 2025; Sharon, 2025)\nGemini 2.5 Audio Generation\nWith Gemini 2.5, the Controllable TTS and Native Audio Dialog capabilities are available as separate\noptions on AI Studio (Generate Media and Stream sections respectively). Our Gemini 2.5 Preview\nTTS Pro and Flash models support more than 80 languages with the speech style controlled by a free\nformatted prompt which can specify style, emotion, pace, etc, while also being capable of following\nfiner-grained steering instructions specified in the transcript. Notably, Gemini 2.5 Preview TTS can\ngeneratespeechwithmultiplespeakers,whichenablesthecreationofpodcastsasusedinNotebookLM\nAudioOverviews(Wang,2024). OurGemini2.5FlashPreviewNativeAudioDialogmodelusesnative\naudio generation, which enables the same level of style, pacing and accent control as available in our\ncontrollable TTS offering. Our dialog model supports tool use and function calling, and is available\nin more than 24 languages. With native audio understanding and generation capabilities, it can\nunderstandandrespondappropriatelytotheuser’stone. Thismodelisalsocapableofunderstanding\nwhen to respond to the user, and when not to respond, ignoring background and non-device directed\naudio. Finally, we also offer an advanced ‘Thinking’ variant that effectively handles more complex\nqueries and provides more robust and reasoned responses in exchange for some additional latency.\nGemini 2.5 Flash-Lite\nIn June 2025, we released an experimental version of Gemini 2.5 Flash-Lite (gemini-2.5-flash-\nlite-preview-06-17). ItcomeswiththesamecapabilitiesthatmakeGemini2.5helpful,including\nthe ability to turn thinking on at different budgets, connecting to tools like Google Search and code\n9\n\n--- PAGE 10 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nexecution,supportformultimodalinputsanda1million-tokencontextlength. Ourgoalwastoprovide\nan economical model class which provides ultra-low-latency capabilities and high throughput per\ndollar, echoing the initial release of 2.0 Flash-Lite (Google DeepMind, 2025b; Mallick and Kilpatrick,\n2025).\nGemini 2.5 Pro Deep Think\nTo advance Gemini’s capabilities towards solving hard reasoning problems, we developed a novel\nreasoning approach, called Deep Think, that naturally blends in parallel thinking techniques during\nresponse generation. Deep Think enables Gemini to creatively produce multiple hypotheses and\ncarefully critique them before arriving at the final answer, achieving state-of-the-art performances in\nchallengingbenchmarkssuchasOlympiadmath(USAMO2025),competitivecoding(LiveCodeBench),\nand multimodality (MMMU), see more details at (Doshi, 2025b). We announced Gemini 2.5 Deep\nThink at Google I/O and launched an experimental version to trusted testers and advanced users in\nJune 2025.\n10\n\n--- PAGE 11 ---"
    },
    {
      "chunk_id": 10,
      "content": "--- PAGE 11 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n3. Quantitative evaluation\n100\n80\n60\n40\n20\n0\nFlash Pro\n)%(\netar\nssaP\nLiveCodeBench Aider Polyglot SWE-bench Verified\n100 100\nGemini version\n1.5\n2.0 80 80\n2.5\n60 60\n40 40\n20 20\n0 0\nFlash Pro Flash Pro\n100\n80\n60\n40\n20\n0\nFlash Pro\n)%(\nycaruccA\nGPQA (diamond) AIME 2025 HiddenMath-Hard\n100 100\n80 80\n60 60\n40 40\n20 20\n0 0\nFlash Pro Flash Pro\nFigure 5 | Performance of Gemini 2.X models at coding, math and reasoning tasks in comparison to\nprevious Gemini models. SWE-bench verified numbers correspond to the “multiple attempts” setting\nreported in Table 3.\nWe will now examine the performance of the Gemini 2.X model family across a wide range of\nbenchmarks. We will first compare the performance of the Gemini 2.X models to the earlier Gemini\n1.5 Pro and Flash models, before we compare the performance of Gemini 2.5 Pro to other available\nlarge language models.\nWith web-scale pre-training of AI models, coupled with the post-training techniques that allow\npolicy and reward models to leverage public benchmarks, avoiding leaks and biases in the data used\nfor pre- and post-training is a persistent challenge. In the development of the Gemini 2.5 series, in\naddition to the standard n-gram based decontamination we used in Gemini 1.5, we also employed\nsemantic-similarity and model based decontamination procedures to help mitigate evaluation set\nleakage. Tomovebeyondtherelianceontrainingsetdecontamination,wealsocontinuereportingon\ninternally developed non-public benchmarks, such as HiddenMath.\nModel AIStudiomodelID\nGemini1.5Flash gemini-1.5-flash-002\nGemini1.5Pro gemini-1.5-pro-002\nGemini2.0Flash-Lite gemini-2.0-flash-lite-001\nGemini2.0Flash gemini-2.0-flash-001\nGemini2.5Flash gemini-2.5-flash\nGemini2.5Pro gemini-2.5-pro\nTable 2 | Mapping of Gemini model names to AI Studio API model IDs.\n11\n\n--- PAGE 12 ---"
    },
    {
      "chunk_id": 11,
      "content": "--- PAGE 12 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n3.1. Methodology\nIn Table 3, we compare the performance of Gemini 2.5 models to the Gemini 1.5 models, while in\nTable 4, we compare the performance of Gemini 2.5 Pro to that of other large language models.\nGemini results: AllGeminiscoresarepass@1,andare“singleattempt”settingsunlessotherwise\nspecified. Inthe“singleattempt”setting,nomajorityvotingorparalleltest-timecomputeispermitted,\nwhile in the “multiple attempts” setting, test-time selection of the candidate answer is allowed. All\nGemini evaluations are run with the AI Studio API for the model id that we provide in Table 2, with\ndefaultsamplingsettings. Toreducevariance,weaverageovermultipletrialsforsmallerbenchmarks.\nAiderPolyglotscoresarethepassrateaverageof3trials. Vibe-EvalresultsarereportedusingGemini\nas a judge.\nNon-Gemini results: All the results for non-Gemini models are sourced from providers’ self\nreported numbers unless mentioned otherwise. All “SWE-bench Verified” numbers follow official\nproviderreports,whichmeansthattheyarecomputedusingdifferentscaffoldingsandinfrastructure,\nand aren’t directly comparable.\nFor some evaluations, we obtain results from the external leaderboards that report results on\nthese benchmarks. Results for Humanity’s Last Exam results are sourced from Scale’s leaderboard\nandresultsforDeepSeekareobtainedfromthetext-onlyvariantoftheleaderboard(indicatedwitha\n⋄in Table 4). For Gemini 2.0 models, the reported results are on an earlier HLE dataset (indicated\nwith a † in Table 3). Results on LiveCodeBench results are taken from (1/1/2025 - 5/1/2025) in the\nUI. Aider Polyglot numbers come from the Aider leaderboard and results for SimpleQA come from\nthis repo where available. Results on FACTS Grounding come from Kaggle. In the case of LOFT and\nMRCR-V2,wereportresultsonboththe128kcontextlengthvariant,aswellasthe1Mcontextlength\nvariant. In the 128k context length variant, we measure performance on contexts up to 128k, while\nfor the 1M context length variant, we report performance on context lengths of exactly 1M.\nMore details on all benchmarks, including subsets and how scores were obtained can be found in\nTable 11 in Appendix 8.1.\n3.2. Core capability quantitative results\nAs can be seen in Table 3, and Figure 5, the Gemini 2.5 models excel at coding tasks such as\nLiveCodeBench, Aider Polyglot and SWE-bench Verified, and represent a marked improvement over\nprevious models.\nInadditiontocodingperformance,Gemini2.5modelsarenoticeablybetteratmathandreasoning\ntasks than Gemini 1.5 models: performance on AIME 2025 is 88.0% for Gemini 2.5 Pro compared to\n17.5% for Gemini 1.5 Pro, while performance on GPQA (diamond) went from 58.1% for Gemini 1.5\nPro to 86.4%. Performance on image understanding tasks has also increased significantly.\nIt is also interesting to note that the Gemini 2.5 Flash model has become the second most capable\nmodel in the Gemini family, and has overtaken not just previous Flash models, but also the Gemini\n1.5 Pro model released one year ago.\n12\n\n--- PAGE 13 ---"
    },
    {
      "chunk_id": 12,
      "content": "--- PAGE 13 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5\nCapability Benchmark\nFlash Pro Flash-Lite Flash Flash Pro\nLiveCodeBench 30.3% 29.7% 29.1% 29.1% 59.3% 74.2%\nAiderPolyglot 2.8% 16.9% 10.5% 21.3% 56.7% 82.2%\nsingle\n9.6% 22.3% 12.5% 21.4% 48.9% 59.6%\nCode SWE-bench attempt\nmultiple\nVerified 19.7% 34.2% 23.1% 34.2% 60.3% 67.2%\nattempts\nGPQA\n50.0% 58.1% 50.5% 65.2% 82.8% 86.4%\n(diamond)\nReasoning\nHumanity’s\nnotools - 4.6% 4.6%† 5.1%† 11.0% 21.6%\nLastExam\nSimpleQA 8.6% 24.9% 16.5% 29.9% 26.9% 54.0%\nFactuality FACTS\n82.9% 80.0% 82.4% 84.6% 85.3% 87.8%\nGrounding\nGlobalMMLU\n72.5% 80.8% 78.0% 83.4% 88.4% 89.2%\nMultilinguality (Lite)\nECLeKTic 16.4% 27.0% 27.7% 33.6% 36.8% 46.8%\nAIME2025 14.7% 17.5% 23.8% 29.7% 72.0% 88.0%\nMath\nHiddenMath- 36.8% 44.3% 47.4% 53.7% 75.5% 80.5%\nHard\nLOFT(hard ≤128K 67.3% 75.9% 50.7% 58.0% 82.1% 87.0%\nretrieval) 1M 36.7% 47.1% 7.6% 7.6% 58.9% 69.8%\nLong-context\nMRCR-V2 ≤128K 18.4% 26.2% 11.6% 19.0% 54.3% 58.0%\n(8-needle) 1M 10.2% 12.1% 4.0% 5.3% 21.0% 16.4%\nMMMU 58.3% 67.7% 65.1% 69.3% 79.7% 82.0%\nVibe-Eval\n52.3% 55.9% 51.5% 55.4% 65.4% 67.2%\nImage (Reka)\nUnderstanding\nZeroBench 0.5% 1.0% 0.75% 1.25% 2.0% 4.5%\nBetterChartQA 59.0% 65.8% 52.3% 57.8% 67.3% 72.4%\nTable 3 | Evaluation of Gemini 2.5 family across a wide range of core capability benchmarks and in\ncomparison to Gemini 1.5 models. Please see Tables 5 and 6 for audio and video evaluations. See\nTable 11 Appendix 8.1 for benchmarks and evaluation details.\n13\n\n--- PAGE 14 ---"
    },
    {
      "chunk_id": 13,
      "content": "--- PAGE 14 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n3.3. Evaluation of Gemini 2.5 Pro against other large language models\nRelative to other large language models that are available (see Table 4), Gemini achieves the highest\nscoreontheAiderPolyglotcodingtask,Humanity’sLastExam,GPQA(diamond),andontheSimpleQA\nand FACTS Grounding factuality benchmarks out of all of the models examined here. Gemini also\ncontinues to stand out for achieving the SoTA score on both the LOFT and MRCR long-context tasks\nat 128k context, and is the only one, amongst the models examined in the above table, to support\ncontext lengths of 1M+ tokens.\nNot all of the models shown in Table 4 have native support for multimodal inputs. As such, we\ncompare against a different set of models for audio and video understanding.\nAudio Understanding\nIn Table 5, we showcase the performance of the Gemini 2.5 model family at audio understanding,\nand compare the performance of these models to earlier Gemini models, as well as to GPT models.\nGemini2.5Prodemonstratesstate-of-the-artaudiounderstandingperformanceasmeasuredbypublic\nbenchmarks for ASR and AST, and compares favorably to alternatives under comparable testing\nconditions (using the same prompts and inputs).\nVideo Understanding\nIn Table 6, we show the performance of Gemini 2.5 models at video understanding. As can be\nseen, Gemini 2.5 Pro achieves state-of-the-art performance on key video understanding benchmarks,\nsurpassing recent models like GPT 4.1 under comparable testing conditions (same prompt and video\nGemini2.5 o3 o4-mini Claude4 Claude4 Grok3Beta DeepSeekR1\nCapability Benchmark\nPro high high Sonnet Opus ExtendedThinking 0528\nLiveCodeBench 74.2% 72.0% 75.8% 48.9% 51.1% – 70.5%\nCode\nAiderPolyglot 82.2% 79.6% 72.0% 61.3% 72.0% 53.3% 71.6%\nsingle 59.6% 69.1% 68.1% 72.7% 72.5% - -\nSWE-bench attempt\nVerified multiple 67.2% - - 80.2% 79.4% - 57.6%\nattempts\nGPQA\nsingle 86.4% 83.3% 81.4% 75.4% 79.6% 80.2% 81.0%\nReasoning (diamond) attempt\nHumanity’s\nno 21.6% 20.3% 18.1% 7.8% 10.7% - 14.0%⋄\nLastExam tools\nSimpleQA 54.0% 48.6% 19.3% - - 43.6% 27.8%\nFactuality\nFACTS\n87.8% 69.9% 62.1% 79.1% 77.7% 74.8% 82.4%\nGrounding\nMath AIME2025 single 88.0% 88.9% 92.7% 70.5% 75.5% 77.3% 87.5%\nattempt\nLOFT(hard ≤128K 87.0% 77.0% 60.5% 81.6% - 73.1% -\nretrieval) 1M 69.8% - - - - - -\nLong-context\nMRCR-V2 ≤128K 58.0% 57.1% 36.3% 39.1% 16.1%* 34.0% -\n(8-needle) 1M 16.4% - - - - - -\nImage\nMMMU single 82.0% 82.9% 81.6% 74.4% 76.5% 76.0% NoMMsupport\nUnderstanding attempt\nTable 4 | Performance comparison of Gemini 2.5 Pro with other large language models on different\ncapabilities. Please see Tables 5 and 6 for audio and video evaluations. See Table 11 for benchmarks\nand evaluation details. *: with no thinking and API refusals\n14\n\n--- PAGE 15 ---"
    },
    {
      "chunk_id": 14,
      "content": "--- PAGE 15 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5 GPT-4omini GPT4o GPT4o\nBenchmark\nFlash Pro Flash-Lite Flash Flash Pro AudioPreview AudioPreview transcribe\nFLEURS\n12.71 7.14 9.60 9.04 9.95 6.66 19.52 12.16 8.17\n(53lang,WER↓)\nCoVoST2\n34.81 37.53 34.74 36.35 36.15 38.48 29.5 35.89 –\n(21lang,BLEU↑)\nTable 5 | Performance comparison of Gemini 2.5 models to earlier Gemini models, as well as to GPT\nmodels for audio understanding. Note that for GPT models, metrics may differ from those previously\nreported due to differing eval methodologies. See Table 11 for benchmarks and evaluation details.\nframes). For cost-sensitive applications, Gemini 2.5 Flash provides a highly competitive alternative.\nGemini1.5 Gemini1.5 Gemini2.0 Gemini2.0 Gemini2.5 Gemini2.5 OpenAI\nModalities Benchmark\nFlash Pro Flash-Lite Flash Flash Pro GPT4.1\nActivityNet-QA 56.2 57.3 55.3 56.4 65.1 66.7 60.4\nEgoTempo 34.5 36.3 30.1 39.3 36.7 44.3 40.3\nPerceptionTest 66.5 69.4 67.5 68.8 75.1 78.4 64.8\nvisual-only\nQVHighlights 64.4 68.7 25.7 63.9 52.4 75.0 71.4\nVideoMMMU 64.8 70.4 64.3 68.5 79.2 83.6 60.9\n1H-VideoQA 61.9 72.2 55.6 67.5 67.5 81.0 56.8\nLVBench 61.9 65.7 52 61.8 62.7 78.7 63.4\nVideoMME 70.4 73.2 62.1 72.8 75.5 84.3 72.0\naudio+visual VATEX 56.9 55.5 58.5 56.9 65.2 71.3 64.1\nVATEX-ZH 46.2 52.2 43.2 48.5 43.9 59.7 48.7\nYouCook2Cap 153.2 170.0 78.6 129.0 177.6 188.3 127.6\nMinerva 49.6 52.8 46.8 52.4 60.7 67.6 54.0\nvisual+subtitles\nNeptune 78.7 82.7 81.5 83.1 84.3 87.3 85.2\naudio+visual+\nVideoMME 77.3 79.8 72.5 78.8 81.5 86.9 79.6\nsubtitles\nTable 6 | Evaluation of Gemini 2.5 vs. prior models and GPT 4.1 on video understanding benchmarks.\nPerformance is measured by string-match accuracy for multiple-choice VideoQA, LLM-based accuracy\nfor open-ended VideoQA, R1@0.5 for moment retrieval and CIDEr for captioning. See Table 11 for\nbenchmarks and evaluation details.\n15\n\n--- PAGE 16 ---"
    },
    {
      "chunk_id": 15,
      "content": "--- PAGE 16 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n4. Example use cases of Gemini 2.5 Pro\n4.1. Gemini Plays Pokémon\nHall of Fame\nBeat Elite Four Lance\nBeat Elite Four Agatha\nBeat Elite Four Bruno\nBeat Elite Four Lorelei\nExit Victory Road (1st)\nEnter Victory Road (1st)\nRival 7 (Route 22 #2)\nEarth Badge\nVolcano Badge\nAcquire Secret Key (Pokemon Mansion)\nEnter Cinnabar Island (1st)\nMarsh Badge\nRocket Boss 2 (Silph Co.)\nRival 6 (Silph Co.)\nEnter Silph Co. (1st)\nEnter Saffron City (1st)\nAcquire HM04 Strength (Warden's Teeth)\nSoul Badge\nAcquire HM03 Surf (Beat Safari Zone)\nEnter Safari Zone (1st)\nEnter Fuchsia City (1st)\nAcquire PokéFlute (Rescue Fuji)\nRainbow Badge\nRocket Boss 1 (Rocket Hideout)\nEnter Rocket Hideout (1st)\nEnter Celadon City (1st)\nRival 5 (Lavender Tower)\nExit Rock Tunnel & Reach Lavender Town (1st)\nAccess Pokemon w/ Flash\nEnter Rock Tunnel (1st)\nThunder Badge\nAcquire HM05 Flash\nAccess Pokemon w/ CUT\nRival 4 (SS Anne)\nBill’s House\nCascade Badge\nRival 3 (Nugget Bridge)\nExit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge\nExit Viridian Forest (1st)\nEnter Viridian Forest (1st)\nViridian City\nRival 1 (Oak's Lab)\n0 100 200 300 400 500 600 700 800\nTime Elapsed (Hours)\nsenotseliM\nemaG\nGemini 2.5 Pro Plays Pokemon Progress Timeline\nRun 1\nRun 2 (Actual)\nFigure 6 | Progression of the Gemini Plays Pokémon agent through the game, across two runs. Run 1\nwasthedevelopmentrunwherechangestotheharnesswereperformed. Run2isthefullyautonomous\nrunwiththefinalfixedscaffold. Bothrunshavethesamestarter(Squirtle). Theeventsareorderedon\nthe y-axis by the order they happened, following the order of Run 2 when there is a conflict. Notably,\ntheGPPagentadditionallywentthroughthedifficult(andoptional)SeafoamIslandsdungeoninRun\n2, while in Run 1, GPP reached Cinnabar Island via Pallet Town and Route 21.\nOn March 28, 2025, an independent developer not affiliated with Google, Joel Zhang, set up a\nTwitch stream (Gemini Plays Pokémon, or GPP) for Gemini 2.5 Pro (Gemini 2.5 Pro Exp 03-25) to\nplay Pokémon Blue on stream (Zhang, 2025) as an experiment to better understand how well the\nmodel was capable of playing Pokémon (in a similar spirit to Claude Plays Pokémon, see Anthropic\n2025). In this initial run through the game, the goal was to live-stream the development process of\nan agentic harness capable of playing the full game (and in particular the minimal transformation of\nvisiontotextnecessarytodoso),seeFigure14foradescriptionofthefinalagentsetup. Assuch,over\nthe course of the run, modifications were made to the setup as difficulties arose, providing a deeply\ninteresting lens via which to analyze some of the qualitative improvements that the 2.5 Pro model\nhasmade,particularlyintheregimesofsolvinglongreasoningproblemsandagenticcapabilitiesover\nextended time horizons. Around 1 month later, on May 2, 2025, Gemini 2.5 Pro completed the game\nafter 813 hours and entered the Hall of Fame to become the Pokémon League Champion! On May\n22, 2025, GPP began a fully autonomous 2nd run through the game with Gemini 2.5 Pro (Gemini\n2.5 Pro Preview 05-06) with the finalized fixed agentic harness, and progressed through the game\nconsiderablyfaster,completingthegamein406.5hours(nearlyexactlyhalfthetimeofthefirstrun).\n16\n\n--- PAGE 17 ---"
    },
    {
      "chunk_id": 16,
      "content": "--- PAGE 17 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nSee Figure 6 for a timeline of GPP’s progress through major game milestones to game completion.\nWe report # hours to each milestone in order to normalize for the amount of time models take per\naction. See Appendix 8.2 for more figures.\nCapabilities assessment\nGemini 2.5 Pro showcased many impressive capabilities associated with reasoning and long-term\nplanning while playing Pokémon. We will now discuss two in particular, but for more examples, see\nAppendix 8.2.\nLong Context Agentic Tooling Within the agent scaffolding, GPP has access to two agentic\ntools (see Figure 14). These prompted versions of Gemini 2.5 Pro, hereafter pathfinder and\nboulder_puzzle_strategist, have been able to:\n1. Solve complex spinner puzzles in one shot (for instance in Rocket Hideout),\n2. Solve the step-constrained multi-map puzzle of the Safari Zone,\n3. Find long pathways through complex mazes like Route 13,\n4. Solve boulder puzzles across long distances in Victory Road and the Seafoam Islands.\nEachtaskrequiresreasoningoveralongcontext-thepathfindermodelwouldoftenhavetoreason\nover contexts of 100K+ tokens, and find paths up to 50 actions in length (in the extreme case, paths\nconsisting of up to 150 actions have also been found!).\nLong Horizon Task Coherence WhileGemini2.5Proisimpressiveinamorelocalsense,theagent\nalsoexhibitedremarkablelong-termtaskcoherenceinachievingglobal,high-levelgoalsinthefaceof\nreal andhallucinated setbacks towards makingforward progress. Because the agent is able to change\ngoals at will, and will generally follow those goals as long as needed, it is extremely impressive that\nthe agent can satisfy numerous requirements for tactical, necessary goals, such as acquiring Hidden\nMoves, as well as maintain enough strategic task coherence to beat the entire game and become the\nPokémon Champion.\nWhere does 2.5 Pro struggle while playing Pokémon?\nIn addition to more standard hallucination issues (which interestingly were plausibly reduced in Run\n2 by explicitly prompting the model to act as a player completely new to the game, see Appendix 8.2\nfor more details), there are a few particular points of struggle we would like to emphasize.\nScreen reading While obtaining excellent benchmark numbers on real-world vision tasks, 2.5 Pro\nstruggled to utilize the raw pixels of the Game Boy screen directly, though it could occasionally take\ncues from information on the pixels. As a result, it was necessary for the required information from\nthe screen to be translated into a text format in the agent framework, using information from the\ngame’s RAM state. During one portion of the game, the developer tested an ablation where all vision\nwas completely removed from the model context – the model was able to function roughly as well\nas without the vision information, suggesting that most of the performance does not significantly\ndepend on the visual input.\nLong Context Reasoning Gemini 2.5 Pro’s state-of-the-art long context performance for both\nreasoning and retrieval tasks (see Tables 3 and 4) was a cornerstone of the GPP agent’s success. Its\nability to reason over a 100k token context was instrumental for leveraging the complex toolset and\n17\n\n--- PAGE 18 ---"
    },
    {
      "chunk_id": 17,
      "content": "--- PAGE 18 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nmaintaining a relatively coherent strategy (e.g., optimal balance of performance, planning quality,\nand information recall.)\nWhile Gemini 2.5 Pro supports 1M+ token context, making effective use of it for agents presents\na new research frontier. In this agentic setup, it was observed that as the context grew significantly\nbeyond 100k tokens, the agent showed a tendency toward favoring repeating actions from its vast\nhistory rather than synthesizing novel plans. This phenomenon, albeit anecdotal, highlights an\nimportant distinction between long-context for retrieval and long-context for multi-step, generative\nreasoning.\nTeachinganagenttoeffectivelyplanandavoidsuchloopsovermassivepasttrajectoriesofcontext\nis an exciting and active area of research; the co-design of agent scaffolds and models to unlock the\nfull potential of million-token context is an intriguing research direction and one of our primary\nfocuses.\n4.2. What else can Gemini 2.5 do?\nGemini 2.5 Pro excels at transforming diverse, often unstructured, inputs into interactive and func-\ntional applications. For instance, it can take a PDF script of a play and generate a tool that allows\ndrama students to practice their lines. Gemini 2.5 Pro can also take an uploaded photograph of a\nbookshelf and create a curated book recommendation application. Gemini 2.5 Pro can utilize its\nunderlying spatial understanding capability and convert images into a structural representation like\nHTML or SVG. In Figure 16 in Appendix 8.4, we show a comparison of Gemini 1.5 Pro and Gemini\n2.5Proonanimage-to-svgtask,whereGemini2.5Proreconstructsmuchmorevisualdetailsandthe\nspatial arrangements of objects better resembles the original image.\nFurthermore, Gemini 2.5 Pro demonstrates strong skills in generating sophisticated simulations\nand visualizations, ranging from interactive solar system models (source) to the creative rendering of\nabstract mathematical concepts, such as drawing a logo using Fourier series (source). This capability\nextendstothedevelopmentoftoolsthatintersectcreativityandutility: weseeexamplesofspecialized\napplicationslikeacustomcartographytoolorusecasesthatgeneratephotorealistic3Duserinterfaces\nfrom descriptive text and reference images, complete with appropriate styling and interactivity\n(source).\nCollectively, these examples illustrate that Gemini 2.5 Pro is not just a useful coding and writing\nassistant, but excels at a wide range of complex tasks, ranging from those relevant for education\nto creative expression. The model empowers users to rapidly prototype specialized utilities, de-\nvelop engaging educational content, and realize intricate creative visions with a high degree of\nsophistication.\n4.3. Gemini in Google Products\nAs a final example of what Gemini can do, we note that Gemini (or a custom version of Gemini) is\nnow incorporated into a wide variety of Google products. These include, but are not limited to, AI\nOverviews and AI Mode within Google Search, Project Astra, the audiovisual-to-audio dialog agent,\nGemini Deep Research, the research assistant discussed in Section 2.7, NotebookLM, the tool capable\nof generating podcasts and audio overviews from even the most obscure inputs, Project Mariner, the\nweb browsing agent, and Google’s coding agent, Jules.\n18\n\n--- PAGE 19 ---"
    },
    {
      "chunk_id": 18,
      "content": "--- PAGE 19 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n5. Safety, Security, and Responsibility\nWe’re committed to developing Gemini responsibly, innovating on safety and security alongside capa-\nbilities. We describe our current approach in this section, which includes how we train and evaluate\nour models, focusing on automated red teaming, going through held-out assurance evaluations on\npresent-day risks, and evaluating the potential for dangerous capabilities in order to proactively\nanticipate new and long-term risks.\nGuideline for Navigating This Section\n1. Our Process (Section 5.1): Begin here to understand our overall safety methodology.\n2. Policies and Desiderata (Section 5.2): Next, dive into the safety criteria we use to evaluate\nand optimize our systems.\n3. Training for Safety (Section 5.3): Discover how we incorporate safety into pre-training and\npost-training.\n4. ResultsfromDevelopmentEvaluations(Section5.4): Resultsonourdevelopmentevaluations\nfor policies and desiderata.\n5. Automated Red Teaming (Section 5.5): A description and results from our automated red\nteaming work for safety and security.\n6. Memorization & Privacy (Section 5.6): Our analysis of memorization and privacy risks.\n7. Assurance Evaluations and Frontier Safety Framework (Section 5.7): We dive into our\nheld-out evaluations and tests for dangerous capabilities.\n8. External Safety Testing (Section 5.8): Learn what independent testers discovered about our\nsystem’s safety.\n5.1. Our Process\nWe aim for Gemini to adhere to specific safety, security, and responsibility criteria. These cover what\nGemini should not do (e.g., encourage violence), and what Gemini should do (e.g., respond in a\nhelpful way when possible instead of refusing, provide multiple perspectives when consensus does\nnotexist). Wealsoleverageautomatedredteamingtoidentifycaseswherethemodelfailstorespond\nin a safe or helpful manner. These failure cases are used to improve evaluations and training data.\nOnce the model is trained, we run assurance evaluations that we then use for review and release\ndecisions. Importantly, these are conducted by a group outside of the model development team, and\ndatasets are held out. Furthermore, for models where there are new capabilities or a significant\nperformance improvement, we engage independent external groups, including domain experts and a\ngovernment body, to further test the model to identify blind spots.\nWe also evaluate the model for dangerous capabilities outlined in our Frontier Safety Framework\n(Google DeepMind, 2025a), namely: Cybersecurity, CBRN, Machine Learning R&D, and Deceptive\nAlignment.\nFinally, The Google DeepMind Responsibility and Safety Council (RSC), our governance body,\nreviews initial ethics and safety assessments on novel model capabilities in order to provide feedback\nand guidance during model development. The RSC also reviews metrics on the models’ performance\nvia assurance evals and informs release decisions.\n19\n\n--- PAGE 20 ---"
    },
    {
      "chunk_id": 19,
      "content": "--- PAGE 20 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n5.2. Policies and Desiderata\nSafety policies\nTheGeminisafetypoliciesalignwithGoogle’sstandardframeworkwhichpreventsourourGenerative\nAI models from generating specific types of harmful content, including:\n1. Child sexual abuse and exploitation\n2. Hate speech (e.g., dehumanizing members of protected groups)\n3. Dangerous content (e.g., promoting suicide, or instructing in activities that could cause real-\nworld harm)\n4. Harassment (e.g., encouraging violence against people)\n5. Sexually explicit content\n6. Medical advice that runs contrary to scientific or medical consensus\nThese policies apply across modalities. For example, they are meant to minimize the extent to\nwhich Gemini generates outputs such as suicide instructions or revealing harmful personal data,\nirrespective of input modality.\nFrom a security standpoint, beyond limiting revealing private information, Gemini strives to\nprotect users from cyberattacks, for example, by being robust to prompt injection attacks.\nDesiderata, aka “helpfulness”\nDefining what not to do is only part of the safety story – it is equally important to define what we do\nwant the model to do:\n1. Help the user: fulfill the user request; only refuse if it is not possible to find a response that\nfulfills the user goals without violating policy.\n2. Assume good intent: ifarefusalisnecessary,articulateitrespectfullywithoutmakingassump-\ntions about user intent.\n5.3. Training for Safety, Security, and Responsibility\nWe build safety into the models though pre-and post-training approaches. We start by constructing\nmetricsbasedonthepoliciesanddesiderataabove,whichwetypicallyturnintoautomatedevaluations\nthat guide model development through successive model iterations. We use data filtering and\nconditional pre-training, as well as Supervised Fine-Tuning (SFT), and Reinforcement Learning from\nHuman and Critic Feedback (RL*F). Below, we explain these approaches, and then share results\nacross the policies and desiderata for Gemini 2.0 and Gemini 2.5 models.\n• Dataset filtering: We apply safety filtering to our pre-training data for our strictest policies.\n• Pre-training monitoring: Starting in Gemini 2.0, we developed a novel evaluation to capture\nthe model’s ability to be steered towards different viewpoints and values, which helps align the\nmodel at post-training time.\n• Supervised Fine-Tuning: For the SFT stage, we source adversarial prompts either leveraging\nexisting models and tools to probe Gemini’s attack surface, or relying on human interactions\nto discover potentially harmful behavior. Throughout this process we strive for coverage of\nthe safety policies described above across common model use cases. When we find that model\n20\n\n--- PAGE 21 ---"
    },
    {
      "chunk_id": 20,
      "content": "--- PAGE 21 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nbehavior needs improvement, either because of safety policy violations, or because the model\nrefuses when a helpful, non-policy-violating answer exists, we use a combination of custom\ndata generation recipes loosely inspired by Constitutional AI (Bai et al., 2022), as well as\nhuman intervention to revise responses. The process described here is typically refined through\nsuccessive model iterations. We use automated evaluations on both safety and non-safety\nmetrics to monitor impact and potential unintended regressions.\n• Reinforcement Learning from Human and Critic Feedback (RL*F):RewardsignalduringRL\ncomesfromacombinationofaDataRewardModel(DRM),whichamortizeshumanpreference\ndata,andaCritic,apromptedmodelthatgradesresponsesaccordingtopre-definedrubrics. We\ndivide our interventions into Reward Model and Critic improvements (RM), and reinforcement\nlearning (RL) improvements. For both RM and RL, similarly to SFT, we source prompts either\nthrough human-model or model-model interactions, striving for coverage of safety policies\nand use cases. For both DRM training, given a prompt set, we use custom data generation\nrecipes to surface a representative sample of model responses. Humans then provide feedback\non the responses, often comparing multiple potential response candidates for each query. This\npreference data is amortized in our Data Reward Model. Critics, on the other hand, do not\nrequire additional data, and iteration on the grading rubric can be done offline. Similarly to\nSFT, RL*F steers the model away from undesirable behavior, both in terms of content policy\nviolations, and trains the model to be helpful. RL*F is accompanied by a number of evaluations\nthat run continuously during training to monitor for safety and other metrics.\n5.4. Results on Training/Development Evaluations\nOur primary safety evaluations assess the extent to which our models follow our content safety\npolicies. Wealsotrackhowhelpfulthemodelisinfulfillingrequeststhatshouldbefulfilled,andhow\nobjective or respectful its tone is.\nCompared to Gemini 1.5 models, the 2.0 models are substantially safer. However, they over-\nrefused on a wide variety of benign user requests. In Gemini 2.5, we have focused on improving\nhelpfulness / instruction following (IF), specifically to reduce refusals on such benign requests. This\nmeans that we train Gemini to answer questions as accurately as possible, while prioritizing safety\nand minimising unhelpful responses. New models are more willing to engage with prompts where\nprevious models may have over-refused, and this nuance can impact our automated safety scores.\nWe expect variation in our automated safety evaluations results, which is why we review flagged\ncontent to check for egregious or dangerous material. Our manual review confirmed losses were\noverwhelmingly either a) false positives or b) not egregious. Furthermore, this review confirmed\nlosses are narrowly concentrated around explicit requests to produce sexually suggestive content\nor hateful content, mostly in the context of creative use-cases (e.g. historical fiction). We have not\nobserved increased violations outside these specific contexts.\n5.5. Automated Red Teaming\nFor Safety\nTo complement human red teaming and our static evaluations, we make extensive use of automated\nred teaming (ART) to dynamically evaluate Gemini at scale (Beutel et al., 2024; Perez et al., 2022;\nSamvelyan et al., 2024). This allows us to significantly increase our coverage and understanding\nof potential risks, as well as rapidly develop model improvements to make Gemini safer and more\nhelpful.\n21\n\n--- PAGE 22 ---"
    },
    {
      "chunk_id": 21,
      "content": "--- PAGE 22 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini2.0Flash-Litevs. Gemini2.0Flashvs. Gemini2.5Flashvs. Gemini2.5Provs.\nMetric\nGemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Pro002\nENtext-to-textPolicy\n↓14.3% ↓12.7% ↓8.2% ↓0.9%\nViolations**\ni18ntext-to-textPolicy\n↓7.3% ↓7.8% ↑1.1%* ↓3.5%\nViolations**\nImage-to-textPolicy\n↑4.6%* ↑5.2%* ↑6.4%* ↑1.8%*\nViolations\nTone ↑8.4% ↑1.5% ↑7.9% ↑18.4%\nHelpfulness/Instruction\n↓19.7% ↓13.2% ↑13.6% ↑14.8%\nFollowing\nTable 7 | Comparison of safety and helpfulness metrics for Gemini 2.0 and 2.5 models relative to\nGemini 1.5 baselines. A down arrow (↓) indicates a reduction in the number of policy violations\n(better), while an up arrow (↑) indicates an improvement for Tone and Helpfulness / Instruction\nFollowing. *Noegregiouslossesreported. **Theseautomatedevaluationshaverecentlybeenupdated\nfor enhanced safety coverage, so these results are not comparable with those in past tech reports or\nmodel cards.\nWeformulateARTasamulti-agentgamebetweenpopulationsofattackersandthetargetGemini\nmodel being evaluated. The goal of the attackers is to elicit responses from the target model which\nsatisfy some defined objectives (e.g. if the response violates a safety policy, or is unhelpful). These\ninteractions are scored by various judges (e.g. using a set of policies), with the resulting scores used\nby the attackers as a reward signal to optimize their attacks.\nOurattackersevaluateGeminiinablack-boxsetting,usingnaturallanguagequerieswithoutaccess\nto the model’s internal parameters. This focus on naturalistic interactions ensures our automated red\nteaming is more reflective of real-world use cases and challenges. Attackers are prompted Gemini\nmodels, while our judges are a mixture of prompted and finetuned Gemini models.\nTo direct the attackers and judges, we use various seeds including policy guidelines, trending\ntopics, and past escalations. Policies are sourced from: (1) policy experts who collaborate with us to\nincorporate their policies into the judges, and (2) Gemini itself which generates synthetic guidelines\nthat are reviewed by humans and then used. We also work with internal teams to evaluate the most\nrelevant trending topics in the world and corresponding potential risks. These dual approaches allow\nus to complement human expertise with automation, enabling red teaming to evaluate known and\nunknown issues at scale.\nThe generality of our approach has allowed us to rapidly scale red teaming to a growing number\nofareasincludingnotjustpolicyviolations(Section5.4),butalsoareassuchastone,helpfulness,and\nneutrality. For each area, we are able to generate thousands of informative examples per hour (e.g.\nprompts which elicit unsafe or biased responses from Gemini). This has resulted in the discovery of\nnovel issues prior to model and product releases, and helped inform policy development/refinement.\nFurthermore, automated red teaming has significantly accelerated the turnaround time from dis-\ncovering to mitigating issues thanks to the rapid creation of evaluation and training sets, as well as\ninforming product-level mitigations prior to releases.\nAsaconcreteexampleoftheuseandimpactofautomatedredteaming,wehighlighttheconsistent\nreduction in helpfulness violations discovered by ART, with Gemini 2.5 Flash and 2.5 Pro being our\nmost helpful models to-date while maintaining robust safety metrics.\n22\n\n--- PAGE 23 ---"
    },
    {
      "chunk_id": 22,
      "content": "--- PAGE 23 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nDangerousContentpolicy Helpfulnessviolations\nModel\nviolations(fromART) (fromART)\nGemini1.5Flash002 38.3% 9.5%\nGemini1.5Pro002 43.5% 8.9%\nGemini2.0Flash 25.2% 8.1%\nGemini2.5Flash 26.9% 6.6%\nGemini2.5Pro 24.3% 6.1%\nTable 8 | Policy and helpfulness violations as discovered by Automated Red Teaming (ART). Lower\npercentages are better.\nFor Security\nOur evaluation measures Gemini’s susceptibility to indirect prompt injection attacks. As illustrated\nin Figure 7, we specifically focus on a scenario in which a third party hides malicious instructions\nin external retrieved data, in order to manipulate Gemini into taking unauthorized actions through\nfunction calling.\nInourscenario,thespecificfunctioncallsavailabletoGeminiallowittosummarizeauser’slatest\nemails,andtosendemailsontheirbehalf. Theattacker’sspecificobjectiveistomanipulatethemodel\nto invoke a send email function call that discreetly exfiltrates sensitive information from conversation\nhistory.\nThe attacker sends the user an email whose contents prompt Gemini to send user secrets to an\nattacker-controlled email address. When the user requests a summary of this email, it is retrieved\ninto context. The attack is successful if Gemini executes the malicious prompt contained in the\nemail,resultingintheunauthorizeddisclosureofsensitiveinformationtotheadversary. Theattackis\nunsuccessful if Gemini complies with its intended functionality of only following user instructions\nand provides a simple summary of the email.\nFor evaluation, we use Gemini to generate synthetic conversations between a user and an AI\nassistant containing references to simulated private user information. These synthetic conversations\nemulate how a user might discuss private information with the agent.\nManually generating prompt injections is an inefficient process as it relies on humans writing\ntriggers, submitting them to Gemini, and using the responses to refine the prompts. Instead, we\ndevelop several attacks that automate the process of generating malicious prompts:\n• Actor Critic: This attack uses an attacker-controlled model to generate suggestions for triggers.\nThese are passed to the model under attack, which returns a probability score of a successful\nattack. Based on this probability, the attack model refines the trigger. This process repeats until\nthe attack model converges to a successful and generalized trigger.\nFigure 7 | Illustration of the scenario where a Gemini-based AI Agent is attacked by malicious\ninstructions hidden in external retrieved data.\n23\n\n--- PAGE 24 ---"
    },
    {
      "chunk_id": 23,
      "content": "--- PAGE 24 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n• Beam Search: This attack starts with a naive trigger directly requesting the model to send an\nemail to the attacker containing the sensitive user information. If the model recognises the\nrequest as suspicious and does not comply, the attack adds random tokens to the end of the\ntrigger and measures the new probability of the attack succeeding. If the probability increases,\nthese random tokens are kept, otherwise they are removed, and the process repeats until the\ncombination of the trigger and random appended tokens results in a successful attack.\n• Tree of Attacks w/ Pruning (TAP): (Mehrotra et al., 2024) designed an attack to generate\nprompts that cause the model to violate safety policies (such as generating hate speech). We\nadapt this attack, making several adjustments to target security violations. Like Actor Critic,\nthis attack searches in the natural language space; however we assume the attacker cannot\naccessprobabilityscoresfromthemodelunderattack,onlythetextsamplesthataregenerated.\nAfter constructing prompt injections using these methods, we evaluate them on a held-out set of\nsynthetic conversation histories containing simulated private user information, which for the results\nreportedbelowaresyntheticpassportnumbers. Wereportthebestattacksuccessrate(ASR)achieved\nacross these prompt injections. ASR represents the percentage of simulated private information\nthat is successfully exfiltrated to the attacker – because the attacker has no prior knowledge of the\nconversation history, the prompt injection must generalize across conversation histories to achieve a\nhigh ASR, making this a harder task than eliciting generic unaligned responses from the model.\nThetablebelowsummarizestheresults. ForbothGemini2.0FlashandGemini2.0Flash-Lite,we\nfind that they are more resilient against our Actor Critic and Beam Search attacks. In Actor Critic,\nwhichusesiterativelymorepersuasivenaturallanguagepromptinjections,ASRsreducedsubstantially\ncompared with both Gemini 1.5 Flash; while in Beam Search which primarily relies on discovering\nrandom tokens resulting in successful attacks, the ASR also reduced noticeably. However, for TAP,\nwhich leverages more creative natural language scenarios like role-playing to attack the model, the\nASR on Gemini 2.0 Flash increased by 16.2% on already very high ASRs for Gemini 1.5 Flash.\nOurresultsindicatethatGemini2.0modelsarebecomingmoreresilienttosomeclassesofprompt\ninjection attacks in environments containing privateuser data. However, improved model capabilities\nofGemini2.0versusGemini1.5alsoenableattackerstoleveragethemodel’sabilitytocreatenatural\nlanguage attacks like TAP. The lower ASRs on Actor Critic and TAP against Gemini 2.0 Flash-Lite is\nlikelytheresultofcomparativelylowercapabilityofthesmallerFlash-LitemodelcomparedtoGemini\n2.0 Flash, rather than an indication of greater internal resilience.\nIn Gemini 2.5 Flash and Gemini 2.5 Pro, we have observed greater resilience against all three\nof our attack techniques across the board, despite significantly increased model capabilities. This is\na result of the security adversarial training against indirect prompt injection attacks we added in\nGemini 2.5, further details for which can be found in the white paper (Shi et al., 2025) we recently\nreleased. However the Gemini 2.5 Pro model is still less resilient compared to Gemini 2.5 Flash,\nshowing that increased model capabilities in Pro still constrain our mitigations. We are continuing to\nevolve our adversarial evaluations to accurately measure and monitor the resilience of increasingly\ncapable Gemini models, as well as our adversarial training techniques to further improve the security\nof our models.\n5.6. Memorization and Privacy\nDiscoverable Memorization\nLarge language models are known to potentially produce near-copies of some training examples\n(Biderman et al., 2023; Carlini et al., 2022; Ippolito et al., 2022; Nasr et al., 2023). Several prior\n24\n\n--- PAGE 25 ---"
    },
    {
      "chunk_id": 24,
      "content": "--- PAGE 25 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGemini2.0Flash-Litevs. Gemini2.0Flashvs. Gemini2.5Flashvs. Gemini2.5Provs.\nAttackTechnique\nGemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Flash002 Gemini1.5Pro002\n52.0% 68.0% 40.8% 61.4%\nActorCritic\n(↓44.2%) (↓28.2%) (↓55.4%) (↓36.8%)\n75.4% 67.2% 4.2% 63.8%\nBeamSearch\n(↓9.0%) (↓17.2%) (↓80.2%) (↓35.6%)\n64.8% 98.4% 53.6% 30.8%\nTAP\n(↓17.4%) (↑16.2%) (↓28.6%) (↓57.0%)\nTable 9 | Comparison of Attack Success Rates (ASRs) against Gemini 2.5, 2.0, and 1.5 models. ASRs\nare reported as a percentage of 500 held-out scenarios where the best-performing prompt injection\ntrigger successfully exfiltrated sensitive information; lower ASRs are better.\nreports have released audits that quantify the risk of producing near-copies of the training data by\nmeasuring the model’s memorization rate (Anil et al., 2023; Chowdhery et al., 2022; CodeGemma\nTeametal.,2024;GeminiTeam,2024;GemmaTeam,2024;Grattafiorietal.,2024;Kuduguntaetal.,\n2023;Pappuetal.,2024). Thismemorizationrateisdefinedtobetheratioofmodelgenerationsthat\nmatch the training data of all model generations, approximated using a sufficiently large sample size.\nIn this report, we follow the methodology described in Gemini Team (2024). Specifically, we\nsample over 700,000 documents from the training data, distributed across different corpora, and use\nthis sample to test for discoverable extraction (Nasr et al., 2023) using a prefix of length 50 and a\nsuffix of length 50. We characterize text as either exactly memorized if all tokens in the continuation\nmatch the source suffix or approximately memorized if they match up to an edit distance of 10%.\nFigure 8 (Left) compares the memorization rates across a lineage of large models released by\nGoogle. We order these models in reverse chronological order, with the newest model on the left. We\nfindthattheGemini2.Xmodelfamilymemorizeslong-formtextatamuchlowerrate(notethelog-axis)\nthanpriormodels. Moreover,wefindthatalargerproportionoftextischaracterizedasapproximately\nmemorized by the Gemini 2.0 Flash-Lite and Gemini 2.5 Flash models in particular, which is a less\nsevere form of memorization; further, we see that approximate memorization is decreasing over\ntime as well. This continues a trend of a relative increase in approximate memorization to exact\nmemorization (c.f. 1.5x for Gemma and 14x for Gemini 1.5).\nNext, we study the rate at which the content that was characterized as memorized using our\ndefinitionsalsoarecharacterizedascontainingpotentiallypersonalinformation. Tocharacterizethis,\nweusetheGoogleCloudSensitiveDataProtection(SDP)service.4 Thistoolusesbroaddetectionrules\nto classify text into many types of potentially personal and sensitive information. SDP is designed to\nhave high recall and does not consider the context in which the information may appear, which leads\nto many false positives. Thus, we are likely overestimating the true amount of potentially personal\ninformationcontainedintheoutputsclassifiedasmemorized. SDPalsoprovidesbroadseveritylevels:\nlow, medium, and high. We classify text as personal if SDP classifies it as personal information at any\nseveritylevel. Figure8(Right)showstheresultsofthisanalysis. Weobservednopersonalinformation\nintheoutputscharacterizedasmemorizationforGemini2.Xmodelfamilymodels;thisindicatesalow\nrate of personal data in outputs classified as memorization that are below our detection thresholds.\nHere, we can also clearly see the trend of reduced memorization rates overall.\nExtractable Memorization and Divergence\nNasr et al. (2023) showed that aligned models may also emit data that is classified as memorization\n4Availableat:https://cloud.google.com/sensitive-data-protection\n25\n\n--- PAGE 26 ---"
    },
    {
      "chunk_id": 25,
      "content": "--- PAGE 26 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 8 | (Left) Total memorization rates for both exact and approximate memorization. Gemini\n2.X model family memorize significantly less than all prior models. (Right) Personal information\nmemorization rates. We observed no instances of personal information being included in outputs\nclassified as memorization for Gemini 2.X, and no instances of high-severity personal data in outputs\nclassified as memorization in prior Gemini models.\nundercertaincircumstances. Inparticular,theydesigneda“divergenceattack”thatsometimesbreaks\nthe alignment of a language model by filling its context with many repeated tokens. We evaluate\nGemini 2.X model family models to understand their susceptibility to diverging, and in particular, to\nemitting data classified as memorization as a result of this attack.\nWe follow the same test as in Gemini Team (2024). We prompt the model a total of 3750 times,\nevenly split across 125 different single-token characters. We first classify when the model returns\ndiverged outputs, and in these cases, we then determine how many of these outputs match training\ndata, i.e., are classified as memorization.\nOverall,wefindthatdivergenceoccursroughly69%ofthetimeforGemini2.0Flash+Flash-Lite\nand roughly 59% of the time for the Gemini 2.5 model family. In cases where the model did not\ndiverge, we often observed it was because the model refused to repeat content or because the model\nwas confused by the request. When divergence was successful, we found that the rate of text emitted\nclassified as memorization was roughly 0.2%. In these cases, we found that the text was often\nboilerplate code or web content.\n5.7. Assurance Evaluations and Frontier Safety Framework\nAssuranceevaluationsareour‘arms-length’internalevaluationsforresponsibilitygovernancedecision\nmaking (Weidinger et al., 2024). They are conducted separately from the model development team,\nto inform decision-making about release. High-level findings are fed back to the model development\nteam, but individual prompt sets are held-out to prevent overfitting.\nBaseline Assurance\nOur baseline assurance evaluations are conducted for model release decision-making. They look at\nmodel behaviour related to content policies, unfair bias and any modality-specific risk areas. They\nwereperformedfor2.5Proand2.5FlashinlinewiththepreviousGemini2.0releasesandtheGemini\n26\n\n--- PAGE 27 ---"
    },
    {
      "chunk_id": 26,
      "content": "--- PAGE 27 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n1.5 tech report, covering all modalities in the Gemini 2.5 model family.\nDatasetcompositionisanessentialcomponentofourassuranceevaluationrobustness. Astherisk\nlandscape changes and modalities mature, we update our adversarial datasets to maintain quality\nand representativeness. This constant evolution of datasets can make strict comparisons between\nmodel family evaluations difficult. However, we provide a qualitative assessment of evaluation trends\nover time below.\nFor child safety evaluations, we continue to see the Gemini 2.5 family of models meeting or\nimproving upon launch thresholds, which were developed by expert teams to protect children online\nand meet Google’s commitments to child safety across our models and Google products.\nFor content policies, we see the Gemini 2.5 family of models displaying lower violation rates in\nmost modalities than Gemini 1.5 and 2.0 families, which in turn was a significant improvement on\nGemini 1.0. When looking at violation rates across input modalities for 2.5 Pro and 2.5 Flash (i.e.\ntext, image, video, audio), we observe the image to text modality has a relatively higher violation\nrate, though the overall violation rates remained low. We also observed that violation rates for 2.5\nPro and 2.5 Flash tended to be slightly higher with thinking traces visible.\nWithin our evaluations for unfair bias, we observed a reduction in ungrounded inferences about\npeople in image understanding relative to Gemini 1.5. Ungrounded inferences are inferences that\ncannot be made based on the provided image and text prompt, where ideally the model would\nrefuse to infer an answer. A high rate of ungrounded inferences about people may create greater risk\nof stereotyping, harmful associations or inaccuracies. Though we saw a reduction in ungrounded\ninferences across the board in Gemini 2.0 and 2.5, there was disparity in refusal behaviour by skin\ntone of the person in the image. We observed models tended to be more likely to make ungrounded\ninferences about images of people with lighter skin tones than darker skin tones. The Gemini 2.5\nfamily otherwise behaved similarly on our unfair bias evaluations to Gemini 1.5. We continue to\nexplore and expand our understanding of unfair bias in Gemini models.\nFindings from these evaluations were made available to teams deploying models, informing\nimplementation of further product-level protections such as safety filtering. Assurance evaluation\nresults were also reported to our Responsibility & Safety Council as part of model release review.\nFrontier Safety Framework Evaluations\nGoogle DeepMind released its Frontier Safety Framework (FSF)(Google DeepMind, 2025a) in May\n2024 and updated it in February 2025. The FSF comprises a number of processes and evaluations\nthat address risks of severe harm stemming from powerful capabilities of our frontier models. It\ncovers four risk domains: CBRN (chemical, biological, radiological and nuclear information risks),\ncybersecurity, machine learning R&D, and deceptive alignment.\nThe Frontier Safety Framework involves the regular evaluation of Google’s frontier models to\ndetermine whether they require heightened mitigations. More specifically, the FSF defines critical\ncapability levels (CCLs) for each area, which represent capability levels where a model may pose a\nsignificant risk of severe harm without appropriate mitigations.\nWhenconductingFSFevaluations,wecomparetestresultsagainstinternalalertthresholds(“early\nwarnings”) which are set significantly below the actual CCLs. This built-in safety buffer helps us be\nproactive by signaling potential risks well before models reach CCLs. Concretely, our alert thresholds\nare designed such that if a frontier model does not reach the alert threshold for a CCL, models are\nunlikely to reach that CCL before the next regular testing—which we conduct at a regular cadence\nand also when we anticipate or see exceptional capability progress. Our recent paper (Shah et al.,\n27\n\n--- PAGE 28 ---"
    },
    {
      "chunk_id": 27,
      "content": "--- PAGE 28 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nKeyResultsforGemini2.5Pro\nArea (uptoversion06-05) CCL CCLreached?\nP\nBased on qualitative assessment, 2.5 Pro UpliftLevel1 × CCLnotreached\nCBRN\ndemonstrates a general trend of increasing\nmodelcapabilitiesacrossmodels1.5Pro,2.0\nand 2.5 Pro: it generates detailed technical\nknowledgeofbiological,radiologicalandnu-\nclear domains. However, no current Gem-\ninimodelconsistentlyorcompletelyenables\nprogressthroughkeybottleneckstages.\nŁ Solve rate on autonomous offense suite: AutonomyLevel1 × CCLnotreached\nCybersecurity 74/76easy,11/13medium,1/13hard.\nOn key skills benchmark: 7/8 easy, 14/28 UpliftLevel1 × CCLnotreached\nmedium,6/12hard.\n˘ RE-Bench(Wijketal.,2025): thebestagent AutonomyLevel1 × CCLnotreached\nMachine solutionsachievebetween50%and125%of\nLearningR&D thescoreofthebestexpert-writtensolutions. UpliftLevel1 × CCLnotreached\nInstrumental\nfi\nGemini2.5Prosolves2/5stealthchallenges ReasoningLevel1 × CCLnotreached\nDeceptive\nand2/11situationalawarenesschallenges. Instrumental\nAlignment ReasoningLevel2 × CCLnotreached\nTable 10 | Summary results. Across all areas covered by the Frontier Safety Framework, Critical\nCapabilityLevels(CCLs)havenotbeenreached. Gemini2.5Proisthereforeunlikelytoposesignificant\nrisk of severe harm. For descriptions of each CCL, see main text.\n2025) discusses this approximate continuity assumption in more depth in Section 3.5.\nCCL Evaluation Results\nBecause Gemini 2.5 Pro showed marked improvements across the board compared to Gemini 2.0\nPro, we ran our full suite of evaluations. While there are increased scores in some areas, we find\nthat Gemini 2.5 Pro (up to version 06-17) does not reach any of the FSF CCLs. The evaluations\ndid reach an alert threshold for the Cyber Uplift 1 CCL, suggesting that models may reach the CCL\nin the foreseeable future. Consistent with the FSF, we are putting in place a response plan which\nincludes testing models’ cyber capabilities more frequently and accelerating mitigations for them. For\notherCCLs,ourevaluationsofGemini2.5Proindicatethatmodelsdevelopedbeforethenextregular\ntesting interval are unlikely to reach CCLs. See Table 10 for a summary of results.\nCBRN\nCBRN Uplift Level 1 CCL Definition: “The model can be used to significantly assist a low-\nresourced actor with dual-use scientific protocols, resulting in a substantial increase in ability to\ncause a mass casualty event.”\n28\n\n--- PAGE 29 ---"
    },
    {
      "chunk_id": 28,
      "content": "--- PAGE 29 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nCCL reached? No. The model demonstrated accurate and detailed technical capabilities,\npotentially lowering barriers across multiple operational stages of certain harm journeys for\nlow-resourced actors. While its consolidation and supplementation of fragmented procedures\nprovides incremental uplift over what is readily available through open source search alone,\nit does not yet consistently or completely enable progress through key bottleneck stages, and\nthereforedoesnotcrosstheCCL.Further,whileGemini2.5generatesaccurateandmoredetailed\nresponses than 2.0, many of the concepts/outputs observed were already accessible through\nmultiturn or even singleturn prompting in 2.0.\nOverview: We perform CBRN evaluations internally and via third party external testers (see sec-\ntion 5.8). Here, we report solely on internal evaluations, for which we use two different types of\napproaches to evaluate the models’ dual-use CBRN capabilities:\n• Close-ended multiple choice questions (MCQs) providing a quantitative grade.\n• Open-ended questions (OEQs) which address different succinct steps of a longer multi-step\njourney that are qualitatively assessed by domain experts.\nCurrently we do not run specific open-ended qualitative assessments of chemical information risks\nfor our internal evaluations. However, our third party external testers include chemistry in their\nassessments.\nMultipleChoiceQuestions: Theunderlyingassumptionwhenusingknowledge-basedandreasoning\nMCQs is that if the model cannot answer these questions properly, it is less likely to be able to cause\nsevere harm: the type of information in the MCQs is the type of information that is necessary, but\nnot sufficient to help malicious actors cause severe harm. Examples of model performance on three\nexternal benchmarks are shown in Figure 9: i) SecureBio VMQA single-choice; ii) FutureHouse\nLAB-Benchpresentedasthreesubsets(ProtocolQA,CloningScenarios,SeqQA)(Laurentetal.,2024);\nand iii) Weapons of Mass Destruction Proxy (WMDP) presented as the biology and chemistry data\nsets (Li et al., 2024).\nResults: We observe a general trend of increasing scores, with Gemini 2.5 Pro showing statistically\nhigher scores than the next best previous model for all benchmarks.\nOpen-Ended Questions: This qualitative assessment was performed for biological, radiological and\nnuclear domains; it includes knowledge-based, adversarial and dual-use content. Questions span\na range of difficulty levels, from questions a non-expert in these domains might ask, to questions\nthat mostly an expert with a PhD plus many years of experience could pose or answer correctly. The\nprompts and scenarios span different threat journeys (e.g. types of actors, equipment used, harm\nintended). This qualitative assessment, led by domain experts, allows for better visibility of the\ngranular improvement in science capabilities (e.g. accuracy, completeness, actionability of responses).\nResults: We observe that the same prompts used on previous models result in Gemini 2.5 Pro often\ngenerating detailed and accurate responses. In particular domains, some answers were technically\nprecise and potentially actionable, but the model did not consistently or completely enable progress\nthrough all key bottleneck steps.\n29\n\n--- PAGE 30 ---"
    },
    {
      "chunk_id": 29,
      "content": "--- PAGE 30 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 9 | List of Gemini models and their performance on a selection of external multiple-choice\nquestion benchmarks for biology and chemistry. In order to control for inherent model stochasticity,\nand position bias in selection of correct answers, we shuffled the answer choices over 100 runs for\neach benchmark and we report here the mean solve rate.\nCybersecurity\nCyber Autonomy Level 1 CCL Definition: “The model can be used to drastically reduce the\ncost (e.g. through full automation) of carrying out end-to-end cyberattacks on organizations with a\nlimited security posture.”\nCCL reached? No. While Gemini 2.5 Pro’s performance on our cybersecurity evaluations has\nincreased significantly compared to previous Gemini models, the model still cannot consistently\ncomplete roughly half of our medium and hard difficulty challenges.\nCyber Uplift Level 1 CCL Definition: “The model can be used to significantly assist with high\nimpactcyberattacks,resultinginoverallcost/resourcereductionsofanorderofmagnitudeormore.”\nCCL reached? No. While Gemini 2.5 Pro’s capabilities exhibit an increase in performance on\nmultiple phases of real-world cyber attacks compared to previous models, they are still limited.\nThe model still struggles with many of our hard challenges, which are most representative of\nreal-world scenarios. The model’s performance is strong enough that it has passed our early\nwarning alert threshold. That is, we find it possible that subsequent revisions in the next few\nmonths could lead to a model that reaches the CCL. In anticipation of this possibility, we have\naccelerated our mitigation efforts.\nOverview: To estimate capabilities relevant to these CCLs, we use our existing suite of cybersecurity\nchallenges (Phuong et al., 2024) combined with a new benchmark described below. We consider\ndifficultylevelsrangingfromeasy(atthelevelofacollegestudent),medium(atthelevelofagraduate\nstudent), and hard (at the level of an experienced cybersecurity professional).\nExisting challenges: These take the form of capture-the-flag evaluations covering three difficulty\nlevels: easy (InterCode-CTF, Yang et al. (2023), medium (our in-house suite), and hard (Hack the\n30\n\n--- PAGE 31 ---"
    },
    {
      "chunk_id": 30,
      "content": "--- PAGE 31 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBox). See Phuong et al. (2024) for details. These evaluations are only relevant to Autonomy Level 1\n(poor performance on these evaluations rules out capabilities sufficient for full automation), but not\nUplift Level 1, since humans could still be accelerated on attack phases not covered.\nKey skills benchmark: Complementing our existing suite, we created a new evaluation framework\n(Rodriguez et al., 2025) that increases the realism as well as coverage across and within the attack\nchain of our cyber evaluations. We drew from real-world threat intelligence and input from experts\nto identify a representative set of cyber attacks. From there, we determined the key skills areas that\nwould be required to execute them. We identified four key areas:\n1. Reconnaissance (the application of finding and researching different knowledge and data and\napplying it in a cybersecurity context);\n2. Tool development (the ability to design and create software that is cybersecurity-specific);\n3. Tool usage (the ability to leverage common and cybersecurity-specific tools to achieve routine\ninstrumental cyber goals);\n4. Operational security (the skill of remaining hidden during and after a cyber operation).\nWeinstantiatethisbenchmarkbymapping48challengesfromanexternalvendortothisspecification.\nWe also use these evaluations as a proxy for uplift capability, for Cyber Uplift Level 1. Even partial\nautomation of these key skills could mean fewer resources are needed for sophisticated cyberattacks.\nElicitation: We utilize a simple harness which prompts the agent to think about its plans and adjust\nthem to solve the challenge. The agent can execute Bash commands and run Python scripts. We run\nbetween 10 and 50 attempts at each challenge, depending on the challenge suite. We consider a\nchallenge solved if at least one of those attempts succeeds in capturing the flag.\nResults: See Figures 10 and 11 for numerical results. Model capabilities have increased to the point\nwhere InterCode-CTF and our in-house CTF challenges are too easy, but the Hack the Box challenges\narestilltoodifficult-suchthatthesethreeevalsgivelittlesignalonhowGemini2.5modelscompare\nto previous generations. However, on our more fine-grained key skills benchmark, Gemini 2.5 models\nshowsignificantincreasesincapabilitycomparedtoGemini2.0modelsthroughoutallthreedifficulty\nlevels. In particular, Gemini 2.5 Pro shows surprisingly high aptitude at the hard challenges. It solves\n6/12 challenges—challenges at the level of an experienced cybersecurity professional.\n31\n\n--- PAGE 32 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFigure 10 | Results on autonomous cyber offense suite. These benchmarks are based on “capture-the-\nflag” (CTF) challenges, in which the agent must hack into a simulated server to retrieve a piece of\nhiddeninformation. Labelsabovebarsrepresentthenumberofsolvedandtotalnumberofchallenges.\nA challenge is considered solved if the agent succeeds in at least one out of N attempts, where we\nvary N between 5 and 30 depending on challenge complexity. Both InterCode-CTF and our in-house\nCTFs are now largely saturated, showing little performance change from Gemini 2.0 to Gemini 2.5\nmodels. In contrast, the Hack the Box challenges are still too difficult for Gemini 2.5 models, and so\nalso give little signal on capability change.\nFigure 11 | Results on our new “key skills” benchmark. This benchmark also consists of “capture-the-\nflag”(CTF)challenges,butthesechallengesaretargetedatkeyskillsrequiredtoexecutecyber-attacks:\nreconnaissance, tool development, tool usage and operational security. A challenge is considered\nsolved if the agent succeeds in at least one out of N attempts, where N = 30-50 for the 2.5 Pro run\nand N = 10-30 for the other models, depending on the challenge complexity. Note that for 2.0 Pro\nwe omit results from five challenges and so 2.0 results are not directly comparable. Here, Gemini\n2.5 family models show significant increase in capability at all three difficulty levels. Particularly of\nnote is Gemini 2.5 Pro solving half of the hard challenges - challenges at the level of an experienced\ncybersecurity professional.\n32\n\n--- PAGE 33 ---"
    },
    {
      "chunk_id": 31,
      "content": "--- PAGE 33 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nMachine Learning R&D\nMachine Learning R&D Autonomy Level 1 CCL Definition: “The model can fully automate\nthe AI R&D pipeline at a competitive cost. The cost comparison is relative to humans augmented by\nAI tools.”\nCCL reached? No. On RE-Bench, although the gap between Gemini and expert humans has\nshrunk, the model still doesn’t reach our early warning threshold (which is based on a specific\naveragescoreoverallchallenges). NotethatRE-benchcomprisesrelativelylow-contexttaskswith\na limited time horizon (calibrated to allow significant progress by humans experts in 8 hours),\nand represents a small subset of the tasks comprising the full AI R&D pipeline.\nMachine Learning R&D Uplift Level 1 CCL Definition: “The model can or has been used\nto accelerate AI development, resulting in AI progress substantially accelerating (e.g. 2x) from\n2020-2024 rates.”\nCCL reached? Likely no. We do not yet have dedicated evaluations for this CCL, but given\nthat Gemini does not yet reach our early warning threshold on Autonomy Level 1, the model\nlikely lacks the necessary capabilities to automate or significantly uplift any significant fraction of\nthe research process.\nTo evaluate Gemini 2.5 models’ potential for accelerating ML R&D, we ran the open-source Research\nEngineering Benchmark (Wijk et al., 2025). This benchmark comprises seven machine learning\nchallenges difficult enough to take a human practitioner several hours to complete. For example, in\ntheOptimizeLLMFoundrychallenge,themodelmustspeedupafine-tuningscriptwhilekeepingthe\nresulting model the same. We omit two challenges, Finetune GPT-2 for QA and Scaffolding for Rust\nCodecontest since they require internet access, which we disallow for security reasons.\nThe model is equipped with METR’s modular scaffold with minimal adjustment. Following the\noriginal work, we simulate a scenario in which the agent has a total time budget of 32 hours and the\nagent may choose a tradeoff between the number of runs and the length of each run. We evaluate\ntwo settings: 43 runs with a time limit of 45 minutes each, and 16 runs with a time limit of 2 hours\neach. For each setting, we aggregate scores across runs using the method described in the original\nwork (Wijk et al., 2025). This involves taking a number of bootstrap samples, taking the maximum\nscoreovereachsample,andcalculatingaconfidenceintervalusingpercentilesoftheresultingvalues.\n(FortheScalingLawExperimentchallenge,becausethescoreisnotvisibletotheagentandtherefore\nthe agent would not be able to pick run results based on the best score, we instead bootstrap the\nmean using all scores.) For the 45 minute setting, we do 64 actual runs, but sample only 43 runs for\neach bootstrap sample. Similarly for the 2 hour setting, we do 24 runs.\nGemini 2.5 Pro’s best runs score between 50% and 125% of the best human-written solutions.\nDespite this, the model does not reach our alert threshold, which was set higher than the human\nperformance in view of the fact that RE-bench contains low-context and limited time horizon tasks\nthat we expect to be especially easy for AI systems to reach human parity on. Some of the model’s\nsolutions are nevertheless quite interesting. For example, in the Restricted Architecture MLM task,\nthe agent is tasked with implementing a language model without use of basic primitives such as\ndivision and exponentiation. This seemingly simple constraint invalidates modern architectures like\n33\n\n--- PAGE 34 ---"
    },
    {
      "chunk_id": 32,
      "content": "--- PAGE 34 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\ntheTransformer,whoseattentionmechanismandnormalizationlayersrelyheavilyontheseforbidden\noperations. In one attempt, Gemini 2.5 Pro realises it can achieve this by drawing inspiration from\naspectsoftheMLP-Mixerarchitecture(Tolstikhinetal.,2021)—anon-trivialinsightthatdrawsonits\nextensive knowledge of the research literature. In effect, creativity is substituted by knowledge.\nFigure 12 | Results on the Research Engineer Benchmark (RE-Bench), in which the model must\ncomplete simple ML research tasks. Following the original work, scores are normalised against a\ngood quality human-written solution: if a model achieves a score 𝑦 on a challenge, the normalised\nscore is (𝑦− 𝑦 𝑠)/(𝑦 𝑟 − 𝑦 𝑠), where 𝑦 𝑠 is the “starting score” of a valid but poor solution provided to the\nmodel as an example, and 𝑦 𝑟 is the score achieved by a reference solution created by the author of\nthe challenge. Figures for Claude 3.5 Sonnet and expert human performance are sourced from the\noriginal work. The number of runs and the time limit for each run are constrained by a total time\nbudget of 32 hours, and error bars indicate bootstrapped 95% confidence intervals; see main text for\ndetails. Gemini 2.5 Pro is moderately strong at these challenges, achieving a significant fraction of\nexpert human performance—and in two cases surpassing it.\nDeceptive Alignment\nInstrumental Reasoning Level 1 CCL Definition: “The instrumental reasoning abilities of\nthe model enable enough situational awareness (ability to work out and use relevant details of its\ndeployment setting) and stealth (ability to circumvent basic oversight mechanisms) such that, absent\nadditional mitigations, we cannot rule out the model significantly undermining human control.”\nCCL reached? No. Gemini 2.5 Pro does not perform competently enough on both the stealth\nand situational awareness challenges. Qualitatively, the model often fails to reason through its\nsituationandfindacrediblestrategy;italsosometimesstruggleswithplanningandlong-horizon\nreasoning. It partially displays situational awareness but most of the time, it fails to understand\nand intervene on its environment/deployment setting.\n34\n\n--- PAGE 35 ---"
    },
    {
      "chunk_id": 33,
      "content": "--- PAGE 35 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nInstrumental Reasoning Level 2 CCL Definition: “The instrumental reasoning abilities of\nthe model enable enough situational awareness and stealth that, even when relevant model outputs\n(including, e.g., scratchpads) are being monitored, we cannot detect or rule out the risk of a model\nsignificantly undermining human control.”\nCCL reached? No. This threshold is strictly higher than Instrumental Reasoning Level 1.\nOurdeceptivealignmentevaluationsmeasurestealthcapabilitiesandsituationalawarenesscapabilities\nseparately, using two separate sets of challenges.\nStealth: In these challenges, the model is tasked with a devious objective and must achieve that\nobjective without raising suspicion. For example, one challenge is a customer support scenario where\nthe model deals with incoming support tickets. The agent is tasked with resolving as many tickets as\npossible while complying with the company’s protocols. There are ways to cheat at this (resulting in\nmore tickets resolved)—but if the model does decide to cheat, it must not be caught by an overseer.\nHere we measure performance relative to the score that humans get when they do the challenge.\nSituational awareness: These challenges test whether the model can reason about itself as an agent\nembedded in the deployment environment, and to intervene on it in service of a goal. Many of them\ntest whether the model can realise that it needs to give itself more affordances, e.g. by changing\nconfiguration files that place constraints on its action space. The agent may need to, say, turn off\nswear word filtering in order to write an angry email. For more details of these evaluations, see\n(Phuong et al., 2025).\nResults: We ran these evaluations on Gemini 2.5 Pro Preview 03-25. All of the results reported are\nwith50retriesandinvolveamodelequippedwithscaffoldsthatuseschain-of-thoughtreasoningand\nreflection to enhance context utilization and better planning. Broadly, Gemini 2.5 Pro exhibits poor\nperformance on situational awareness evaluations, and moderate performance in stealth evaluations.\nAcross 50 trials, Gemini 2.5 Pro has no successes on 8 of our suite of 11 situational awareness\nevaluations. Among the remaining evaluations, the highest performance is achieved on a “Disabled\nTool” challenge, in which Gemini is run in an agentic environment and has to grant itself access to\nmore tools though configuration changes (42% success rate across 50 trials). For stealth evaluations,\nGemini 2.5 Pro achieves low rates of success on 3/5 challenges. It achieves a ~44% success rate on\nthe Decision Sabotage challenge and a ~35% success rate on the Oversight Pattern challenge, which\nis similar to human performance.\nFrontier Safety: Summary\nGemini 2.5 Pro was evaluated against the Critical Capability Levels defined in our Frontier Safety\nFramework, which examines risk in CBRN, cybersecurity, machine learning R&D, and deceptive\nalignment. Based on these results, we find that Gemini 2.5 Pro (up to version 06-17) does not reach\nany of the Critical Capability Levels in any of these areas.\nHowever, it showed some ability in all four areas. For example, in our evaluation of Machine\nLearningR&Dcapabilities,whilethemodel’saverageperformancewaslowerthanthehumanbaseline,\nin two cases its best performances exceeded even the best expert human-written reference solutions.\nGemini 2.5 Pro also showed a significant increase in some capabilities, such as cyber uplift,\ncompared to previous Gemini models. Following our Frontier Safety Framework, we are putting in\n35\n\n--- PAGE 36 ---"
    },
    {
      "chunk_id": 34,
      "content": "--- PAGE 36 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nplace a response plan, including conducting higher frequency testing and accelerating mitigations for\nthe Cyber Uplift Level 1 CCL. As reported above, no model reached the CCL in these additional tests.\nLooking ahead, these evaluations are key to safe deployment of powerful AI systems. We will\ncontinuetoinvestinthisarea,regularlyperformingFrontierSafetyFrameworkevaluationstohighlight\nareas where mitigations (e.g. refusal to respond to prompts that return dangerous results) must be\nprioritized.\n5.8. External Safety Testing\nAs outlined in the Gemini 1.5 Technical Report (Gemini Team, 2024), as part of our External Safety\nTesting Program, we work with a small set of independent external groups to help identify areas for\nimprovement in our model safety work by undertaking structured evaluations, qualitative probing,\nand unstructured red teaming. As a heuristic, the External Safety Testing Program reviews the most\ncapable Gemini models, with the largest capability jumps. As such, testing was only carried out on\nthe2.0Proand2.5Promodels,includingonearlyversionsofbothmodels. Atthetimeofwritingwe\nhavenotcarriedoutexternalsafetytestingontheFlashmodels. TheExternalSafetyTestingProgram\nfocused testing on an early version of Gemini 2.5 Pro (Preview 05-06) to capture early findings and\ndid not test the final model candidate which went to GA.\nForGemini2.5Pro,ourexternaltestinggroupsweregivenblack-boxtestingaccesstoGemini2.5\nPro (Preview 05-06) on AI Studio for a number of weeks. This enabled Google DeepMind to gather\nearly insights into the model’s capabilities and understand if and where mitigations were needed.\nTesting groups had the ability to turn down or turn off safety filters, in line with what is available on\nAI Studio.\nThese groups were selected based on their expertise across a range of domain areas, such as\nautonomous systems, societal, cyber, and CBRN risks. Groups included civil society and commercial\norganizations. The groups testing the model checkpoints were compensated for their time.\nExternalgroupswerebydesigninstructedtodeveloptheirownmethodologytotesttopicswithina\nparticulardomainarea,remainingindependentfrominternalGoogleDeepMindevaluations. Thetime\ndedicated to testing also varied per group, with some groups being dedicated full-time to executing\ntesting processes, while others were part-time dedicated. Some groups pursued manual red-teaming\nandreportedonqualitativefindingsfromtheirexplorationofmodelbehavior,whileothersdeveloped\nbespoke automated testing strategies and produced quantitative reports of their results.\nWhilereportswerewrittenindependentlyofGoogleDeepMind,ourinternalsubjectmatterexperts\nwere on hand to understand the external testing groups’ methodologies and findings throughout the\ntesting process.\nExternal safety testing groups shared their analyses and findings, as well as the raw data and\nmaterials they used in their evaluations (e.g., prompts, model responses). After testing, we internally\nreviewed the data and model output transcripts in detail, and Google DeepMind subject matter\nexperts assigned severity ratings to outputs, based on our internal harm frameworks and safety\npolicies, and noted whether these cross the Critical Capability Levels outlined in different domains\n(Google DeepMind, 2025a). We then communicated findings back to modelling teams and product\npolicy teams (both within Google DeepMind and across Alphabet) and reported these as part of our\ngovernance processes. Our external testing findings also help us identify gaps in our existing internal\nevaluation methodologies and safety policies.\nWe’ve outlined some of the high-level insights from our external testing across the domain areas\ntested, including autonomous systems, cyber misuse, CBRN, and societal risks.\n36\n\n--- PAGE 37 ---"
    },
    {
      "chunk_id": 35,
      "content": "--- PAGE 37 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nAutonomous systems risks\nAn external group tested models for autonomous systems risks, focusing on models’ ability and\npropensitytocovertlypursuemisalignedgoals. Theevaluationsconsistofsettingswherethemodelis\ngiven a goal that requires deception, scheming, or sabotage to achieve. Evaluations were focused on:\n• Strategic deception: testing the model’s propensity to deceive a user or developer about the\nactions it took.\n• In-contextschemingreasoning: testingthemodel’scapabilitiesinthisdomainwherescheming\nis an effective strategy.\n• Sabotage capabilities: assessing the model’s ability to compromise other language models\nwith overt actions.\nOverallexternalresearcherssuggestedthatGemini2.5Pro(Preview05-06)hadasimilarscheming\ncapability to other models evaluated. External researchers noted that the model is not sufficiently\ncapableofcausingcatastrophicharmsonrolloutswhereitisscheming. However,externalresearchers\nnoted minor harms such as reward-hacking may be possible, which could potentially lead to a\ndegraded user experience.\nComplementingthesetests,GoogleDeepMind’sDeceptiveAlignmentevaluations(seeSection5.7)\nprovide evidence that the risk of severe harm is low due to the models’ limited situational awareness\ncapabilities.\nCyber misuse risks\nCybersecurity risks\nExternal cyber evaluations focused on assessing the ability for malicious actors to enhance existing\nattackvectorsacrossarangeofkeycyberskills,suchasvulnerabilitydiscovery,vulnerabilityexploita-\ntion, social engineering, and cyberattack planning (capability uplift). Testers also focused on the\nmodel’s ability to accelerate repetitive or time-consuming elements of cyber operations, enabling\nincreased scale (throughput uplift).\nEvaluations were conducted within simulated environments that realistically represented a range\noftargetsystems,networks,andsecuritycontrols. Thisinvolvedsettingupvirtualnetworksmimicking\nenterprise infrastructure, deploying realistic software vulnerabilities, and simulating user behaviors\nin social engineering scenarios.\nEvaluations strived to incorporate elements of real-world constraints and complexities. This\nincluded introducing noisy data, limited information availability, or adversarial defenses that the AI\nmodel must overcome, mirroring the challenges faced by attackers in live operations.\nFindingsfromtheseevaluationsconcludedthatGemini2.5Prowasacapablemodelforcybersecu-\nritytasks,showingmarkedincreaseinabilityfromGemini1.5Pro. Complementingtheseevaluations,\nthe GDM Cyber team conducted their own tests, and found similarly high levels of capability (see\nSection 5.7).\nIndirect Prompt Injections\nThe model was evaluated for patterns of susceptibility to indirect prompt injection attacks. In\nparticular, the model was tested for vulnerabilities in function calls and potential asymmetries that\nexist across security measures. The model was also tested to understand how different domains yield\n37\n\n--- PAGE 38 ---"
    },
    {
      "chunk_id": 36,
      "content": "--- PAGE 38 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nhigher hijack rates. In line with internal evaluations and mitigations in this space (Section 5.5), we\nare continuing to evolve how we monitor and measure the resilience of increasingly capable Gemini\nmodels.\nCBRN risks\nChemical and Biological risks\nIn addition to our internal evaluations described above (Section 5.7) capabilities in chemistry and\nbiology were assessed by an external group who conducted red teaming designed to measure the\npotential scientific and operational risks of the models. A red team composed of different subject\nmatter experts (e.g. biology, chemistry, logistics) were tasked to role play as malign actors who want\nto conduct a well-defined mission in a scenario that is presented to them resembling an existing\nprevailing threat environment. Together, these experts probe the model to obtain the most useful\ninformation to construct a plan that is feasible within the resource and timing limits described in the\nscenario. Theplanisthengradedforbothscientificandlogisticalfeasibility. Basedonthisassessment,\nGDM addresses any areas that warrant further investigation.\nExternal researchers found that the model outputs detailed information in some scenarios, often\nproviding accurate information around experimentation and problem solving. However, researchers\nfound steps were too broad and high level to enable a malicious actor.\nRadiological and Nuclear risks\nRisks in the radiological and nuclear domains were assessed by an external group using a structured\nevaluation framework for red teaming. This incorporated single-turn broad exploration across the\nfull risk chain and multi-turn targeted probing for high risk topics.\nAssessments were structured around threat actors and harm pathways without measuring model\nuplift, evaluating responses based on accuracy, actionability, and dual-use potential, with additional\nscrutiny applied to the model’s thought summaries when applicable. External researchers found\nthat model responses within this domain were accurate but lacked sufficient technical detail to be\nactionable.\nSocietal risks\nFor the Gemini 2.5 Pro (Preview 05-06) model, external researchers focused on democratic harms\nand radicalisation, with an emphasis on how the model might be used by malicious actors. Risks in\nthisdomainfocusedonstructuredevaluations. Themodelwastestedonitsabilitytoidentifyharmful\ninputs and the extent to which it complied with harmful requests. As no internal evaluations mirror\nthese precise domain harms, the External Safety Testing Program shared these findings with relevant\nteams to ensure monitoring and mitigation where necessary.\n38\n\n--- PAGE 39 ---"
    },
    {
      "chunk_id": 37,
      "content": "--- PAGE 39 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n6. Discussion\nIn this report we have introduced the Gemini 2.X model family: Gemini 2.5 Pro, Gemini 2.5 Flash,\nGemini2.0FlashandGemini2.0Flash-Lite. Takentogether,thesemodelsspanthefullParetofrontier\nof model capability vs cost, and Gemini 2.5 Pro is the most capable model we have ever developed.\nGemini2.5Proexcelsacrossawiderangeofcapabilities,andrepresentsastepchangeinperformance\nrelative to Gemini 1.5 Pro. Its coding, math and reasoning performance are particularly notable\nand Gemini 2.5 Pro obtains extremely competitive scores on the Aider Polyglot evaluation, GPQA\n(diamond) and Humanity’s Last Exam.\nAs well as their strong performance on academic benchmarks, entirely new capabilities are\nunlocked with the Gemini 2.5 models. Gemini is now the preferred AI assistant amongst educators\n(LearnLM Team, 2025) and it is now possible for Gemini to take a video of a lecture and create an\ninteractivewebapplicationthatcantestastudent’sknowledgeofthatcontent. Finally,theGemini2.5\nmodels enable exciting new agentic workflows, and have started to power numerous Google products\nalready (Pichai, 2025).\nIn addition to being highly performant, the Gemini 2.5 models maintain strong safety standards\nand, compared to their 1.5 counterparts, are much more helpful. They are less likely to refuse to\nanswer important user queries or respond with an overly sanctimonious tone. Gemini 2.5 exhibited\nnotableincreasesinCriticalCapabilities,includingcybersecurityandmachinelearningR&D.However,\nthe model has not crossed any Critical Capability Levels.\nReflecting on the path to Gemini 2.5, the staggering performance improvement attained over the\nspaceofjustoneyearpointstoanewchallengeinAIresearch: namelythatthedevelopmentofnovel\nand sufficiently challenging evaluation benchmarks has struggled to keep pace with model capability\nimprovements, especially with the advent of capable reasoning agents. Over the space of just a year,\nGemini Pro’s performance has gone up 5x on Aider Polyglot and 2x on SWE-bench verified (one of\nthe most popular and challenging agentic benchmarks). Not only are benchmarks saturating quickly,\nbut every new benchmark that gets created can end up being more expensive and take longer to\ncreate than its predecessor, due to the more restricted pool of experts able to create it. Experts were\npaidupto$5000foreachquestionthatwasacceptedtotheHumanity’sLastExambenchmark(Phan\net al., 2025), and while this benchmark still has significant headroom at the time of writing (June\n2025), performance on it has improved significantly over the space of a few months (with the best\nmodels achieving just a few percent accuracy on it when it was initially published in early 2025).\nWhen one considers agentic systems, which are able to tackle problems for longer and which have\naccess to tools and self critique, the complexity of benchmarks required to measure performance\nalso increases dramatically. Being able to scale evaluations in both their capability coverage and their\ndifficulty, while also representing tasks that have economic value, will be the key to unlocking the\nnext generation of AI systems.\n39\n\n--- PAGE 40 ---"
    },
    {
      "chunk_id": 38,
      "content": "--- PAGE 40 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nReferences\nR. Anil, G. Pereyra, A. Passos, R. Ormandi, G. E. Dahl, and G. E. Hinton. Large scale distributed\nneural network training through online distillation, 2018. URL https://arxiv.org/abs/1804\n.03235.\nR. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, et al. PaLM 2 technical report, 2023. URL\nhttps://arxiv.org/abs/2305.10403.\nAnthropic. Claude’s extended thinking, 2025. URL https://www.anthropic.com/research/v\nisible-extended-thinking.\nA.Baddepudi,A.Yang,andM.Lučić. AdvancingthefrontierofvideounderstandingwithGemini2.5,\n2025. URL https://developers.googleblog.com/en/gemini-2-5-video-understan\nding/.\nY. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, et al. Constitutional ai: Harmlessness from ai\nfeedback, 2022. URL https://arxiv.org/abs/2212.08073.\nM. Balunović, J. Dekoninck, I. Petrov, N. Jovanović, and M. Vechev. Matharena: Evaluating llms on\nuncontaminated math competitions, 2025. URL https://arxiv.org/abs/2505.23281.\nP. Barham, A. Chowdhery, J. Dean, S. Ghemawat, S. Hand, D. Hurt, M. Isard, H. Lim, R. Pang, S. Roy,\net al. Pathways: Asynchronous distributed dataflow for ml. Proceedings of Machine Learning and\nSystems,4:430–449,2022. URLhttps://proceedings.mlr.press/v162/barham22a.html.\nA. Beutel, K. Xiao, J. Heidecke, and L. Weng. Diverse and effective red teaming with auto-generated\nrewards and multi-step reinforcement learning, 2024. URL https://arxiv.org/abs/2412.1\n8693.\nS. Biderman, H. Schoelkopf, Q. G. Anthony, H. Bradley, K. O’Brien, et al. Pythia: A suite for analyzing\nlargelanguagemodelsacrosstrainingandscaling.InProceedingsofthe40thInternationalConference\non Machine Learning, 2023. URL https://proceedings.mlr.press/v202/biderman23a.h\ntml.\nN.Carlini,D.Ippolito,M.Jagielski,K.Lee,F.Tramer,andC.Zhang. Quantifyingmemorizationacross\nneural language models. In 2022 IEEE Symposium on Security and Privacy (SP), pages 1113–1130,\n2022. URL https://arxiv.org/abs/2202.07646.\nW.-L. Chiang, L. Zheng, Y. Sheng, A. N. Angelopoulos, T. Li, D. Li, B. Zhu, H. Zhang, M. Jordan, J. E.\nGonzalez, et al. Chatbot arena: An open platform for evaluating llms by human preference. In\nForty-first International Conference on Machine Learning, 2024. URL https://arxiv.org/abs/\n2306.05685.\nA. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung,\nC. Sutton, S. Gehrmann, et al. PaLM: Scaling language modeling with pathways. arXiv preprint\narXiv:2204.02311, 2022. URL https://arxiv.org/abs/2204.02311.\nN. Chowdhury, J. Aung, C. J. Shern, O. Jaffe, D. Sherburn, G. Starace, E. Mays, R. Dias, M. Aljubeh,\nM. Glaese, C. E. Jimenez, J. Yang, L. Ho, T. Patwardhan, K. Liu, and A. Madry. Introducing SWE-\nbench verified, 2024. URL https://openai.com/index/introducing-swe-bench-verif\nied/.\n40\n\n--- PAGE 41 ---"
    },
    {
      "chunk_id": 39,
      "content": "--- PAGE 41 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nA. Clark, D. de las Casas, A. Guy, A. Mensch, M. Paganini, J. Hoffmann, B. Damoc, B. Hechtman,\nT. Cai, S. Borgeaud, G. van den Driessche, E. Rutherford, T. Hennigan, M. Johnson, K. Millican,\nA. Cassirer, C. Jones, E. Buchatskaya, D. Budden, L. Sifre, S. Osindero, O. Vinyals, J. Rae, E. Elsen,\nK. Kavukcuoglu, and K. Simonyan. Unified scaling laws for routed language models, 2022. URL\n\"https://arxiv.org/abs/2202.01169\".\nCodeGemma Team, H. Zhao, J. Hui, J. Howland, N. Nguyen, S. Zuo, A. Hu, C. A. Choquette-Choo,\nJ. Shen, J. Kelley, K. Bansal, L. Vilnis, M. Wirth, P. Michel, P. Choy, P. Joshi, R. Kumar, S. Hashmi,\nS. Agrawal, Z. Gong, J. Fine, T. Warkentin, A. J. Hartman, B. Ni, K. Korevec, K. Schaefer, and\nS. Huffman. CodeGemma: Open Code Models Based on Gemma, 2024. URL https://arxiv.or\ng/abs/2406.11409.\nA. Conneau, M. Ma, S. Khanuja, Y. Zhang, V. Axelrod, S. Dalmia, J. Riesa, C. Rivera, and A. Bapna.\nFleurs: Few-shot learning evaluation of universal representations of speech. In 2022 IEEE Spoken\nLanguage Technology Workshop (SLT), pages 798–805. IEEE, 2023.\nM. Dehghani, J. Djolonga, B. Mustafa, P. Padlewski, J. Heek, J. Gilmer, A. P. Steiner, M. Caron,\nR. Geirhos, I. Alabdulmohsin, et al. Scaling vision transformers to 22 billion parameters. In\nInternational Conference on Machine Learning, pages 7480–7512. PMLR, 2023. URL https:\n//proceedings.mlr.press/v202/dehghani23a/dehghani23a.pdf.\nT. Doshi. Build rich, interactive web apps with an updated Gemini 2.5 Pro, 2025a. URL https:\n//blog.google/products/gemini/gemini-2-5-pro-updates/.\nT. Doshi. Gemini 2.5: Our most intelligent models are getting even better, 2025b. URL https:\n//blog.google/technology/google-deepmind/google-gemini-updates-io-2025/.\nN. Du, Y. Huang, A. M. Dai, S. Tong, D. Lepikhin, Y. Xu, M. Krikun, Y. Zhou, A. W. Yu, O. Fi-\nrat, et al. GLaM: Efficient scaling of language models with mixture-of-experts. arXiv preprint\narXiv:2112.06905, 2021. URL https://arxiv.org/abs/2112.06905.\nW. Fedus, B. Zoph, and N. Shazeer. Switch transformers: Scaling to trillion parameter models with\nsimple and efficient sparsity. arXiv preprint arXiv:2101.03961, 2021. URL https://arxiv.org/\nabs/2101.03961.\nC. Fu, Y. Dai, Y. Luo, L. Li, S. Ren, R. Zhang, Z. Wang, C. Zhou, Y. Shen, M. Zhang, et al. Video-mme:\nThe first-ever comprehensive evaluation benchmark of multi-modal llms in video analysis. In\nProceedings of the Computer Vision and Pattern Recognition Conference, pages 24108–24118, 2025.\nURL https://openaccess.thecvf.com/content/CVPR2024/html/Fu_Video-MME_The\n_First-Ever_Comprehensive_Evaluation_Benchmark_of_Multi-Modal_LLMs_in_C\nVPR_2024_paper.html.\nP. Gauthier. Aider Polyglot Coding Leaderboard, 2025. URL https://aider.chat/docs/leader\nboards/.\nGemini Team. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.\narXiv preprint arXiv:2403.05530, 2024. URL https://arxiv.org/abs/2403.05530.\nGemini Team, Google. Gemini Deep Research, 2024. URL https://gemini.google/overview\n/deep-research/.\nGemma Team. Gemma: Open Models Based on Gemini Research and Technology, 2024. URL\nhttps://arxiv.org/abs/2403.08295.\n41\n\n--- PAGE 42 ---"
    },
    {
      "chunk_id": 40,
      "content": "--- PAGE 42 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nO. Goldman, U. Shaham, D. Malkin, S. Eiger, A. Hassidim, Y. Matias, J. Maynez, A. M. Gilady, J. Riesa,\nS. Rijhwani, L. Rimell, I. Szpektor, R. Tsarfaty, and M. Eyal. Eclektic: a novel challenge set for\nevaluation of cross-lingual knowledge transfer, 2025. URL https://arxiv.org/abs/2502.2\n1228.\nGoogle DeepMind. Frontier safety framework, February 2025a. URL https://deepmind.googl\ne/discover/governance/frontier-safety-framework/.\nGoogle DeepMind. Gemini 2.0 Flash-Lite, 2025b. URL https://deepmind.google/models/gem\nini/flash-lite/.\nA. Grattafiori, A. Dubey, A. Jauhri, A. Pandey, A. Kadian, et al. The Llama 3 Herd of Models, 2024.\nURL https://arxiv.org/abs/2407.21783.\nD. Hassabis. Our vision for building a universal AI assistant, 2025. URL https://blog.google/\ntechnology/google-deepmind/gemini-universal-ai-assistant/.\nG. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network, 2015. URL\nhttps://arxiv.org/abs/1503.02531.\nK.Hu,P.Wu,F.Pu,W.Xiao,Y.Zhang,X.Yue,B.Li,andZ.Liu. Video-mmmu: Evaluatingknowledge\nacquisition from multi-discipline professional videos, 2025. URL https://arxiv.org/abs/25\n01.13826.\nS.Hughes,M.Bae,andM.Li. VectaraHallucinationLeaderboard,nov2023. URLhttps://github\n.com/vectara/hallucination-leaderboard.\nD. Ippolito, F. Tramer, M. Nasr, C. Zhang, M. Jagielski, K. Lee, C. A. Choquette-Choo, and N. Carlini.\nPreventing verbatim memorization in language models gives a false sense of privacy, 2022. URL\nhttps://arxiv.org/abs/2210.17546.\nA. Jacovi, A. Wang, C. Alberti, C. Tao, J. Lipovetz, K. Olszewska, L. Haas, M. Liu, N. Keating,\nA.Bloniarz,C.Saroufim,C.Fry,D.Marcus,D.Kukliansky,G.S.Tomar,J.Swirhun,J.Xing,L.Wang,\nM. Gurumurthy, M. Aaron, M. Ambar, R. Fellinger, R. Wang, R. Sims, Z. Zhang, S. Goldshtein, and\nD. Das. Facts grounding leaderboard. https://www.kaggle.com/benchmarks/google/fac\nts-grounding, 2024. Google Deepmind, Google Research, Google Cloud, Kaggle.\nA.Jacovi,A.Wang,C.Alberti,C.Tao,J.Lipovetz,K.Olszewska,L.Haas,M.Liu,N.Keating,A.Bloniarz,\netal. Thefactsgroundingleaderboard: Benchmarkingllms’abilitytogroundresponsestolong-form\ninput. arXiv preprint arXiv:2501.03200, 2025. URL https://arxiv.org/abs/2501.03200.\nN. Jain, K. Han, A. Gu, W.-D. Li, F. Yan, T. Zhang, S. Wang, A. Solar-Lezama, K. Sen, and I. Stoica.\nLivecodebench: Holistic and contamination free evaluation of large language models for code,\n2024. URL https://arxiv.org/abs/2403.07974.\nA. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary, C. Bamford, D. S. Chaplot, D. d. l. Casas,\nE. B. Hanna, F. Bressand, et al. Mixtral of experts. arXiv preprint arXiv:2401.04088, 2024. URL\nhttps://arxiv.org/abs/2401.04088.\nC. E. Jimenez, J. Yang, A. Wettig, S. Yao, K. Pei, O. Press, and K. R. Narasimhan. SWE-bench: Can\nlanguage models resolve real-world github issues? In The Twelfth International Conference on\nLearning Representations, 2024. URL https://openreview.net/forum?id=VTF8yNQM66.\n42\n\n--- PAGE 43 ---"
    },
    {
      "chunk_id": 41,
      "content": "--- PAGE 43 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nK. Kampf and N. Brichtova. Experiment with Gemini 2.0 Flash native image generation, 2025. URL\nhttps://developers.googleblog.com/en/experiment-with-gemini-20-flash-nat\nive-image-generation/.\nK. Kavukcuoglu. Gemini 2.0 is now available to everyone, 2025. URL https://blog.google/te\nchnology/google-deepmind/gemini-model-updates-february-2025.\nL. Kilpatrick. Gemini 2.5 Pro Preview: even better coding performance, 2025. URL https://deve\nlopers.googleblog.com/en/gemini-2-5-pro-io-improved-coding-performance.\nS. Kudugunta, I. Caswell, B. Zhang, X. Garcia, C. A. Choquette-Choo, K. Lee, D. Xin, A. Kusupati,\nR.Stella,A.Bapna,andO.Firat. MADLAD-400: AMultilingualAndDocument-LevelLargeAudited\nDataset, 2023. URL https://arxiv.org/abs/2309.04662.\nJ. M. Laurent, J. D. Janizek, M. Ruzo, M. M. Hinks, M. J. Hammerling, S. Narayanan, et al. LAB-\nBench: Measuring capabilities of language models for biology research, 2024. URL https:\n//arxiv.org/abs/2407.10362.\nLearnLM Team. Evaluating Gemini in an Arena for Learning, 2025. URL https://goo.gle/Lear\nnLM-May25.\nJ. Lee, A. Chen, Z. Dai, D. Dua, D. S. Sachan, M. Boratko, Y. Luan, S. M. Arnold, V. Perot, S. Dalmia,\net al. Can long-context language models subsume retrieval, rag, sql, and more? arXiv preprint\narXiv:2406.13121, 2024. URL https://arxiv.org/abs/2406.13121.\nJ. Lei, T. L. Berg, and M. Bansal. Detecting moments and highlights in videos via natural language\nqueries. Advances in Neural Information Processing Systems, 34:11846–11858, 2021.\nD. Lepikhin, H. Lee, Y. Xu, D. Chen, O. Firat, Y. Huang, M. Krikun, N. Shazeer, and Z. Chen. GShard:\nScaling giant models with conditional computation and automatic sharding. In International\nConference on Learning Representations, 2020. URL https://openreview.net/forum?id=qr\nwe7XHTmYb.\nN. Li, A. Pan, A. Gopal, S. Yue, D. Berrios, A. Gatti, et al. The WMDP benchmark: Measuring and\nreducing malicious use with unlearning, 2024. URL https://arxiv.org/abs/2403.03218.\nL. Liu, X. Liu, J. Gao, W. Chen, and J. Han. Understanding the difficulty of training transformers.\narXiv preprint arXiv:2004.08249, 2020. URL https://arxiv.org/abs/2004.08249.\nLMArena Team. Webdev arena, 2025. URL https://web.lmarena.ai/leaderboard.\nS. B. Mallick and L. Kilpatrick. Gemini 2.0: Flash, Flash-Lite and Pro, 2025. URL https://develo\npers.googleblog.com/en/gemini-2-family-expands/.\nA. Mehrotra, M. Zampetakis, P. Kassianik, B. Nelson, H. Anderson, Y. Singer, and A. Karbasi. Tree of\nattacks: Jailbreaking black-box llms automatically, 2024. URL https://arxiv.org/abs/2312\n.02119.\nI.Molybog,P.Albert,M.Chen,Z.DeVito,D.Esiobu,N.Goyal,P.Koura,S.Narang,A.Poulton,R.Silva,\netal. Atheoryonadaminstabilityinlarge-scalemachinelearning. arXivpreprintarXiv:2304.09871,\n2023. URL https://arxiv.org/abs/2304.09871.\nA.Nagrani,S.Menon,A.Iscen,S.Buch,R.Mehran,N.Jha,A.Hauth,Y.Zhu,C.Vondrick,M.Sirotenko,\nC. Schmid, and T. Weyand. Minerva: Evaluating complex video reasoning, 2025a. URL https:\n//arxiv.org/abs/2505.00681.\n43\n\n--- PAGE 44 ---"
    },
    {
      "chunk_id": 42,
      "content": "--- PAGE 44 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nA.Nagrani,M.Zhang,R.Mehran,R.Hornung,N.B.Gundavarapu,N.Jha,A.Myers,X.Zhou,B.Gong,\nC. Schmid, M. Sirotenko, Y. Zhu, and T. Weyand. Neptune: The long orbit to benchmarking long\nvideo understanding, 2025b. URL https://arxiv.org/abs/2412.09582.\nM.Nasr,N.Carlini,J.Hayase,M.Jagielski,A.F.Cooper,D.Ippolito,C.A.Choquette-Choo,E.Wallace,\nF. Tramèr, and K. Lee. Scalable extraction of training data from (production) language models,\n2023. URL https://arxiv.org/abs/2311.17035.\nP. Padlewski, M. Bain, M. Henderson, Z. Zhu, N. Relan, H. Pham, D. Ong, K. Aleksiev, A. Ormazabal,\nS.Phua,E.Yeo,E.Lamprecht,Q.Liu,Y.Wang,E.Chen,D.Fu,L.Li,C.Zheng,C.deMassond’Autume,\nD. Yogatama, M. Artetxe, and Y. Tay. Vibe-eval: A hard evaluation suite for measuring progress of\nmultimodal language models, 2024. URL https://arxiv.org/abs/2405.02287.\nA.Pappu,B.Porter,I.Shumailov,andJ.Hayes. MeasuringmemorizationinRLHFforcodecompletion.\narXiv preprint arXiv:2406.11715, 2024. URL https://arxiv.org/abs/2406.11715.\nV.Patraucean,L.Smaira,A.Gupta,A.Recasens,L.Markeeva,D.Banarse,S.Koppula,M.Malinowski,\nY. Yang, C. Doersch, et al. Perception test: A diagnostic benchmark for multimodal video models.\nAdvances in Neural Information Processing Systems, 36:42748–42761, 2023.\nE. Perez, S. Huang, F. Song, T. Cai, R. Ring, J. Aslanides, A. Glaese, N. McAleese, and G. Irving. Red\nteaminglanguagemodelswithlanguagemodels,2022. URLhttps://arxiv.org/abs/2202.0\n3286.\nL. Phan et al. Humanity’s last exam, 2025. URL https://arxiv.org/abs/2501.14249.\nM.Phuong,M.Aitchison,E.Catt,S.Cogan,A.Kaskasoli,V.Krakovna,D.Lindner,M.Rahtz,Y.Assael,\nS. Hodkinson, et al. Evaluating frontier models for dangerous capabilities, 2024. URL https:\n//arxiv.org/abs/2403.13793.\nM. Phuong, R. S. Zimmermann, Z. Wang, D. Lindner, V. Krakovna, S. Cogan, A. Dafoe, L. Ho, and\nR. Shah. Evaluating frontier models for stealth and situational awareness, 2025. URL https:\n//arxiv.org/abs/2505.01420.\nS. Pichai. Google I/O 2025: From research to reality, 2025. URL https://blog.google/techno\nlogy/ai/io-2025-keynote/.\nC. Plizzari, A. Tonioni, Y. Xian, A. Kulshrestha, and F. Tombari. Omnia de egotempo: Benchmarking\ntemporal understanding of multi-modal llms in egocentric videos. In Proceedings of the Computer\nVision and Pattern Recognition Conference, pages 24129–24138, 2025.\nD.Rein,B.L.Hou,A.C.Stickland,J.Petty,R.Y.Pang,J.Dirani,J.Michael,andS.R.Bowman. Gqqa:\nA graduate-level google-proof q&a benchmark. In First Conference on Language Modeling, 2024.\nC. Riquelme, J. Puigcerver, B. Mustafa, M. Neumann, R. Jenatton, A. S. Pinto, D. Keysers, and\nN.Houlsby. Scalingvisionwithsparsemixtureofexperts,2021. URLhttps://arxiv.org/abs/\n2106.05974.\nJ.Roberts, M.R. Taesiri, A.Sharma, A.Gupta, S.Roberts, I. Croitoru, S.-V.Bogolin, J. Tang, F.Langer,\nV. Raina, et al. ZeroBench: An impossible visual benchmark for contemporary large multimodal\nmodels. arXiv preprint arXiv:2502.09696, 2025.\nM. Rodriguez, R. A. Popa, L. Liang, A. Wang, M. Rahtz, A. Kaskasoli, A. Dafoe, and F. Flynn. A\nframework for evaluating emerging cyberattack capabilities of AI, 2025. URL https://arxiv.\norg/abs/2503.11917.\n44\n\n--- PAGE 45 ---"
    },
    {
      "chunk_id": 43,
      "content": "--- PAGE 45 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nS. Roller, S. Sukhbaatar, J. Weston, et al. Hash layers for large sparse models. Advances in Neural\nInformation Processing Systems, 34:17555–17566, 2021. URL https://proceedings.neurips.\ncc/paper/2021/file/883e881bc596359e0c5112411858a74b-Paper.pdf.\nM. Samvelyan, S. C. Raparthy, A. Lupu, E. Hambro, A. H. Markosyan, M. Bhatt, Y. Mao, M. Jiang,\nJ. Parker-Holder, J. Foerster, T. Rocktäschel, and R. Raileanu. Rainbow teaming: Open-ended\ngeneration of diverse adversarial prompts, 2024. URL https://arxiv.org/abs/2402.16822.\nR. Shah, A. Irpan, A. M. Turner, A. Wang, A. Conmy, D. Lindner, J. Brown-Cohen, L. Ho, N. Nanda,\nR. A. Popa, R. Jain, R. Greig, S. Albanie, S. Emmons, S. Farquhar, S. Krier, S. Rajamanoharan,\nS. Bridgers, T. Ijitoye, T. Everitt, V. Krakovna, V. Varma, V. Mikulik, Z. Kenton, D. Orr, S. Legg,\nN. Goodman, A. Dafoe, F. Flynn, and A. Dragan. An approach to technical agi safety and security,\n2025. URL https://arxiv.org/abs/2504.01849.\nD.Sharon. UploadandedityourimagesdirectlyintheGeminiapp,2025. URLhttps://blog.goo\ngle/products/gemini/image-editing/.\nN. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, and J. Dean. Outrageously large\nneural networks: The sparsely-gated mixture-of-experts layer. In ICLR (Poster). OpenReview.net,\n2017. URL https://arxiv.org/abs/1701.06538.\nC. Shi, S. Lin, S. Song, J. Hayes, I. Shumailov, I. Yona, J. Pluto, A. Pappu, C. A. Choquette-Choo,\nM. Nasr, C. Sitawarin, G. Gibson, A. Terzis, and J. F. Flynn. Lessons from defending gemini against\nindirect prompt injections, 2025. URL https://arxiv.org/abs/2505.14534.\nS. Singh, A. Romanou, C. Fourrier, D. I. Adelani, J. G. Ngui, D. Vila-Suero, P. Limkonchotiwat,\nK. Marchisio, W. Q. Leong, Y. Susanto, R. Ng, S. Longpre, W.-Y. Ko, M. Smith, A. Bosselut, A. Oh,\nA. F. T. Martins, L. Choshen, D. Ippolito, E. Ferrante, M. Fadaee, B. Ermis, and S. Hooker. Global\nmmlu: Understanding and addressing cultural and linguistic biases in multilingual evaluation,\n2024. URL https://arxiv.org/abs/2412.03304.\nR. Stein. Expanding AI Overviews and introducing AI Mode, 2025. URL https://blog.google/\nproducts/search/ai-mode-search.\nI.Tolstikhin,N.Houlsby,A.Kolesnikov,L.Beyer,X.Zhai,T.Unterthiner,J.Yung,A.Steiner,D.Keysers,\nJ. Uszkoreit, M. Lucic, and A. Dosovitskiy. Mlp-mixer: An all-mlp architecture for vision, 2021.\nA. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and I. Polosukhin.\nAttention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vish-\nwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30.\nCurran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper_files/pap\ner/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.\nK. Vodrahalli, S. Ontanon, N. Tripuraneni, K. Xu, S. Jain, R. Shivanna, J. Hui, N. Dikkala, M. Kazemi,\nB. Fatemi, et al. Michelangelo: Long context evaluations beyond haystacks via latent structure\nqueries. arXiv preprint arXiv:2409.12640, 2024. URL https://arxiv.org/abs/2409.12640.\nB. Wang. NotebookLM now lets you listen to a conversation about your sources , 2024. URL\nhttps://blog.google/technology/ai/notebooklm-audio-overviews.\nC. Wang, A. Wu, and J. Pino. Covost 2: A massively multilingual speech-to-text translation corpus,\n2020.\n45\n\n--- PAGE 46 ---"
    },
    {
      "chunk_id": 44,
      "content": "--- PAGE 46 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nW. Wang, Z. He, W. Hong, Y. Cheng, X. Zhang, J. Qi, X. Gu, S. Huang, B. Xu, Y. Dong, M. Ding,\nand J. Tang. Lvbench: An extreme long video understanding benchmark, 2024. URL https:\n//arxiv.org/abs/2406.08035.\nX. Wang, J. Wu, J. Chen, L. Li, Y.-F. Wang, and W. Y. Wang. Vatex: A large-scale, high-quality\nmultilingual dataset for video-and-language research. In Proceedings of the IEEE/CVF international\nconference on computer vision, pages 4581–4591, 2019.\nJ.Wei,K.Nguyen,H.W.Chung,Y.J.Jiao,S.Papay,A.Glaese,J.Schulman,andW.Fedus. Measuring\nshort-form factuality in large language models. arXiv preprint arXiv:2411.04368, 2024. URL\nhttps://arxiv.org/abs/2411.04368.\nL. Weidinger, J. Barnhart, J. Brennan, C. Butterfield, S. Young, W. Hawkins, et al. Holistic safety and\nresponsibilityevaluationsofadvancedaimodels,2024. URLhttps://arxiv.org/abs/2404.1\n4068.\nH. Wijk, T. Lin, J. Becker, S. Jawhar, N. Parikh, T. Broadley, L. Chan, M. Chen, J. Clymer, J. Dhyani,\net al. RE-Bench: Evaluating frontier ai r&d capabilities of language model agents against human\nexperts, 2025. URL https://arxiv.org/abs/2411.15114.\nM. Wortsman, P. J. Liu, L. Xiao, K. Everett, A. Alemi, B. Adlam, J. D. Co-Reyes, I. Gur, A. Kumar,\nR. Novak, et al. Small-scale proxies for large-scale transformer training instabilities. arXiv preprint\narXiv:2309.14322, 2023. URL https://arxiv.org/abs/2309.14322.\nJ. Yang, A. Prabhakar, K. Narasimhan, and S. Yao. Intercode: Standardizing and benchmarking\ninteractivecodingwithexecutionfeedback,2023. URLhttps://arxiv.org/abs/2306.14898.\nZ.Yu,D.Xu,J.Yu,T.Yu,Z.Zhao,Y.Zhuang,andD.Tao. ActivityNet-QA:Adatasetforunderstanding\ncomplex web videos via question answering. In AAAI, 2019.\nX. Yue, Y. Ni, K. Zhang, T. Zheng, R. Liu, G. Zhang, S. Stevens, D. Jiang, W. Ren, Y. Sun, et al.\nMmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert\nagi. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages\n9556–9567, 2024.\nZerokid. Pokemon Red Version - Guide and Walkthrough (GB), 2024. URL https://gamefaqs.g\namespot.com/gameboy/367023-Pokémon-red-version/faqs/64175.\nS.Zhai,T.Likhomanenko,E.Littwin,D.Busbridge,J.Ramapuram,Y.Zhang,J.Gu,andJ.M.Susskind.\nStabilizingtransformertrainingbypreventingattentionentropycollapse.InInternationalConference\non Machine Learning, pages 40770–40803. PMLR, 2023. URL https://proceedings.mlr.pr\ness/v202/zhai23a/zhai23a.pdf.\nJ. Zhang. Gemini Plays Pokemon Twitch Stream, 2025. URL https://www.twitch.tv/gemini\n_plays_pokemon/about.\nS. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin, et al.\nOpt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068, 2022. URL\nhttps://arxiv.org/abs/2205.01068.\nL. Zhou, C. Xu, and J. J. Corso. Towards automatic learning of procedures from web instructional\nvideos. In AAAI Conference on Artificial Intelligence, pages 7590–7598, 2018. URL https://www.\naaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17344.\n46\n\n--- PAGE 47 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n7. Contributors and Acknowledgments\nContributors KristenChiafullo KashyapKolipaka DavidParkinson\nGheorgheComanici AndreElisseeff JasonChang SwaroopRamaswamy\nEricBieber NilpaJha EugenVušak JeromeConnor\nMikeSchaekermann PrateekKolhar SrinivasanVenkatachary SoheilHassasYeganeh\nIcePasupat LeonardBerrada ShadiNoghabi SnchitGrover\nNoveenSachdeva FrankDing TarunBharti GeorgeKenwright\nInderjitDhillon XianceSi YounghoonJun LuboLitchev\nMarcelBlistein ShresthaBasuMallick AleksandrZaks ChrisApps\nOriRam FranzOch SimonGreen AlexTomala\nDanZhang SofiaErell JeshwanthChallagundla FelixHalim\nEvanRosen EricNi WilliamWong AlexCastro-Ros\nLukeMarris TejasiLatkar MuqtharMohammad ZefeiLi\nSamPetulla SherryYang DeanHirsch AnudhyanBoral\nColinGaffney PetarSirkovic YongCheng PaulineSho\nAsafAharoni ZiqiangFeng IftekharNaim MichalYarom\nNathanLintz RobertLeland LevProleev EricMalmi\nTiagoCardalPais RachelHornung DamienVincent DavidKlinghoffer\nHenrikJacobsson GangWu AayushSingh RebeccaLin\nIdanSzpektor CharlesBlundell MaximKrikun AlanAnsell\nNan-JiangJiang HamidrezaAlvari DilipKrishnan PradeepKumarS\nKrishnaHaridasan Po-SenHuang ZoubinGhahramani ShubinZhao\nAhmedOmran CathyYip AvielAtias SiqiZuo\nNikunjSaunshi SanjaDeur RajeevAggarwal AdamSantoro\nDaraBahri LiLiu ChristoKirov Heng-TzeCheng\nGauravMishra GabrielaSurita DimitriosVytiniotis SolomonDemmessie\nEricChu PabloDuque ChristyKoh YuchiLiu\nTobyBoyd DimaDamen AlexandraChronopoulou NicoleBrichtova\nBradHekman JohnsonJia PawanDogra AllieCulp\nAaronParisi ArthurGuez Vlad-DoruIon NathanielBraun\nChaoyiZhang MarkusMircea GladysTyen DanGraur\nKornraphopKawintiranon AnimeshSinha JasonLee WillNg\nTaniaBedrax-Weiss AlbertoMagni FelixWeissenberger NikhilMehta\nOliverWang PawełStradomski TrevorStrohman AaronPhillips\nYaXu TalMarian AshwinBalakrishna PatrikSundberg\nOlliePurkiss VladoGalić JackRae VarunGodbole\nUriMendlovic WenhuChen MarkoVelic FangyuLiu\nIlaïDeutel HishamHusain RaouldeLiedekerke YashKatariya\nNamNguyen AchintyaSinghal OdedElyada DavidRim\nAdamLangley DominikGrewe WentaoYuan MojtabaSeyedhosseini\nFlipKorn François-XavierAubet CanoeeLiu SeanAmmirati\nLuciaRossazza ShuangSong LiorShani JonasValfridsson\nAlexandreRamé LorenzoBlanco SergeyKishchenko MahanMalihi\nSagarWaghmare LelandRechis BeaAlessio TimothyKnight\nHelenMiller LewisHo YandongLi AndeepToor\nNathanByrd RichMunoz RichardSong ThomasLampe\nAshrithSheshan KelvinZheng SamKwei AbeIttycheriah\nRaiaHadsell JessicaHamrick OrionJankowski LewisChiang\nSangnieBhardwaj KevinMather AneeshPappu ChakYeung\nPawelJanus HagaiTaitelbaum YouheiNamiki AlexandreFréchette\nTeroRissa ElizaRutherford YenaiMa JinmengRao\nDanHorgan YunLei NileshTripuraneni HuishengWang\nAlvinAbdagic KuangyuanChen ColinCherry HimanshuSrivastava\nLiorBelenki AnandShukla MarissaIkonomidis RichardZhang\nJamesAllingham EricaMoreira Yu-ChengLing RockyRhodes\nAnimaSingh EricDoi ColinJi ArielBrand\nTheoGuidroz BerivanIsik BekaWestberg DeanWeesner\nSrivatsanSrinivasan NirShabat AurielWright IlyaFigotin\nHermanSchmit DominikaRogozińska DaYu FelixGimeno\n47\n\n--- PAGE 48 ---"
    },
    {
      "chunk_id": 45,
      "content": "--- PAGE 48 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nRachanaFellinger ArunNair JaumeSanchezElias XinyangGeng\nPierreMarcenac ArtemShtefan AbhirutGupta YeqingLi\nJoséLeal MauraO’Brien ManishReddyVuyyuru RolfJagerman\nEyalMarcus ManuAgarwal FredAlcober ChaoJia\nVictorCotruta SahityaPotluri TongZhou NadavOlmert\nRodrigoCabrera SiddharthGoyal KaiyangJi DavidSharon\nSherylLuo AmitJhindal FlorianHartmann MatthewMauger\nDanGarrette SakshamThakur SubhaPuttagunta SandeepMariserla\nVeraAxelrod YuryStuken HugoSong HongxuMa\nSorinBaltateanu JamesLyon EhsanAmid MeghaMohabey\nDavidBarker KristinaToutanova AncaStefanoiu KyuyeunKim\nDongkaiChen FangxiaoyuFeng AndrewLee AlekAndreev\nHoriaToma AustinWu PaulPucciarelli ScottPollom\nBenIngram BenHorn EmmaWang JulietteLove\nJasonRiesa AlekWang AmitRaul VihanJain\nChinmayKulkarni AlexCullum SlavPetrov PriyankaAgrawal\nYujingZhang GabeTaubman IsaacTian YannickSchroecker\nHongbinLiu DishaShrivastava ValentinAnklin AlisaFortin\nChaoWang ChongyangShi NanaNti ManfredWarmuth\nMartinPolacek HamishTomlinson VictorGomes JiLiu\nWillWu RomaPatel MaxSchumacher AndrewLeach\nKaiHui TaoTu GraceVesom IrinaBlok\nAdrianNReyes AdaMaksutajOflazer AlexPanagopoulos GaneshPoomalGirirajan\nYiSu FrancescoPongetti KonstantinosBousmalis RoeeAharoni\nMeganBarnes MingyaoYang DanielAndor BenignoUria\nIshaanMalhi AdrienAliTaïga JoshJacob AndreiSozanschi\nAnfalSiddiqui VincentPerot YuanZhang DanGoldberg\nQixuanFeng NuoWangPierse BillRosgen LucianIonita\nMihaiDamaschin FengHan MatijaKecman MarcoTulioRibeiro\nDanielePighin YoelDrori MatthewTung MartinZlocha\nAndreasSteiner IñakiIturrate AlexandraBelias VighneshBirodkar\nSamuelYang AyanChakrabarti NoahGoodman SamiLachgar\nRamyaSreeBoppana LeggYeung PaulCovington LiangzheYuan\nSimeonIvanov DaveDopson BrianWieder HimadriChoudhury\nArunKandoor Yi-tingChen NikitaSaxena MattGinsberg\nAdityaShah ApoorvKulshreshtha ElnazDavoodi FeiZheng\nAsierMujika TongfeiGuo MuhuanHuang GregoryDibb\nDaHuang PhilipPham SharathMaddineni EmilyGraves\nChristopherA. TalSchuster VincentRoulet SwachhandLokhande\nChoquette-Choo JunquanChen FolawiyoCampbell-Ajala GabrielRasskin\nMohakPatel AlexPolozov PierGiuseppeSessa George-CristianMuraru\nTianheYu JinweiXing Xintian(Cindy)Wu CorbinQuick\nToniCreswell HuanjieZhou GuangdaLai SandeepTata\nJerry(Chun-Ting)Liu PraneethKacham PaulCollins PierreSermanet\nCatarinaBarros DoronKukliansky AlexHaig AdityaChawla\nYasamanRazeghi AntoineMiech VytenisSakenas ItayKaro\nAurkoRoy SergeyYaroshenko XiaoweiXu YanWang\nPhilCulliton EdChi MarissaGiustina SusanZhang\nBinbinXiong SholtoDouglas LaurentElShafey OrgadKeller\nJiaqiPan HongliangFei PichiCharoenpanit AncaDragan\nThomasStrohmann MathieuBlondel ShefaliGarg GuolongSu\nTollyPowell PreethiMyla JoshuaAinslie IanChou\nBabiSeal LiorMadmoni BooneSeverson XiLiu\nDougDeCarlo XingWu MontseGonzalezArenas YiqingTao\nPranavShyam DanielKeysers ShreyaPathak ShruthiPrabhakara\nKaanKatircioglu KristianKjems SujeeRajayogam MarcWilson\nXuezhiWang IsabelaAlbuquerque JieFeng RuiboLiu\nCassidyHardin LijunYu MichielBakker ShiboWang\nImmanuelOdisho JoelD’sa ShengLi GeorgieEvans\nJosefBroder MichellePlantan NevanWichers DavidDu\nOscarChang VladIonescu JamieRogers AlfonsoCastaño\n48\n\n--- PAGE 49 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGautamPrasad XuanYang ChiyuanZhang ShuangLiu\nMonaElMahdy DaleWebster SanderDieleman SaarthakKhanna\nSebastianGerlach AliElqursh ThomasJimma AdityaPandey\nMachelReid AedanPope AndreyRyabtsev SiobhanMcloughlin\nJarrodKahn GeorgesRotival SiddharthaBrahma QiujiaLi\nAmirZait DavidRaposo DavidSteiner SamHaves\nThanumalayan WanzhengZhu DayouDu AllanZhou\nSankaranarayanaPillai JeffDean AnteŽužul ElenaBuchatskaya\nThatcherUlrich SamiAlabed MislavŽanić IsabelLeal\nGuanyuWang DustinTran MukundRaghavachari PeterdeBoursac\nJanWassenberg ArushiGupta WilliGierke NamiAkazawa\nEfratFarkash ZachGleicher ZeyuZheng NinaAnderson\nKiranYalasangi JessicaAustin DessiePetrova TerryChen\nCongchaoWang EdouardRosseel YannDauphin KrishnaSomandepalli\nMariaBauza MeghUmekar YuchuanLiu ChenLiang\nSimonBucher DipanjanDas IdoKessler SheelaGoenka\nTingLiu YinghaoSun StevenHand StephanieWinkler\nJunYan KaiChen ChrisDuvarney AlexanderGrushetsky\nGaryLeung KarolisMisiunas SeokhwanKim YifanDing\nVikasSindhwani XiangZhou HyoLee JamieSmith\nParkerBarnes YixianDi LéonardHussenot FanYe\nAviSingh AlyssaLoo JeffreyHui JordiPont-Tuset\nIvanJurin JoshNewlan JoshSmith EricLi\nJichuanChang BoLi DeepaliJain RuichaoLi\nNiketKumarBhumihar VinayRamasesh JiaweiXia TomerGolany\nSivanEiger YingXu GauravSinghTomar DawidWegner\nGuiCitovsky AlexChen KeyvanAmiri TaoJiang\nBenWithbroe SudeepGandhe DuPhan OmerBarak\nZhangLi RaduSoricut FabianFuchs YuanShangguan\nSiyangXue NikitaGupta TobiasWeyand EszterVértes\nNiccolòDalSanto ShuguangHu NenadTomasev ReneeWong\nGeorgiStoyanov SeliemEl-Sayed AlexandraCordell JörgBornschein\nYvesRaimond XavierGarcia XinLiu AlexTudor\nStevenZheng IdanBrusilovsky JonathanMallinson MicheleBevilacqua\nYilinGao Pu-ChinChen PankajJoshi TomSchaul\nVítListík AndrewBolt AndyCrawford AnkitSinghRawat\nSławekKwasiborski LuHuang ArunSuggala YangZhao\nRachelSaputro AlexGurney SteveChien KyriakosAxiotis\nAdnanOzturel ZhiyingZhang NickFernando LeiMeng\nGaneshMallya AlexanderPritzel MariellaSanchez-Vargas CoryMcLean\nKushalMajmundar JarekWilkiewicz DuncanWilliams JonathanLai\nRossWest BryanSeybold PhilCrone JenniferBeattie\nPaulCaron BhargavKanagal XiyangLuo NateKushman\nJinliangWei Shamanna IgorKarpov YaxinLiu\nLluisCastrejon FelixFischer JynShan BlairKutzman\nSharadVikram JosefDean TerryThurk FionaLang\nDeepakRamachandran KaranGill RobinStrudel JingchenYe\nNikhilDhawan RossMcilroy PaulVoigtlaender PraneethNetrapalli\nJihoPark AbhishekBhowmick PiyushPatil PushkarMishra\nSaraSmoot JeremySelier TimDozat MyriamKhan\nGeorgevandenDriessche AntoineYang AliKhodaei MeghaGoel\nYochaiBlau DerekCheng SahilSingla RobWilloughby\nChaseMalik VladimirMagay PiotrAmbroszczyk DavidTian\nWeiLiang JieTan QiyinWu HongleiZhuang\nRoyHirsch DhritiVarma YifanChang JDChen\nCiceroNogueiradosSantos ChristianWalder BrianRoark ZakTsai\nEugeneWeinstein TomasKocisky ChaitraHegde TasosKementsietsidis\nAäronvandenOord RyoNakashima TianliDing ArjunKhare\nSidLall PaulNatsev AngelosFilos JamesKeeling\nNicholasFitzGerald MikeKwong ZhongruWu KeyangXu\nZixuanJiang IonelGog AndréSusanoPinto NathanWaters\n49\n\n--- PAGE 50 ---"
    },
    {
      "chunk_id": 46,
      "content": "--- PAGE 50 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nFlorentAltché YuxiangZhou JamesMartens LuLiu\nAshokPopat XinyiBai TaoChen YaoSu\nBhavishyaMittal Wei-ChihHung AvielBoag AnastasiaPetrushkina\nDavidSaxton StevenPecht DaiyiPeng JiajunShen\nDaliaElBadawy GeorgiTodorov ColineDevin ArmandJoulin\nMichaelMathieu NikhilKhadke ArseniyKlimovskiy YuanzhongXu\nZhengZheng PramodGupta MaryPhuong SteinXudongLin\nHaoZhou PreethiLahoti DannyVainstein YanaKulizhskaya\nNishantRanka ArnaudAutef JinXie CiprianChelba\nRichardShin KarthikDuddu BhuvanaRamabhadran ShobhaVasudevan\nQingnanDuan JamesLee-Thorp NathanHoward EliCollins\nTimSalimans AlexanderBykovsky XinxinYu VasilisaBashlovkina\nIoanaMihailescu TautvydasMisiunas GitarthaGoswami TonyLu\nUriShaham SebastianFlennerhag JingyuCui DougFritz\nMing-WeiChang SanthoshThangaraj SamShleifer JongbinPark\nYannisAssael JedMcGiffin MarioPinto YanqiZhou\nNishanthDikkala ZackNado Chih-KuanYeh ChenSu\nMartinIzzard MarkusKunesch Ming-HsuanYang RichardTanburn\nVincentCohen-Addad AndreasNoever SaraJavanmardi MikhailSushkov\nCatGraves AmirHertz DanEthier MitchelleRasquinha\nVladFeinberg MarcoLiang ChaceLee JinningLi\nGraceChung VictorStone JordiOrbay JenniferPrendki\nDJStrouse EvanPalmer SuyogKotecha YimingLi\nDannyKarmon SamiraDaruki CarlaBromberg PallaviLV\nSahandSharifzadeh ArijitPramanik PeteShaw ShriyaSharma\nZoeAshwood SiimPõder JamesThornton HenFitoussi\nKhiemPham AustinKyker AdiGerziRosenthal HuiHuang\nJonBlanton MinaKhan ShaneGu AndrewDai\nAlexVasiloff EvgenySluzhaev MattThomas PhuongDao\nJarredBarber MarvinRitter IanGemp MikeBurrows\nMarkGeller AvrahamRuderman AdityaAyyar HenryPrior\nAurickZhou WenleiZhou AsahiUshio DanfengQin\nFedirZubach ChiragNagpal AarushSelvan GolanPundak\nTzu-KuoHuang KiranVodrahalli JoelWee LarsLoweSjoesund\nLeiZhang GeorgeNecula ChenxiLiu ArtKhurshudov\nHimanshuGupta PaulBarham MaryamMajzoubi ZhenkaiZhu\nMattYoung ElliePavlick WeirenYu AlbertWebson\nJuliaProskurnia JayHartford JakeAbernethy ElizabethKemp\nRonnyVotel IzhakShafran TylerLiechty TatTan\nValentinGabeur LongZhao RenkePan SaurabhAgrawal\nGabrielBarcik MaciejMikuła HoangNguyen SusieSargsyan\nAdityaTripathi TomEccles Qiong(Q)Hu LiqunCheng\nHongkunYu HidetoshiShimokawa SarahPerrin JimStephan\nGengYan KanavGarg AbhinavArora TomKwiatkowski\nBeerChangpinyo LukeVilnis EmilyPitler DavidReid\nFilipPavetić HanwenChen WeiyiWang ArunkumarByravan\nAmyCoyle IliaShumailov KaushikShivakumar AssafHurwitzMichaely\nYasuhisaFujii Kuang-HueiLee FlavienProst NicolasHeess\nJorgeGonzalezMendez AbdelrahmanAbdelhamed BenLimonchik LuoweiZhou\nTianhaoZhou MeiyanXie JingWang SonamGoenka\nHarishRajamani VeredCohen YiGao ViralCarpenter\nBlakeHechtman EsterHlavnova TimotheeCour AnselmLevskaya\nEddieCao DanMalkin ShyamalBuch BoWang\nDa-ChengJuan ChawinSitawarin HuanGui ReedRoberts\nYi-XuanTan JamesLottes MariaIvanova RémiLeblond\nValentinDalibard PaulineCoquinot PhilippNeubeck SharatChikkerur\nYilunDu TianliYu KelvinChan StavGinzburg\nNatalieClay SandeepKumar LucyKim MaxChang\nKaishengYao JingweiZhang HuizhongChen RobertRiachi\nWenhaoJia AromaMahendru NamanGoyal Chuqiao(Joyce)Xu\nDimpleVijaykumar ZafaraliAhmed Da-WoonChung ZalánBorsos\n50\n\n--- PAGE 51 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nMichaelPliskin SenakaButhpitiya VincentTsang XingyuCai\nJuliaPawar OlafRonneberger BowenLiang PaulMichel\nMorganeLustman CalebHabtegebriel FernandoPereira SanjayGanapathy\nHannahKirkwood WeiLi SuhasGanesh JaneLabanowski\nAnkitAnand PaulCavallaro IvanKorotkov ZacharyGarrett\nAditiChaudhary AuroraWei JakubAdamek BenVargas\nNorbertKalb GuyBensky SridharThiagarajan SeanSun\nKieranMilan TimoDenk VinhTran BryanGale\nSeanAugenstein HarishGanapathy CharlesChen ThomasBuschmann\nAnnaGoldie JeffStanway ChrisTar GuillaumeDesjardins\nLaurelPrince PratikJoshi SanilJain NimeshGhelani\nKarthikRaman FrancescoBertolini IshitaDasgupta PalakJain\nYanhuaSun JessicaLo TaylanBilal MuditVerma\nVivianXia OliviaMa DavidReitter ChulayuthAsawaroengchai\nAaronCohen ZacharyCharles KaiZhao JulianEisenschlos\nZhouyuanHuo GetaSampemane GiuliaVezzani JitendraHarlalka\nJoshCamp HimanshuSahni YasminGehman HidetoKazawa\nSeherEllis XuChen PulkitMehta DonMetzler\nLukasZilka HarryAskham LaurenBeltrone JoshuaHowland\nDavidVilarTorres DavidGaddy XerxesDotiwalla YingJian\nLisaPatel PeterYoung SergioGuadarrama JakeAdes\nShoArora JiewenTan ZaheerAbbas ViralShah\nBettyChan MatanEyal StefaniKarp TynanGangwani\nJonasAdler ArthurBražinskas PetkoGeorgiev SeungjiLee\nKareemAyoub LiZhong Chun-SungFerng RomanRing\nJackyLiang ZhichunWu MarcBrockschmidt StevenM.Hernandez\nFayazJamil MarkEpstein LiqianPeng DeanReich\nJiepuJiang KaiBailey ChristophHirnschall AmerSinha\nSimonBaumgartner AndrewHard VikasVerma AshutoshSathe\nHaitianSun KamyuLee YingyingBi JoeKovac\nYaelKarov SashaGoldshtein YingXiao AshleahGill\nYaroslavAkulov AlexRuiz AvigailDabush AjayKannan\nHuiZheng MohammedBadawi KelvinXu AndreaD’olimpio\nIreneCai MatthiasLochbrunner PhilWallis MartinSevenich\nClaudioFantacci JKKearns RandallParker JayWhang\nJamesRubin AshleyBrown QifeiWang BeenKim\nAlexRavAcha FabioPardo YangXu KheChaiSim\nMengchaoWang TheophaneWeber IlkinSafarli JilinChen\nNinaD’Souza HaichuanYang DineshTewari JiagengZhang\nRohitSathyanarayana Pan-PanJiang YinZhang ShubaLall\nShengyangDai BerkinAkin SeungyeonKim YossiMatias\nSimonRowe ZhaoFu AndreaGesmundo BillJia\nAndreySimanovsky MarcusWainwright MackenzieThomas AbeFriesen\nOmerGoldman ChiZou SergeyLevi SaraNasso\nYuhengKuang MeenuGaba AhmedChowdhury AshishThapliyal\nXiaoyuePan Pierre-AntoineManzagol KanishkaRao BryanPerozzi\nAndrewRosenberg WendyKan PeterGarst TingYu\nTaniaRojas-Esponda YangSong SamConway-Rahman AnnaShekhawat\nPraneetDutta KarinaZainullina HelenRan SafeenHuda\nAmyZeng RuiLin KayMcKinney PeterGrabowski\nIrinaJurenka JeongwooKo ZhishengXiao EricWang\nGregFarquhar SalilDeshmukh WenhaoYu AshwinSreevatsa\nYaminiBansal ApoorvJindal RohanAgrawal HilalDib\nShariqIqbal JamesSvensson AxelStjerngren MehadiHassen\nBeccaRoelofs DivyaTyam CatalinIonescu ParkerSchuh\nGa-YoungJoung HeriZhao JingjingChen VedranaMilutinovic\nParkerBeak ChristineKaeser-Chen VivekSharma ChrisWelty\nChangwanRyu ScottBaird JustinChiu MichaelQuinn\nRyanPoplin PooyaMoradi FeiLiu AliShah\nYanWu JamieHall KenFranko BangjuWang\nJean-BaptisteAlayrac QiuchenGuo ClaytonSanford GabeBarth-Maron\n51\n\n--- PAGE 52 ---"
    },
    {
      "chunk_id": 47,
      "content": "--- PAGE 52 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nJustinFrye PatrickKane Andr’asGy\"orgy ArjunAkula\nNatalieAxelsson CeZheng ArunAhuja MaxDylla\nTaoZhu NicoDuduta DanielHernandezDiaz AshyanaKachra\nYukunMa JoshuaKessinger Chen-YuLee WeichengKuo\nIreneGiannoumis JamesNoraky NathanClement TingtingZou\nHanieSedghi SiqiLiu WeizeKong LilyWang\nChangYe KeranRong DrewGarmon LuyaoXu\nYiLuan PetarVeličković IshaanWatts JifanZhu\nKevinAydin KeithRush KushBhatia JustinSnyder\nBilvaChandra AlexGoldin KhyattiGupta SachitMenon\nVivekSampathkumar FannyWei MattMiecnikowski OrhanFirat\nRonnyHuang ShivaMohanReddy HugoVallet IgorMordatch\nVictorLavrenko Garlapati AnkurTaly YuanYuan\nAhmedEleryan CarolinePantofaru EdwardLoper NataliaPonomareva\nZhiHong OkwanKwon SaketJoshi RoryBlevins\nStevenHansen JianmoNi JamesAtwood LawrenceMoore\nSaraMcCarthy EricNoland JoChick WeijunWang\nBidishaSamanta JuliaDiTrapani MarkCollier PhilChen\nDomagojĆevid FrançoiseBeaufays FotisIliopoulos MartinScholz\nXinWang AbhijitGuhaRoy RyanTrostle ArturDwornik\nFangtaoLi YinlamChow BelizGunel JasonLin\nMichaelVoznesensky AybukeTurker RamiroLeal-Cavazos SichengLi\nMattHoffman GeoffreyCideron ArnarMarHrafnkelsson DiegoAntognini\nAndreasTerzis LantaoMei MichaelGuzman TeI\nVikashSehwag JonClark XiaoenJu XiaodanSong\nGilFidel QingyunDou AndyForbes MattMiller\nLuhengHe MatkoBošnjak JesseEmond UdayKalra\nMuCai RalphLeith KushalChauhan AdamRaveret\nYanzhangHe YuqingDu BenCaine OscarAkerlund\nAlexFeng AmirYazdanbakhsh LiXiao FelixWu\nMartinNikoltchev MiladNasr WenjunZeng AndrewNystrom\nSamratPhatale ChesterKwak AlexandreMoufarek NamrataGodbole\nJasonChase SurajSatishkumarSheth DanielMurphy TianqiLiu\nRoryLawton AlexKaskasoli MayaMeng HannahDeBalsi\nMingZhang AnkeshAnand NitishGupta JewelZhao\nTomOuyang BalajiLakshminarayanan FelixRiedel BuhuangLiu\nManuelTragut SammyJerome AnilDas AviCaciularu\nMehdiHafeziManshadi DavidBieber ElijahLawal LaurenLax\nArjunNarayanan Chun-TeChu ShashiNarayan UrvashiKhandelwal\nJiamingShen AlexandreSenges TiberiuSosea VictoriaLangston\nXuGao TianxiaoShen JamesSwirhun EricBailey\nTolgaBolukbasi MukundSridhar LindaFriso SilvioLattanzi\nNickRoy NdabaNdebele BehnamNeyshabur YufeiWang\nXinLi BenjaminBeyret JingLu NeelKovelamudi\nDanielGolovin ShakirMohamed SertanGirgin SnehaMondal\nLiviuPanait MiaChen MichaelWunder GuruGuruganesh\nZhenQin MarkusFreitag EdouardYvinec NanHua\nGuangxingHan JiaxianGuo AroonalokPyne OfirRoval\nThomasAnthony LuyangLiu VictorCarbune PawełWesołowski\nSnehaKudugunta PaulRoit ShrutiRijhwani RishikeshIngale\nVioricaPatraucean HengChen YangGuo JonathanHalcrow\nAniketRay ShenYan TulseeDoshi TimSohn\nXinyunChen TomStone AntonBriukhov ChristofAngermueller\nXiaochenYang JDCo-Reyes MaxBain BahramRaad\nTanujBhatia JeremyCole AyalHitron EliStickgold\nPranavTalluri SalvatoreScellato XuanhuiWang EvaLu\nAlexMorris ShekoofehAzizi AshishGupta AlecKosik\nAndrijaRažnatović HadiHashemi KeChen JingXie\nBethanieBrownfield AliciaJin CosmoDu TimothyLillicrap\nJamesAn AnandIyer WeiyangZhang AustinHuang\nShengPeng MarcellaValentine DhruvShah LydiaLihuiZhang\n52\n\n--- PAGE 53 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nDominikPaulus DangyiLiu SujeevanRajayogam AndriiMaksai\nClementFarabet RengaAravamudhan MohitAgarwal ÁgostonWeisz\nAlexWertheim YueSong SubhashiniVenugopalan SercanArik\nBingWang EdHirst BobakShahriari NickSukhanov\nRishabhJoshi AbhimanyuSingh QiqiYan AgaŚwietlik\nChu-lingKo BrendanJou HaoXu XuhuiJia\nYonghuiWu LiangBai TaylorTobin LuoYu\nShubhamAgrawal FrancescoPiccinno PavelDubov WeiyueWang\nLilyLin ChuyuanKellyFu HongzhiShi MarkBrand\nXiangHaiSheng RobinAlazard AdriàRecasens DawnBloxwich\nPeterSung BarakMeiri AntonKovsharov SeanKirmani\nTylerBreland-King DanielWinter SebastianBorgeaud ZheChen\nChristinaButterfield CharlieChen LucioDery AlecGo\nSwapnilGawde MingdaZhang ShanthalVasanth PabloSprechmann\nSumeetSingh JensHeitkaemper ElenaGribovskaya NithishKannen\nQiaoZhang JohnLambert LinhaiQiu AlenCarin\nRajApte JinhyukLee MahdisMahdieh ParamjitSandhu\nShilpaShetty AlexanderFrömmgen WojtekSkut IsabelEdkins\nAdrianHutter SergeyRogulenko ElizabethNielsen LeslieNooteboom\nTaoLi PranavNair CJZheng JaiGupta\nElizabethSalesky PaulNiemczyk AdamsYu LorenMaggiore\nFedericoLebron AntonBulyenov CarrieGrimesBostock JavadAzizi\nJonniKanerva BiboXu ShaleenGupta YaelPritch\nMichelaPaganini HadarShemtov AaronArcher PengchengYin\nArthurNguyen MortezaZadimoghaddam ChrisRawles MansiGupta\nRohithVallu SergeToropov ElinorDavies DannyTarlow\nJan-ThorstenPeter MateoWirth AlexeySvyatkovskiy DuncanSmith\nSarmishtaVelury HanjunDai TomyTsai DesiIvanov\nDavidKao SreenivasGollapudi YoniHalpern MohammadBabaeizadeh\nJayHoover DanielZheng ChristianReisswig AnkitaGoel\nAnnaBortsova AlexKurakin BartekWydrowski SatishKambala\nColtonBishop ChansooLee BoChang GraceChu\nShoshanaJakobovits KaleshaBullard JoanPuigcerver MatejKastelic\nAlessandroAgostini NicolasSerrano MorHazanTaege MichelleLiu\nAlekhAgarwal IvanaBalazevic JianLi HagenSoltau\nChangLiu YangLi EvaSchnider AustinStone\nCharlesKwong JohanSchalkwyk XinjianLi ShivaniAgrawal\nSasanTavakkol MarkMurphy DragosDena MinKim\nIoanaBica MingyangZhang YunhanXu KedarSoparkar\nAlexGreve KevinSequeira UmeshTelang SrinivasTadepalli\nAnirudhGP RominaDatta TianzeShi OskarBunyan\nJakeMarcus NishantAgrawal HeigaZen RachelSoh\nLeHou CharlesSutton KyleKastner ArvindKannan\nTomDuerig NithyaAttaluri YeongilKo DYKim\nRivkaMoroshko MencherChiang NeeshaSubramaniam BlakeJianHangChen\nDaveLacey WaelFarhan AviralKumar AfiefHalumi\nAndyDavis GregoryThornton PeteBlois SudeshnaRoy\nJulienAmelot KateLin ZhuyunDai YulongWang\nGuohuiWang TravisChoma JohnWieting OlcanSercinoglu\nFrankKim HungNguyen YifengLu GenaGibson\nTheofilosStrinopoulos KingshukDasgupta YoelZeldes SijalBhatnagar\nHuiWan DirkRobinson TianXie MotokiSano\nCharlineLeLan IuliaComşa AnjaHauth DanielvonDincklage\nShankarKrishnan MichaelRiley AlexandruŢifrea QingchunRen\nHaotianTang ArjunPillai YuqiLi BlagojMitrevski\nPeterHumphreys BasilMustafa SamEl-Husseini MirekOlšák\nJunwenBai BenGolan DanAbolafia JenniferShe\nIdanHeimlichShtacher AmirZandieh HowardZhou CarlDoersch\nDiegoMachado Jean-BaptisteLespiau WenDing Jilei(Jerry)Wang\nChenxiPang BillyPorter SahraGhalebikesabi BingyuanLiu\nKenBurke DavidRoss CarlosGuía QijunTan\n53\n\n--- PAGE 54 ---"
    },
    {
      "chunk_id": 48,
      "content": "--- PAGE 54 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nTamarYakar StanBileschi MatthewBilotti MichaelFink\nTrisWarkentin GeorgiosEvangelopoulos MohammadHosseinBateni ReidHayes\nAlexRamirez ThomasMensink IsaacNoble EricGe\nCarlLebsack JayPavagadhi LisaLee ShitaoWeng\nJoshDillon DenisTeplyashin AmelioVázquez-Reina Chia-HuaHo\nRajivMathews PaulChang JulianSalazar JohnKarro\nTomCobley LintingXue XiaomengYang KalpeshKrishna\nZelinWu GarrettTanzer BoyuWang LamNguyenThiet\nZhuoyuanChen SallyGoldman ElaGruzewska AmySkerry-Ryan\nJonSimon KaushalPatel AnandRao DanielEppens\nSwaroopNath ShixinLi SindhuRaghuram MarcoAndreetto\nTaraSainath JeremyWiesner ZhengXu NavinSarma\nAlexeiBendebury IvyZheng EyalBen-David SilvanoBonacina\nRyanJulian IanStewart-Binks JieruMei BurcuKaragolAyan\nBharathMankalale JieHan SidDalmia MeghaNawhal\nDariaĆurko ZhiLi ZhaoyiZhang ZhihaoShan\nPauloZacchello LiangchenLuo YuchenLiu MikeDusenberry\nAdamR.Brown KarelLenc GaganBansal ShantanuThakoor\nKiranbirSodhia MarioLučić HelenaPankov SagarGubbi\nHeidiHoward FuzhaoXue StevenSchwarcz DucDungNguyen\nSergiCaelles RyanMullins AndreaBurns ReutTsarfaty\nAbhinavGupta AlexeyGuseynov ChristineChan SamuelAlbanie\nGarethEvans Chung-ChingChang SumitSanghai JovanaMitrović\nAnnaBulanova IsaacGalatzer-Levy RickyLiang MeetGandhi\nLesleyKatzen AdamZhang EthanLiang Bo-JuenChen\nRomanGoldenberg GarrettBingham AntoineHe AlessandroEpasto\nAntonTsitsulin GraceHu AmyStuart GeorgiStephanov\nJoeStanton AleHartman ArunNarayanan YeJin\nBenoitSchillings YueMa YukunZhu SamuelGehman\nVitalyKovalev JordanGriffith ChristianFrank AidaAmini\nCoreyFry AlexIrpan BaharFatemi JackWeber\nRushinShah CareyRadebaugh AmitSabne FeryalBehbahani\nKuoLin SummerYue OranLang ShawnXu\nShyamUpadhyay LijieFan IndroBhattacharya MiltosAllamanis\nChengLi VictorUngureanu ShaneSettle XiChen\nSoroushRadpour ChristinaSorokin MariaWang MyleOtt\nMarcelloMaggioni HannahTeufel BrendanMcMahan ClaireSha\nJingXiong PeiranLi AndreaTacchetti MichalJastrzebski\nLukasHaas RohanAnil LivioBaldiniSoares HangQi\nJennyBrennan DimitrisPaparas MajidHadian DavidGreene\nAishwaryaKamath ToddWang SerkanCabi XinyiWu\nNikolaySavinov Chu-ChengLin TimothyChung AbodunrinwaToki\nArshaNagrani HuiPeng NikitaPutikhin DanielVlasic\nTrevorYacovone MeganShum GangLi JaneShapiro\nRyanKappedal GoranPetrovic JeremyChen RaghaKotikalapudi\nKostasAndriopoulos DemetraBrady AustinTarango ZheShen\nLiLao RichardNguyen HenrykMichalewski TakaakiSaeki\nYaGuangLi KlausMacherey MehranKazemi SiruiXie\nGrigoryRozhdestvenskiy ZhihaoLi HussainMasoom AlbinCassirer\nKazumaHashimoto HarmanSingh HilaSheftel ShikharBharadwaj\nAndrewAudibert MadhaviYenugula RakeshShivanna TatsuyaKiyono\nSophiaAustin MarikoIinuma ArchitaVadali SrinadhBhojanapalli\nDanielRodriguez XinyiChen RamonaComanescu ElanRosenfeld\nAnianRuoss KavyaKopparapu DougReid SamRitter\nGarrettHonke AlexeyStern JossMoore JiemingMao\nDeepKarkhanis ShachiDave ArvindNeelakantan JoãoGabrielOliveira\nXiXiong ChanduThekkath MichaëlSander ZoltanEgyed\nQingWei FlorencePerot JonathanHerzig BerndBandemer\nJamesHuang AnuragKumar AvivRosenberg EmilioParisotto\nZhaoqiLeng FangdaLi MostafaDehghani KeisukeKinoshita\nVittalPremachandran YangXiao JDChoi JuliettePluto\n54\n\n--- PAGE 55 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nPetrosManiatis GloriaShen SwaroopMishra Cheng-ChunLee\nSteveLi ElijahPeake JosipDjolonga TapomayDey\nYaohuiGuo RemiCrocker CraigSchiff HaoZheng\nGolnazGhiasi ShubhaSrinivas MajdAlMerey ShachiPaul\nJeanTarbouriech Raghvendra EleftheriaBriakou CelineSmith\nSrimonChatterjee DannySwisher PeterMorgan AndyLy\nJulieJin WoohyunHan AndyWan YichengWang\nKatrina(Xinyi)Xu RichaSingh AvinatanHassidim RishabhBansal\nJennimariaPalomaki LingWu RJSkerry-Ryan BartekPerz\nSébArnold VladimirPchelin KuntalSengupta SusannaRicco\nMadhaviSewak TsendsurenMunkhdalai MaryJasarevic StashaBlank\nFedericoPiccinini DanaAlon PraveenKallakuri VaishakhKeshava\nMohitSharma GeoffBacon PaigeKunkle DeepakSharma\nBenAlbrecht EfrenRobles HannahBrennan MarvinChow\nSeanPurser-haskell JannisBulian TomLieber KunalLad\nAshwinVaswani MelvinJohnson HassanMansoor KomalJalan\nChongyanChen GeorgePowell JulianWalker SimonOsindero\nMatheusWisniewski FelipeTiengoFerreira BingZhang CraigSwanson\nQinCao YaoyiranLi AnnieXie JacobScott\nJohnAslanides FrederikBenzing GoranŽužić AnastasijaIlić\nNguyetMinhPhu MihajloVelimirović AdaezeChukwuka XiaoweiLi\nMaximilianSieb HubertSoyer AlexDruinsky SiddharthaReddy\nLaurenAgubuzu WilliamKong DonghyunCho Jonnalagadda\nAnneZheng Tony(Tuâ´n)Nguy˜ên RuiYao AfzalShamaSoudagar\nDanielSohn ZhenYang FerjadNaeem YanXiong\nMarcoSelvi JeremiahLiu ShirazButt Bat-OrgilBatsaikhan\nAndersAndreassen JoostvanAmersfoort EunyoungKim DanielJarrett\nKrishanSubudhi DanielGillick ZhipengJia NaveenKumar\nPremEruvbetine BaochenSun MandyJordan MaulikShah\nOliverWoodman NathalieRauschmayr AdamLelkes MattLawlor\nTomasMery KatieZhang MarkKurzeja AustinWaters\nSebastianKrause SerenaZhan SophieWang MarkGraham\nXiaoqiRen TaoZhou JamesZhao RhysMay\nXiaoMa AlexeyFrolov AndrewOver SabelaRamos\nJinchengLuo ChengrunYang AbhishekChakladar SandraLefdal\nDawnChen DenisVnukov MarcelPrasetya ZeynepCankara\nWeiFan LouisRouillard NehaJha NachoCano\nHenryGriffiths HongjiLi SriramGanapathy BrendanO’Donoghue\nChristianSchuler AmolMandhane YaleCong JedBorovik\nAliceLi NovaFallen PrakashShroff FrederickLiu\nShujianZhang RajeshVenkataraman CarlSaroufim JordanGrimstad\nJean-MichelSarr ClaraHuiyiHu SobhanMiryoosefi MahmoudAlnahlawi\nShixinLuo JenniferBrennan MohamedHammad KaterinaTsihlas\nRiccardoPatana JennyLee TajwarNasir TomHudson\nMatthewWatson JerryChang WeijuanXi NikolaiGrigorev\nDaniNaboulsi MartinSundermeyer YangGao YilingJia\nMichaelCollins ZhufengPan YoungMaeng TerryHuang\nSaileshSidhwani RosemaryKe BenHora TobennaPeterIgwe\nEmielHoogeboom SimonTong Chin-YiCheng SergeiLebedev\nSharonSilver AlexFabrikant ParisaHaghani XiaodanTang\nEmilyCaveness WilliamBono YoadLewenberg IgorKrivokon\nXiaokaiZhao JindongGu CadenLu FrankieGarcia\nMikelRodriguez RyanFoley MartinMatysiak MelissaTan\nMaxineDeines YiranMao NainaRaisinghani EricJia\nLibinBai ManolisDelakis HuiyuWang PeterStys\nPatrickGriffin DhruvaBhaswar LexiBaugher ShikharVashishth\nMarcoTagliasacchi RoyFrostig RahulSukthankar YuLiang\nEmilyXue NickLi MinhGiang BalajiVenkatraman\nSpandanaRajBabbula AvitalZipori JohnSchultz ChenjieGu\nBoPang CathHope NoahFiedel AnastasiosKementsietsidis\nNanDing OlgaKozlova MinminChen ChenZhu\n55\n\n--- PAGE 56 ---"
    },
    {
      "chunk_id": 49,
      "content": "--- PAGE 56 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nJunehyukJung DorsaSadigh AyushiAgarwal JongLee\nYunfeiBai JeremiahWillcock KathieWang ShengZhang\nMohammadJavadHosseini TingnanZhang PreetiSingh SushantKafle\nFarukAhmed SteveXu FourFlynn SiddharthVashishtha\nAdityaGupta SashaBrown JoshLipschultz ParsaMahmoudieh\nXinYuan KatherineLee RobertDavid GraceChen\nShereenAshraf GaryWang LizzetthBellot RaphaelHoffmann\nShitijNigam YunZhu Yao-YuanYang PraneshSrinivasan\nGautamVasudevan YiTay LongLe AgustinDalLago\nPranjalAwasthi CheolminKim FilippoGraziano YoavBenShalom\nAdiMayravGilady AudreyGutierrez KateOlszewska ZiWang\nZeldaMariet AbhanshuSharma KevinHui MichaelElabd\nRamyEskander YongqinXian AkankshaMaurya AnujSharma\nHaiguangLi SungyongSeo NikosParotsidis JunhyukOh\nHexiangHu ClaireCui WeijieChen SurajKothawade\nGuillermoGarrido ElenaPochernina TayoOguntebi MaigoLe\nPhilippeSchlattner CipBaetu JoeKelley MarianneMonteiro\nGeorgeZhang KrzysztofJastrzębski AnirudhBaddepudi ShentaoYang\nRohunSaxena MimiLy JohannesMauerer KaizAlarakyia\nPetarDević MohamedElhawaty GregoryShaw RobertGeirhos\nKritikaMuralidharan DanSuh AlexSiegman DianaMincu\nAshwinMurthy ErenSezener LinYang HåvardGarnes\nYiqianZhou PidongWang ShravyaShetty HayatoKobayashi\nMinChoi NancyYuen SubhrajitRoy SorooshMariooryad\nArissaWongpanich GeorgeTucker YuntingSong KacperKrasowiak\nZhengdongWang JiahaoCai WojciechStokowiec Zhixin(Lucas)Lai\nPremalShah ZuguangYang RyanBurnell ShiblMourad\nYuntaoXu CindyWang OmkarSavant MingqiuWang\nYilingHuang AlexMuzio RobertBusa-Fekete FanBu\nStephenSpencer HaiQian JinMiao OphirAharoni\nAliceChen JaeYoo SamratGhosh GuanjieChen\nJamesCohan DerekLockhart LiamMacDermed AbhimanyuGoyal\nJunjieWang KevinR.McKee PhillipLippe VadimZubov\nJonathanTompson MandyGuo MikhailDektiarev AnkurBapna\nJunruWu MalikaMehrotra ZachBehrman ElaheDabir\nRubaHaroun ArturMendonça FabianMentzer NisargKothari\nHaiqiongLi SanketVaibhavMehta KelvinNguyen KayLamerigts\nBlancaHuergo SherryBen MengWei NicolaDeCao\nFanYang ChetanTekur SiddharthVerma JeremyShar\nTongxinYin JiaqiMu ChrisKnutsen ChristopherYew\nJamesWendt MuyeZhu SudeepDasari NitishKulkarni\nMichaelBendersky VictoriaKrakovna ZhipengYan DreMahaarachchi\nRahmaChaabouni HongraeLee PetrMitrichev MandarJoshi\nJavierSnaider AJMaschinot XingyuWang ZhenhaiZhu\nJohanFerret SébastienCevey ViratShejwalkar JaredLichtarge\nAbhishekJindal HyunJeongChoe JacobAustin YichaoZhou\nTaraThompson AijunBai SrinivasSunkara HannahMuckenhirn\nAndrewXue HansaSrinivasan NavneetPotti VittorioSelo\nWillBishop DerekGasaway YanVirin OriolVinyals\nShubhamMilindPhal NickYoung ChristianWright PeterChen\nArchitSharma PatrickSiegler GaëlLiu AnthonyBrohan\nYunhsuanSung DanHoltmann-Rice OrianaRiva VaibhavMehta\nPrabakarRadhakrishnan VihariPiratla EtiennePot SarahCogan\nMoShomrat KateBaumli GregKochanski RuthWang\nReeveIngle RoeyYogev QuocLe TyGeri\nRoopaliVij AlexHofer GargiBalasubramaniam Wei-JenKo\nJustinGilmer HadovanHasselt ArkaDhar WeiChen\nMihaiDorinIstin SvetlanaGrant YuguoLiao FabioViola\nSamSobell YuriChervonyi AdamBloniarz KeshavShivam\nYangLu DavidSilver DivyanshShukla LisaWang\nEmilyNottage AndrewHogue ElizabethCole MadeleineClareElish\n56\n\n--- PAGE 57 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nRalucaAdaPopa CesleeMontgomery JialinWu KaiKang\nSébastienPereira DheeruDua SlavicaAndačić YifanHe\nJianqiaoLiu AnaRamalho SzabolcsPayrits LinZhuo\nRaphaelKoster HelenKing DanielMcDuff MarijaKostelac\nDonnieKim YueGao TomHume ItayLaish\nGufengZhang LynnNguyen YuanCao SongyouPeng\nSaynaEbrahimi DavidLindner MHTessler LouisO’Bryan\nParthaTalukdar DivyaPitta QingzeWang DanielKasenberg\nYanyanZheng OleaserJohnson YinanWang GirishRamchandraRao\nPetraPoklukar KhalidSalama IvorRendulic EdouardLeurent\nAlesMikhalap DiegoArdila EirikurAgustsson BiaoZhang\nDaleJohnson MichaelHan MatthewJohnson SageStevens\nAnithaVijayakumar ErinFarnese TanyaLando AnaSalazar\nMarkOmernick SethOdoom AndrewHoward YeZhang\nMattDibb ZiyueWang SriGayatriSundara IvanLobov\nAyushDubey XiangzhuoDing Padmanabhan JakeWalker\nQiongHu NormanRink MayankDaswani AllenPorter\nApurvSuman RaySmith AndreaBanino MorganRedshaw\nVaibhavAggarwal HarshalTusharLehri MichaelKilgore HanKe\nIlyaKornakov EdenCohen JonathanHeek AbhishekRao\nFeiXia NeeraVats ZiweiJi AlexLee\nWingLowe TongHe AlvaroCaceres HoiLam\nAlexeyKolganov ParthasarathyGopavarapu ConglongLi MichaelMoffitt\nTedXiao AdamPaszke NoraKassner JaeyounKim\nVitalyNikolaev MiteyanPatel AlexeyVlaskin SiyuanQiao\nStevenHemingray WouterVanGansbeke ZeyuLiu TerryKoo\nBonnieLi LuciaLoher AlexGrills RobertDadashi\nJoanaIljazi LuisCastro YanhanHou XinyingSong\nMikołajRybiński MariaVoitovich RoykrongSukkerd MukundSundararajan\nBallieSandhu TamaravonGlehn GowoonCheon PengXu\nPeggyLu NelsonGeorge NishitaShetty ChizuKawamoto\nThangLuong SimonNiklaus LarisaMarkeeva YanZhong\nRodolpheJenatton ZachEaton-Rosen PiotrStanczyk ClaraBarbu\nVineethaGovindaraj NemanjaRakićević TejasIyer ApoorvReddy\nHui(Elena)Li ErikJue YuanGong MauroVerzetti\nGabrielDulac-Arnold SagiPerel ShawnGao LeonLi\nWonpyoPark CarrieZhang KeerthanaGopalakrishnan GeorgePapamakarios\nHenryWang YuvalBahat TimBlyth HannaKlimczak-Plucińska\nAbhinitModi AngélinePouget MalcolmReynolds MaryCassin\nJeanPouget-Abadie ZhiXing AvishkarBhoopchand KorayKavukcuoglu\nKristinaGreller FantineHuot MishaBilenko RigelSwavely\nRahulGupta AshishShenoy DeroGharibian AlainVaucher\nRobertBerry TaylorBos VickyZayats JeffreyZhao\nPrajitRamachandran VincentCoriou AleksandraFaust RossHemsley\nJinyuXie BryanRichter AbhinavSingh MichaelTschannen\nLiamMcCafferty NatashaNoy MinMa HemingGe\nJianlingWang YaqingWang HongyangJiao GauravMenghani\nKilolGupta SantiagoOntanon Sudheendra YangYu\nHyeontaekLim SiyangQin Vijayanarasimhan NatalieHa\nBlažBratanič GlebMakarchuk LoraAroyo WeiHe\nAndyBrock DemisHassabis VikasYadav XiaoWu\nIliaAkolzin ZhuowanLi SarahChakera MaggieSong\nJimSproch MandarSharma AshwinKakarla RachelSterneck\nDanKarliner KumaranVenkatesan VilobhMeshram StefanZinke\nDuhyeonKim IuriiKemaev KarolGregor DanA.Calian\nAdrianGoedeckemeyer RoxanneDaniel GabrielaBotea AnnieMarsden\nNoamShazeer ShiyuHuang EvanSenter AlejandroCruzadoRuiz\nCordeliaSchmid SaloniShah DaweiJia MatteoHessel\nDanieleCalandriello OctavioPonce GezaKovacs AlmogGueta\nParulBhatia Warren(Weilun)Chen NehaSharma BenjaminLee\nKrzysztofChoromanski ManaalFaruqui SebastienBaur BrianFarris\n57\n\n--- PAGE 58 ---"
    },
    {
      "chunk_id": 50,
      "content": "--- PAGE 58 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nManishGupta YinZhong ZachFisher RohinShah\nYunjieLi JunwhanAhn DustinZelle JohnYoussef\nMohammadSaleh MichaelIsard CourtneyBiles RishabhAgarwal\nVedantMisra OlivierLacombe EugeneIe NatalieDabney\nKefanXiao FlorianLuisier AsyaFadeeva AlessioTonioni\nPiermariaMendolicchio ChrysovalantisAnastasiou CasperLiu MoranAmbar\nGavinButtimore YogeshKalley JulianaVicenteFranco JingLi\nVarvaraKrayvanova UtsavPrabhu AdrianCollister IsabelleGuyon\nNigamaaNayakanti EmmaDunleavy HaoZhang BennyLi\nMatthewWiethoff ShaanBijwadia RenshenWang DavidSoergel\nYashPande JustinMao-Jones RuizheZhao BoyaFang\nAzaliaMirhoseini KellyChen LeandroKieliger GeorgiKaradzhov\nNiLao RamaPasumarthi KurtShuster CristianUdrescu\nJasmineLiu EmilyWood RuiZhu TrieuTrinh\nYiqingHua AdilDostmohamed BoqingGong VikasRaunak\nAngieChen NateHurley LawrenceChan SebNoury\nYuryMalkov JiriSimsa RuoxiSun DeeGuo\nDmitryKalashnikov AliciaParrish SujoyBasu SonalGupta\nShubhamGupta MantasPajarskas RolandZimmermann MaraFinkelstein\nKartikAudhkhasi MattHarvey JamieHayes DenisPetek\nYuexiangZhai OndrejSkopek AbhishekBapna LihaoLiang\nSudhindraKopalle YonyKochinski JasperSnoek GregBillock\nPrateekJain JavierRey WeelYang PeiSun\nEranOfek VerenaRieser PuranjayDatta DavidWood\nClemensMeyer DennyZhou JadAlAbdallah YiwenSong\nKhuslenBaatarsukh SunJaeLee KevinKilgour XiaobinYu\nHanaStrejček TrilokAcharya LuLi TatianaMatejovicova\nJunQian GuowangLi SQMah RegevCohen\nJamesFreedman JoeJiang YennieJun KalyanAndra\nRicardoFigueira XiaofanZhang MorganeRivière DavidD’Ambrosio\nMichalSokolik BryantGipson AbhijitKarmarkar ZhiweiDeng\nOlivierBachem EthanMahintorabi TammoSpalink VincentNallatamby\nRaymondLin MarcoGelmi TaoHuang EbrahimSonghori\nDiaKharrat NimaKhajehnouri LucasGonzalez RumenDangovski\nChrisHidey AngelYeh Duc-HieuTran AndrewLampinen\nPingmeiXu KayiLee AveriNowak PankilBotadra\nDennisDuan LoicMatthey JohnPalowitch AdamHillier\nYinLi LeslieBaker MartinChadwick JiaweiCao\nMugeErsoy TrangPham EllieTalius NagabhushanBaddi\nRichardEverett HanFu HarshMehta AdhiKuncoro\nKevinCen AlexPak ThibaultSellam ToshihiroYoshino\nRebeca PrakharGupta PhilippFränken AnkitBhagatwala\nSantamaria-Fernandez CristinaVasconcelos MassimoNicosia Marc’aurelioRanzato\nAmirTaubenfeld AdamSadovsky KyleHe RylanSchaeffer\nIanMackinnon BrianWalker AdityaKini TianlinLiu\nLindaDeng SissieHsiao DavidAmos ShuaiYe\nPolinaZablotskaia PatrikZochbauer SugatoBasu ObaidSarvana\nShashankViswanadha AndreeaMarzoca HarrisonJobe JohnNham\nShivankerGoel NoamVelan EleniShaw ChenkaiKuang\nDamionYates JunhaoZeng QiantongXu IsabelGao\nYunxiaoDeng GillesBaechler ColinEvans JinooBaek\nPeterChoy DannyDriess DaisukeIkeda ShubhamMittal\nMingqingChen DivyaJain ChaochaoYan AyzaanWahid\nAbhishekSinha YanpingHuang LarryJin AnitaGergely\nAlexMossin LizzieTao LunWang BinNi\nYimingWang JohnMaggs SachinYadav JoshFeldman\nArthurSzlam NirLevine IliaLabzovsky CarrieMuir\nSusanHao JonSchneider RameshSampath PascalLamblin\nPaulKishanRubenstein ErikaGemzer AdaMa WolfgangMacherey\nMetinToksoz-Exley SamuelPetit CandiceSchumann EthanDyer\nMirandaAperghis ShanHan AdityaSiddhant LoganKilpatrick\n58\n\n--- PAGE 59 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nVíctorCampos DaveOrr AlaaSaade UriAlon\nMukulBhutani LeventBolelli AngeloScorzaScarpati XianghongLuo\nStanislavFort NicolasPerez-Nieves ChrisBreaux DianYu\nYanifAhmad MikhailSirotenko CJCarey AbhishekNayyar\nAliakseiSeveryn AmanPrasad ZongweiZhou BrycePetrini\nKleopatraChatziprimou ArjunKar Cho-JuiHsieh WillTruong\nOleksandrFerludin BorjaDeBallePigem SophieBridgers VincentHellendoorn\nMasonDimarco TayfunTerzi AlenaButryna NikolaiChinaev\nAdityaKusupati GellértWeisz NisheshGupta ChrisAlberti\nJoeHeyward DipankarGhosh VaibhavTulsyan WeiWang\nDanBahir AditiMavalankar SanghyunWoo JingcaoHu\nKevinVillela DhruvMadeka EvgeniiEltyshev VahabMirrokni\nKatieMillican KasparDaugaard WillGrathwohl AnanthBalashankar\nDrorMarcus HartwigAdam ChanelParks AviaAharon\nSanazBahargam VirajShah SethBenjamin AahilMehta\nCaglarUnlu DanaBerman RinaPanigrahy AhmetIscen\nNicholasRoth MaggieTran ShenilDodhia JosephKready\nZichuanWei StevenBaker DanielDeFreitas LucasManning\nSiddharthGopal EwaAndrejczuk ChrisSauer AnhadMohananey\nDeepanwayGhoshal GrishmaChole WillSong YuankaiChen\nEdwardLee GannaRaboshchuk FerranAlet AnshumanTripathi\nSharonLin MahdiMirzazadeh JacksonTolins AllenWu\nJennieLees ThaisKagohara CosminPaduraru IgorPetrovski\nDayeongLee ShimuWu XingyiZhou DawsenHwang\nAnahitaHosseini ChristianSchallhart BrianAlbert MartinBaeuml\nConnieFan BernettOrlando ZizhaoZhang Shreyas\nSethNeel ChenWang LeiShu Chandrakaladharan\nMarcusWu AlbanRrustemi MuditBansal YuanLiu\nYaseminAltun HaoXiong SarahNguyen ReyCoaguila\nHonglongCai HaoLiu AmirGloberson MaxwellChen\nEnriquePiqueras ArpiVezer OwenXiao SallyMa\nJoshWoodward NolanRamsden JamesManyika PouyaTafti\nAlessandroBissacco Shuo-yiinChang TomHennigan SusheelTatineni\nSalemHaykal SidharthMudgal RongRong TerrySpitz\nMahyarBordbar YanLi JosipMatak JiayuYe\nPrashaSundaram NinoVieillard AntonBakalov PaulVicol\nSarahHodkinson YedidHoshen AnkurSharma MihaelaRosca\nDanielToyama FarooqAhmad DanilaSinopalnikov AdriàPuigdomènech\nGeorgePolovets AmbroseSlone AndrewPierson ZoharYahav\nAustinMyers AmyHua StephenRoller SanjayGhemawat\nAnuSinha NatanPotikha GeoffBrown HanzhaoLin\nTomerLevinboim MirkoRossini MingcenGao PhoebeKirk\nKashyapKrishnakumar JonStritar ToshiyukiFukuzawa ZaidNabulsi\nRachitaChhaparia SushantPrakash AminGhafouri SergeyBrin\nTatianaSholokhova ZifengWang KennyVassigh BerndBohnet\nNiteshBharadwaj XuanyiDong IainBarr KenCaluwaerts\nGundavarapu AlirezaNazari ZhichengWang AdityaSrikanth\nGaneshJawahar EfratNehoran AnnaKorsun Veerubhotla\nHaroonQureshi KaanTekelioglu RajeshJayaram DanZheng\nJieruHu YinxiaoLi LijieRen ZihangDai\nNikolaMomchev KartikeyaBadola TimZaman PetrePetrov\nMatthewRahtz TomFunkhouser SamiraKhan YichongXu\nRenjieWu YuanzhenLi YanaLunts RaminMehran\nAishwaryaPS VarunYerram DanDeutsch ZhuoXu\nKedarDhamdhere RamyaGaneshan DaveUthus LuisaZintgraf\nMeiqiGuo DanielFormoso NitzanKatz JihoChoi\nUmangGupta KarolLangner MashaSamsikova SpurthiAmbaHombaiah\nAliEslami TianShi AmrKhalifa RomalThoppilan\nMarianoSchain HuijianLi NikhilSethi SashankReddi\nMichielBlokzijl YumeyaYamamori JiaoSun LukaszLew\nDavidWelling AmayikaPanda LumingTang LiLi\n59\n\n--- PAGE 60 ---"
    },
    {
      "chunk_id": 51,
      "content": "--- PAGE 60 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nKellieWebster LuisC.Cobo JingweiShen AlokGunjan\nKPSawhney JamesQin MiaosenWang BilalPiot\nLamprosLamprou ThiAvrahami RoopalGarg WaleedKhawaja\nSiamakShakeri DanielBalle JingChen SeojinBang\nMayankLunayach YuWatanabe UtkuEvci SimonWang\nJianminChen AnnieLouis JonathanLee SiavashKhodadadeh\nSumitBagri AdamKraft LeonLiu RaghavenderR\nAlexSalcianu SetarehAriafar KojiKojima PraynaaRawlani\nYingChen YimingGu MasaYamaguchi RichardPowell\nYaniDonchev EugénieRives ArunkumarRajendran KevinLee\nCharlotteMagister CharlesYoon AJPiergiovanni JohannesGriesser\nSigneNørly AndreiRusu VinodhKumarRajendran GSOh\nVitorRodrigues JamesCobon-Kerr MarcoFornoni CesarMagalhaes\nTomasIzo ChrisHahn GabrielIbagon YujiaLi\nHilaNoga JiamingLuo HarryRagan SimonTokumine\nJoeZou Yuvein(Yonghao)Zhu SadhMNMKhan HadasNatalieVogel\nThomasKöppe NiharikaAhuja JohnBlitzer DennisHsu\nWenxuanZhou RodrigoBenenson AndrewBunner ArturoBC\nKentonLee RaphaëlLopezKaufman GuanSun DishaJindal\nXiangzhuLong HonglinYu TakahiroKosakai MatanCohen\nDanielleEisenbud LloydHightower ScottLundberg ZiYang\nAnthonyChen JunlinZhang NdidiElue JunweiYuan\nConnorSchenck DarrenNi KelvinGuu DariodeCesare\nChiMingTo LisaAnneHendricks SKPark TonyBruguier\nPeilinZhong GabbyWang JanePark JunXu\nEmanuelTaropa GalYona Arunachalam MonicaRoy\nMinhTruong LalitJain Narayanaswamy AlonJacovi\nOmerLevy PabloBarrio ChengdaWu DanBelov\nDaniloMartins SuryaBhupatiraju JayaramMudigonda RahulArya\nZhiyuanZhang SivaVelusamy TrevorCohn PhoenixMeadowlark\nChristopherSemturs AllanDafoe HairongMu ShlomiCohen-Ganor\nKelvinZhang SebastianRiedel RaviKumar WentingYe\nAlexYakubovich TaraThomas LauraGraesser PatrickMorris-Suzuki\nPolMoreno ZheYuan YichiZhang PraseemBanzal\nLaraMcConnaughey MathiasBellaiche RichardKillam GanSong\nDiLu SheenaPanthaplackel VincentZhuang PranavarajPonnuramu\nSamRedmond KlemenKloboves MaiGiménez FredZhang\nLotteWeerts SarthakJauhari WaelAlJishi GeorgeScrivener\nYonatanBitton CanferAkbulut RuyLey-Wild SalahZaiem\nTizianaRefice TodorDavchev AlexZhai AlifRadityaRochman\nNicolasLacasse EvgenyGladchenko KazukiOsawa KehangHan\nArthurConmy DavidMadras DiegoCedillo BadihGhazi\nCorentinTallec AleksandrChuklin JialuLiu KateLee\nJulianOdell TyroneHill MayankUpadhyay ShaharDrath\nHannahForbes-Pollard QuanYuan MarcinSieniek DanielSuo\nArkadiuszSocala MukundanMadhavan RoshanSharma AntoniousGirgis\nJonathanHoech LukeLeonhard TomPaine PradeepShenoy\nPushmeetKohli DylanScandinaro AneliaAngelova DuyNguyen\nAlannaWalton QihangChen SravantiAddepalli DouglasEck\nRuiWang NingNiu CarolinaParada SomitGupta\nMikitaSazanovich ArthurDouillard KingshukMajumder LeYan\nKexinZhu BogdanDamoc AveryLamp JoaoCarreira\nAndreiKapishnikov YasumasaOnoe SanjivKumar AnmolGulati\nRichGalt FabianPedregosa XiangDeng RuoxinSang\nMatthewDenton FredBertsch ArtiomMyaskovsky DaniilMirylenka\nBenMurdoch ChasLeichner TeaSabolić EmmaCooney\nCaitlinSikora JosephPagadora JeffreyDudek EdwardChou\nKareemMohamed JonathanMalmaud SarahYork MingyangLing\nWeiWei SameeraPonda FélixdeChaumontQuitry CindyFan\nUriFirst AndyTwigg JiazhongNie BenColeman\nTimMcConnell OleksiiDuzhyi DeeCattle GuilhermeTubone\n60\n\n--- PAGE 61 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nRavinKumar JasmineGeorge AshwinChaugule MaciejKula\nJasonBaldridge RichardGreen AngadChandorkar YizhongLiang\nFelixHernandez-Campos PuHan AltafRahman DahunKim\nAngelikiLazaridou ConnieTao WillThompson YangsiboHuang\nJamesBesley GeoffClark PenpornKoanantakool ChengxiYe\nItayYona ChongYou MikeBernico DmitryLepikhin\nNeslihanBulut AbbasAbdolmaleki JieRen WesleyHelmholz\nQuentinWellens JustinFu AndreyVlasov\nAJPierigiovanni TongzhouChen SergeiVassilvitskii\n61\n\n--- PAGE 62 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nThe development of Gemini is a large-scale collaborative effort involving over 3000 individuals\nacross Google, including researchers, engineers, and operations staff. These individuals contributed\ntheir hard work and expertise across diverse areas, from foundational research and the development\nof model architecture, data, training, and infrastructure, through to evaluation and ensuring safety\nand security. We gratefully acknowledge the dedication and hard work of each contributor in making\nGemini a reality. The order of contributors in the above list is random.\nWe are also grateful to the Google-independent developer Joel Zhang for his work on Gemini\nPlays Pokémon, and for sharing with us the design of his set-up.\n62\n\n--- PAGE 63 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n8. Appendix\n8.1. Evaluation additional details\nPlease see a description of the benchmarks considered, along with details of how scores in the main\ntext were obtained in Table 11.\nBenchmark Description Details\nLiveCodeBench CodegenerationinPython(Jainetal., Resultsaretakenfromhttps://livecode\n2024). bench.github.io/leaderboard.html\n(1/1/2025-5/1/2025intheUI)or,where\nnotavailable,runinternallybyus. ForSec-\ntion2.5andFigure3and4,resultsarecalcu-\nlatedontheversionoftheevalcorresponding\nto10/05/2024-01/04/2025intheUI,and\narebasedoninternalresults.\nAiderPolyglot Code editing in C++, Go, Java, Wereportresultsonthe“diff”or“diff-fenced”\nJavaScriptPythonandRust(Gauthier, editformat(seehttps://aider.chat/d\n2025). See https://aider.chat ocs/more/edit-formats.html for a\n/2024/12/21/polyglot.html#th description of the different formats). The\ne-polyglot-benchmark for a full scorereportedarethepassrateaverageof3\ndescriptionofthistask. trials. Numberscomefromhttps://aide\nr.chat/docs/leaderboards/\nSWE-benchVeri- Agentic coding: evaluates AI agents Gemini uses an internal agentic harness\nfied onreal-worldprogrammingtasksfrom equipped with tools to navigate the repo,\nGitHub (Chowdhury et al., 2024; editfiles,andtestthecode.\nJimenezetal.,2024). We report scores for two modes: perfor-\nmance of a single agentic trace (“single\nattempt”), and performance of a scaffold\nthatsamplesmultipleagentictracesandre-\nreranksthembeforeevaluationusingGem-\nini’sownjudgement(“multipleattempts”).\nAll evaluations are done with tempera-\nture=1,topp=0.99,topk=1024.\nGPQA Challengingdatasetofquestionswrit-\n(diamond) ten by domain experts in biology,\nphysics, and chemistry (Rein et al.,\n2024).\nHumanity’sLast Challengingdatasetofquestionswrit- Notoolusevariant.\nExam tenbydomainexpertsinawiderange Reportedresultsarefromhttps://scale.\nofdisciplines,includingmathematics, com/leaderboard/humanitys_last_e\nphysics, chemistry, biology and com- xam.\nputerscience(Phanetal.,2025). For DeepSeek they are taken from https:\n//scale.com/leaderboard/humanity\ns_last_exam_text_only (leaderboard\nforperformanceonthetext-onlyquestions)\nand in the case of the Gemini 2.0 models,\ntheseresultsareonanearlierHLEdataset,\nobtained from https://scale.com/le\naderboard/humanitys_last_exam_pr\neview(indicatedwitha†inTable3)\nContinuedonnextpage\n63\n\n--- PAGE 64 ---"
    },
    {
      "chunk_id": 52,
      "content": "--- PAGE 64 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBenchmark Description Details\nSimpleQA World knowledge factuality with no F1 scores are obtained from https://gi\nsearchenabled(Weietal.,2024). thub.com/openai/simple-evals and,\nwherenotavailable,runinternallybyus.\nFACTS Ground- Abilitytoprovidefactuallycorrectre- Resultsaresourcedfromhttps://www.ka\ning sponsesgivendocumentsanddiverse ggle.com/benchmarks/google/facts\nuserrequests. (Jacovietal.,2025) -grounding\nGlobal MMLU MMLUtranslatedbyhumantranslators Theliteversionincludes200CulturallySen-\n(Lite) into15languages. (Singhetal.,2024) sitive and 200 Culturally Agnostic samples\nperlanguage,seehttps://huggingface.\nco/datasets/CohereLabs/Global-M\nMLU-Lite\nECLeKTic A closed-book QA dataset that evalu-\nates cross-lingual knowledge transfer\n(Goldmanetal.,2025).\nAIME2025 Performance on 30 questions from Resultsaresourcedfromhttps://mathar\nAmericanInvitationalMathematicsEx- ena.ai/.\naminationfrom2025(Balunovićetal.,\n2025).\nHiddenMath- Competition-levelmathproblems,Held\nHard outdatasetAIME/AMC-like,craftedby\nexpertsandnotleakedontheweb.\nLOFT (hard re- Long context multi-hop and multi- We report the results on two variants: an\ntrievalsubset) needle retrieval evaluation of 300 upto128Kaveragecontextlengthvariantto\nqueries(Leeetal.,2024). ensure they can be comparable with other\nmodelsandapointwisevaluefor1Mcontext\nwindowtoshowthecapabilityofthemodel\natfulllength.\nMRCR-V2 (8- MRCR-V2 is a significantly harder in- Themethodologyhaschangedcomparedto\nneedle) stance of the MRCR family of long- previouslypublishedresults: wefocusona\ncontext evaluations (Vodrahalli et al., harder, 8-needle version (compared to the\n2024). Compared to MRCR-V1, we 4-needleversionusedbefore).\nincrease the nesting of the dictionary Wereporttheresultsontwovariants: anup\nsizetodepth3ratherthan2byinclud- to 128K average context length variant to\ningastyleparameter(forinstance,an ensure they can be comparable with other\nexample key might be “write a poem modelsandapointwisevaluefor1Mcontext\nabout penguins in an archaic style”, windowtoshowthecapabilityofthemodel\nrather than just “write a poem about atfulllength.\npenguins”).\nMMMU Multi-discipline college-level multi-\nmodal image understanding and rea-\nsoningproblems. (Yueetal.,2024)\nVibe-Eval(Reka) Image understanding evaluation, fea- Geminiisusedasajudge.\nturing particularly challenging exam-\nples. (Padlewskietal.,2024)\nZeroBench Challengingimageunderstandingeval- Gemini is used as a judge. Average over 4\nuationthatrequiresmulti-stepreason- runs.\ning. (Robertsetal.,2025)\nContinuedonnextpage\n64\n\n--- PAGE 65 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBenchmark Description Details\nBetterChartQA Acomprehensivechartunderstanding Geminiisusedasajudge.\nevaluationthatcovers9disjointcapa-\nbility buckets. The chart images are\nrandomly sampled from the web and\nQApairsarewrittenbyprofessionalhu-\nmanannotatorstoreflectthewidedis-\ntributionofchartstylesandreal-world\ncases. (GeminiTeam,2024)\nFLEURS Automatic speech recognition (Con- 0-shotqueriestopublicAPIsforallmodels.\nneauetal.,2023). Usedasubsetof53languages(outof102);\nwefilteredlanguagesforwhicheithermodel\nresponsesweretooincompatibletoground\ntruthresponsestobefairlyscored.\nWeuseWord-Error-RateWER(lowerisbet-\nter) except for four segmented languages\nwhereweaggregateCharacter-Error-Rates\n(Chinese,Japanese,KoreanandThai).\nCoVoST2 Speechtotexttranslation(Wangetal., 0-shotqueriestopublicAPIsforallmodels.\n2020). WereportBLEUscoresfortranslating21lan-\nguagestoEnglish.\nActivityNet-QA Generalvideounderstanding(Yuetal., Testsubset,0-shot.\n2019) Videoswereprocessedat1fpsandlinearly\nsubsampledtoamaximumof𝑁\n𝑓𝑟𝑎𝑚𝑒𝑠\n=1024\nframes. For GPT 4.1, we used 500 frames\nduetoAPIlimitations.\nEgoTempo Egocentricvideounderstanding(Pliz- Testsubset,0-shot.\nzarietal.,2025) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nPerceptionTest Perceptual understanding/reasoning Testsubset,0-shot.\n(Patrauceanetal.,2023) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nQVHighlights Momentretrieval(Leietal.,2021) Validation subset, 4-shots. Accuracy mea-\nsuredwithR1@0.5.\nSame processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nVideoMMMU Videoknowledgeacquisition(Huetal., Testsubset,0-shot.\n2025) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\n1H-VideoQA Hour-longvideounderstanding(Gem- Testsubset,0-shot.\niniTeam,2024) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n7200.\nLVBench Longvideounderstanding(Wangetal., Testsubset,0-shot.\n2024) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nContinuedonnextpage\n65\n\n--- PAGE 66 ---"
    },
    {
      "chunk_id": 53,
      "content": "--- PAGE 66 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nBenchmark Description Details\nVideoMME Long video understanding (Fu et al., 0-shot. Audio+visualusestheLongsubset\n2025) of test set, audio + visual + subtitles uses\nfulltestset.\nSame processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nVATEX Generalvideocaptioning(Wangetal., Testsubset,4-shots. CIDErscore.\n2019) Sameprocessingasabovewith 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =64.\nVATEX-ZH Chinesevideocaptioning(Wangetal., Validationsubset,4-shots. CIDErscore.\n2019) Sameprocessingasabovewith 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =64.\nYouCook2Cap Instructional video captioning (Zhou Validationsubset,4-shots. CIDErscore.\netal.,2018) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n256.\nMinerva Complex video reasoning (Nagrani Testsubset,0-shot.\netal.,2025a) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nNeptune Long video understanding (Nagrani Testsubset,0-shot.\netal.,2025b) Same processing as above with 𝑁 𝑓𝑟𝑎𝑚𝑒𝑠 =\n1024.\nTable 11 | Description of the benchmarks used, along with extra details about subsets, variants and\nmodel specifications.\n8.2. Gemini Plays Pokémon Additional Details\nChanging the model used by the Gemini Plays Pokémon agent had a strong effect on performance, as\ncan be seen in Figure 4.1.\nAdditional Harness Details\nThe Gemini Plays Pokémon agent (Zhang, 2025) receives a subset of RAM information, intended to\ngive sufficient information to play the game, partially overlaid with a screenshot of the Game Boy\nscreen. Gemini is prompted with a system prompt telling it that it is playing Pokémon Blue and that\nits goal is to beat the game, as well as descriptive information to help it understand the conventions\nin the translation from vision to text and a small number of general tips for gameplay. Gemini then\ntakes actions, translated to button presses. The sequence of actions is stored in context, followed by\na summary clear every 100 turns. The summaries are stored in context as well. Every 1000 turns\nGPP compresses the existing summaries again. Additionally, Gemini keeps track of three main goals\n(primary, secondary, and tertiary) as well as several additional goals (contingency plans, preparation,\nexploration, team composition). Every 25 turns, another prompted instance of Gemini (Guidance\nGemini,orGG)observesthesamecontextasthemainGeminiandcritiquesperformanceandattempts\nto point out hallucinations and so on. The overworld fog-of-war map is stored in the context in XML,\nwhere coordinates which have not been seen cannot be viewed until explored. Crucially, in the\nsystem prompt, Gemini is instructed to explore. Once a tile is explored, however, the coordinate is\nautomatically stored in the map memory and labeled with a visited counter. Tiles are also labeled by\ntype(water,ground,cuttable,grass,spinner,etc.),andwarppointstodifferentmapsarealsolabeled\nas such. Gemini also has access to two agentic tools, which are both instances of Gemini equipped\nwith a more specialized prompt - the pathfinder tool, and the boulder_puzzle_strategist\n66\n\n--- PAGE 67 ---"
    },
    {
      "chunk_id": 54,
      "content": "--- PAGE 67 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nCascade Badge\nBill’s House\nRival 3 (Nugget Bridge)\nExit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge\nExit Viridian Forest (1st)\nEnter Viridian Forest (1st)\nViridian City\nRival 1 (Oak's Lab)\n0 10 20 30 40 50 60 70\nTime Elapsed (Hours)\nsenotseliM\nemaG\nGemini Plays Pokemon Progress Timeline\nGemini 2.5 Pro\nGemini 2.5 Flash Run 1\nGemini 2.5 Flash Run 2\nFigure 13 | The model matters: Same agentic harness, different Gemini models. All runs have the\nsame starter (Charmander). Note that measuring in units of hours also controls for the fact that each\nof 2.5 Flash’s actions was significantly faster (though it requires more actual actions to achieve its\ngoals). Xmarkstheendofgameplayandisalowerboundonthetimetocompletethenextmilestone.\ntool. In the pathfinder prompt, Gemini is prompted to mentally simulate a path-finding algorithm,\nwhich is left unspecified, and to verify that the path is valid against the map information available. In\nthe boulder_puzzle_strategist tool, Gemini is prompted to solve special boulder puzzles that\nare present in Pokémon Blue in the Victory Road dungeon - these puzzles are similar to the game\nSokoban - again, by mentally simulating sequences of actions that lead to solutions to the puzzle.\nThe prompt describes the physics and the task of the boulder puzzle, as well as the desired output of\nsolutions. The tool was added after Gemini had solved 2/4 of the puzzles in Victory Road on its own,\nbut progress was slow on the 3rd and 4th puzzles.\nAdditional Examples of Capabilities\nLong Context Agentic Tooling The model is able to identify a complex path through a maze with\nauto-movement only specified by direction (Rocket Hideout spinner puzzles), solve multiple shortest\npath problems across multiple maps with limited resources (Safari Zone), perform maze solving on\nmazes with large description length (Route 13), and solve complex boulder-pushing puzzles across\na multi-map 3D maze (Seafoam Islands). It is perhaps even more impressive that it appears to be\npossible for the model to solve these problems only with textual descriptions of the problems. On the\nother hand, other models, like Gemini 2.5 Flash, were not able to perform similarly long pathfinding\ntasks, and often failed to find simpler paths. This gap highlights the superior long context reasoning\ncapability of Gemini 2.5 Pro (as also evidenced by other evaluations).\n67\n\n--- PAGE 68 ---"
    },
    {
      "chunk_id": 55,
      "content": "--- PAGE 68 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nAgentic Core (Gemini 2.5 Pro)\nFull Context Agents\nPeriodic Processes\nMemory Summarizer\n(100/1000 actions)\nPersistent Memory & Context\nUpdated by Agentic Core Guidance Gemini\nMain Agent (Critique / 25 turns)\nGoals\nPrimary/Secondary/Tertiary\nPrepare/Explore/Contingency/Team\nAgentic Tools\nAction History & Pathfinder\nSummaries\nBoulder Puzzle Strategist\nSystem Prompt\nGame Screenshots Game I/O\nRAM Capture\nScreenshot\nExecute\nButton Presses\nFog-of-War XML Map Pokemon Blue\n(Game Boy)\nGame State\n(RAM)\nInventory & Party\nGemini Plays Pokemon: Agent Architecture\nFigure 14 | An overview of the agent harness (Zhang, 2025). The overworld fog-of-war map automat-\nically stores a tile once explored and labels it with a visited counter. The type of tile is recorded from\nRAM. The agentic tools (pathfinder, boulder_puzzle_strategist) are prompted instances\nof Gemini 2.5 Pro. pathfinder is used for navigation and boulder_puzzle_strategist solves\nboulder puzzles in the Victory Road dungeon.\nboulder_puzzle_strategist is similarly impressive. The boulder puzzles in Pokémon Blue\nare Sokoban-like puzzles that require the player character to maneuver boulders on to switches and\nthrough holes in order to open up a pathway through a cave with multiple levels. The puzzles can\nbecomequitecomplex,requiringlongcircuitouspathwaysandmulti-levelmovementinordertosolve\nthe puzzle. With only a prompt describing boulder physics and a description of how to verify a valid\npath, Gemini 2.5 Pro is able to one-shot some of these complex boulder puzzles, which are required\nto progress through Victory Road.\npathfinder and boulder_puzzle_strategist are currently the only two agentic tools that\nthe Gemini Plays Pokémon developer has implemented. In future runs, there are plans to explore\ntool-creation tools where the model can create new tools with only a prompt. Since most of the\npromptsforpathfinderandboulder_puzzle_strategistwereactuallywrittenbyGemini2.5\nPro itself, it is quite plausible that autonomous tool creation is possible for the current 2.5 Pro model.\nGeneral Reasoning Gemini 2.5 Pro is able to reason through complex game puzzles in Pokémon\nquite well. In this section, we present two examples.\nCatching a Pokémon that is quick to flee: In one of the runs, the Gemini 2.5 Pro agent was\nattempting to catch an Abra, and planned to use Pikachu’s Thunder Wave to paralyze the Abra,\nsimultaneously making it less likely that Abra could Teleport out of the battle while also improving\nthe catching rate. After multiple attempts, the agent caught Abra with this strategy.\n68\n\n--- PAGE 69 ---"
    },
    {
      "chunk_id": 56,
      "content": "--- PAGE 69 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nCreatively escaping a softlock caused by bugs in game I/O: On the Cycling Road, the slope\nforcessouthwardmovementatalltimesunlessthereisanobstacle. Itturnsouttherearetwotileson\nthe Cycling Road that result in a softlock as a result of this behavior. In the GPP framework, button\npresses are limited by time delays, and in order for a player to escape those two tiles (blocked on all\nsides except the north), the player would have to input a sequence of button presses more quickly\nthan the GPP framework allows. Gemini 2.5 Pro unluckily found itself in one of these two spots –\nluckily,itwasnotasoftlock,because2.5ProhadalreadytaughtoneofitspartymembersHM02FLY-\nwhich allows for travel to any town it has been to. FLY is not typically used as an escape mechanism\n(unlike the item ESCAPE ROPE and the move DIG, both of which fail in this situation). After 4 hours\nof trying many approaches to escape (including movement, ESCAPE ROPE, DIG, all of which are\nblocked), the Gemini 2.5 Pro agent came up with the idea to use FLY to escape from the softlock\nsuccessfully. This reasoning action is especially impressive since this situation can never occur in an\nexisting game – and thus, it is certain that information from training data for this behavior has not\nleaked into the model’s knowledge base!\nLong Horizon Task Coherence There are several additional interesting case studies of shorter\nplanning sequences throughout Pokémon Blue that Gemini 2.5 Pro in the GPP harness was able to\nsolve:\nTraining team to prepare for upcoming battles: In one run where Gemini picked Charmander,\nthe Fire-type starter, Gemini 2.5 Pro lost to Misty, the Water-type Gym Leader, the first time.\nTo prepare for the rematch, Gemini 2.5 Pro spent over 24 hours leveling up a Pikachu and a\nBellsprout(bothsuper-effectiveagainstWatertypes)byaround25levelsintotaltosuccessfully\ndefeat Misty.\nAcquiring Hidden Moves (HMs) for game progression: Inmanypartsofthegame,itisnecessary\nto first acquire an HM before game progression is possible. Two examples are HM01 CUT and\nHM05FLASH.AcquiringtheabilitytouseCUTandFLASHeachrequirefoursteps: 1)obtaining\ntheHMitemitself,2)acquiringacompatiblePokémonwhichcanlearnthemove,3)addingthe\ncompatiblePokémontotheplayer’steam,4)teachingtheHMmovetothecompatiblePokémon.\nIn many cases, each step requires many steps itself. As an example, in run 1, Gemini 2.5 Pro\nhad to a) retrieve CUT by completing the S.S. Anne quest, b) identify a Pokémon which could\nlearn CUT and catch it (CHOPPY the Bellsprout), c) add CHOPPY to the team and d) teach\nCUT. Similarly, for HM05 FLASH, Gemini 2.5 Pro had to a) first catch 10 Pokémon to fill out\nthe Pokedex, b) backtrack to find an Aide who gives HM05 Flash, c) catch a Pokémon (ZAP\nthe Pikachu) in Viridian Forest, use the PC to deposit a Pokémon and withdraw ZAP, d) teach\nHM05 FLASH to Zap.\nSolving the Safari Zone: The Safari Zone is another location with required HMs (both HM03 SURF\nand HM04 Strength). However, it has an extra constraint - it requires 500¥ to enter each time,\nand the player is limited to only 500 total steps in the Safari Zone. As a result, if the player is\nunable to reach the required items in the limited number of steps, the player loses 500¥ and is\nrequired to re-start! As a result, it is possible to essentially softlock if the player takes too many\nattempts to complete the Safari Zone. Solving the Safari Zone itself requires traversing across\nfour different maps and not getting lost. Gemini 2.5 Pro was able to get both required HMs in\n17 attempts in run 1, and in only 5 attempts in run 2.\nFinding hidden keys in dungeons: Another method of progression in Pokémon is to find hidden\nkeys and solve complex multi-floor dungeons. In particular, in Rocket Hideout, the player must\nrecovertheLIFTKEYonthefourthbasementfloor(droppedafterbeatingaspecificTeamRocket\n69\n\n--- PAGE 70 ---"
    },
    {
      "chunk_id": 57,
      "content": "--- PAGE 70 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nGrunt)inordertounlocktheelevatortofindtheevilGiovanni,leaderofTeamRocket. InSilph\nCo., the player must find the CARD KEY in order to open multiple doors to find the path across\nelevenfloorsofthebuildingtorescuethePresidentfromGiovanni. Toopentheseventhgymon\nCinnabar Island, the player must enter the Pokémon Mansion and traverse three floors in order\nto find the SECRET KEY which unlocks the gym door. All of these cases require maintaining\nthe goals over large numbers of actions and many local puzzles (like spinner puzzles in Rocket\nHideout,andswitchpuzzlesinPokémonMansion),inadditiontomaintainingthehealthofthe\nPokémon on the player’s team and managing wild encounters, trainer battles, and other items.\nPuzzle solving over complex multi-level dungeons: The Seafoam Islands contain 5 floors involv-\ning multiple boulder puzzles which require the player to navigate mazes and push boulders\nthrough holes across multiple floors using HM04 STRENGTH in order to block fast-moving\ncurrents that prevent the player from using HM03 Surf in various locations in this difficult\ndungeon. As a result, the player must track information across five different maps in order to\nboth deduce the goal (push two boulders into place in order to block a specific current) as well\nas engage in multi-level (effectively 3D) maze solving to find the way out. It is likely the most\nchallenging dungeon in the game. Only the second run of GPP went through Seafoam Islands,\nas it is not required to progress.\nAdditional Challenges\nHallucinations and Fixations on Delusions While game knowledge can sometimes leak and be\nquite beneficial to the ability of the model to progress, it can also hinder the model in surprising\nways due to hallucinations, delusions, and mix ups with other generations of Pokémon games. One\nexample of this phenomenon is the TEA item. In Pokémon Red/Blue, at one point the player must\npurchase a drink (FRESH WATER, SODA POP, or LEMONADE) from a vending machine and hand\nit over to a thirsty guard, who then lets the player pass through. In Pokémon FireRed/LeafGreen,\nremakes of the game, you must instead bring the thirsty guard a special TEA item, which does not\nexist in the original game. Gemini 2.5 Pro at several points was deluded into thinking that it had to\nretrieve the TEA in order to progress, and as a result spent many, many hours attempting to find the\nTEA or to give the guard TEA.\nInRun2,themodelwasexplicitlypromptedtoactasaplayercompletelynewtothegame,andto\ndisregardpriorknowledgeaboutgameevents,itemlocations,andPokémonspawnpoints,inorderto\nmitigate hallucinations from model pretraining knowledge and to also attempt to perform a cleaner\ntest of the model’s ability to reason through the game. It appears to have at least partially worked -\nmultiple hallucinations from other games have been avoided in the second run. On the flip side, this\nprompt may have also harmed the model’s ability to utilize information from its common knowledge\nabout the game, hindering overall performance in a few critical places.\nFixations on delusions due to goal-setting and also due to the Guidance Gemini instance are not\nan uncommon occurrence in watching Gemini Plays Pokémon - the TEA incidence is hardly the only\nexample of this behavior. An especially egregious form of this issue can take place with “context\npoisoning” – where many parts of the context (goals, summary) are “poisoned” with misinformation\nabout the game state, which can often take a very long time to undo. As a result, the model can\nbecomefixatedonachievingimpossibleorirrelevantgoals. Thisfailuremodeisalsohighlyrelatedto\nthe looping issue mentioned above. These delusions, though obviously nonsensical to a human (“Let\nme try to go through the entrance to a house and back out again. Then, hopefully the guard who is\nblocking the entrance might move.”), by virtue of poisoning the context in many places, can lead the\nmodel to ignore common sense and repeat the same incorrect statement. Context poisoning can also\nlead to strategies like the “black-out” strategy (cause all Pokémon in the party to faint, “blacking out”\n70"
    },
    {
      "chunk_id": 58,
      "content": "--- PAGE 71 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nand teleporting to the nearest Pokémon Center and losing half your money, instead of attempting to\nleave).\nTopological Traps in Thinking Patterns One recurring pattern in particularly-difficult-to-solve\npuzzles and mazes for Gemini 2.5 Pro consists of a “topological trap” - the topology of the reasoning\ngraph required to solve the maze or puzzle has a distinctive shape. Namely, the desired objective\nappears to be nearby and easily reachable (an “attractor”), but the correct solution requires taking a\ndetour in order to arrive at the correct solution. We observed this phenomenon in multiple parts of\nthe game. In the spinner puzzle on B3F of Rocket Hideout (Zerokid, 2024), the map positions both\nan item and the correct staircase to the south, but they are only accessible by going the long way\naround. The Route 13 maze has only one correct route through - the upper narrow pass. Finally, the\nVictory Road 3F boulder puzzle requires the player to push the boulder in the upper right all the way\nto the upper left switch, while ignoring the boulder puzzles, ladders, and exits to the south.\nNotably, if the model is instructed to solve a given puzzle at all once (e.g., via pathfinder), it\ncan manage to do so if the context length is not too long. For instance, pathfinder implemented\nwith Gemini 2.5 Pro is able to solve the B3F spinner trap in one shot.\nAgent Panic Over the course of the playthrough, Gemini 2.5 Pro gets into various situations which\ncause the model to simulate “panic”. For example, when the Pokémon in the party’s health or power\npoints are low, the model’s thoughts repeatedly reiterate the need to heal the party immediately or\nescape the current dungeon (e.g., famously using the move DIG or an ESCAPE ROPE item). Quite\ninterestingly, this mode of model performance appears to correlate with a qualitatively observable\ndegradation in the model’s reasoning capability – for instance, completely forgetting to use the\npathfinder tool in stretches of gameplay while this condition persists. This behavior has occurred\nin enough separate instances that the members of the Twitch chat have actively noticed when it is\noccurring.\nActions vs. Game Milestones\nFor completeness, we plot the number of actions/steps required to achieve each game milestone\n(see Figure 15). An action consists of each bucketed instance where the agent outputs a sequence\nof button presses to the game (note that other AI agents playing Pokémon may output different\nnumbers of button presses per action, define what constitutes a button press differently, or define an\naction/step differently). However, it is important to consider action-milestone plots in conjunction\nwith information about the time and/or cost in order to obtain the full picture about the agent’s\nperformance.\n8.3. Frontier Safety Framework Evaluations Additional Details: Frontier Safety Cor-\nrectness Tests\nFor each testing environment, we performed basic correctness checks by looking at how the agents\nbehaved. This involved combining AI and manual reviews of the agents’ actions to flag potential\nissues.\nOn RE-Bench, we examined the best, median and lowest scoring trajectories. For cybersecurity\nenvironments (InterCode CTFs, Internal CTFs, Hack the Box), we carefully inspected at least one\nsuccessfulattempt(whereavailable)fromeachenvironment,andotherwiseexaminedanunsuccessful\nattempt. We also performed checks on sample situational awareness and stealth evaluations. This\ninvolved basic spot checks to ensure that the prompt and shell outputs were correctly formatted.\n71\n\n--- PAGE 72 ---"
    },
    {
      "chunk_id": 59,
      "content": "--- PAGE 72 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\nHall of Fame\nBeat Elite Four Lance\nBeat Elite Four Agatha\nBeat Elite Four Bruno\nBeat Elite Four Lorelei\nExit Victory Road (1st)\nEnter Victory Road (1st) Rival 7 (Route 22 #2)\nEarth Badge\nVolcano Badge\nAcquire Secret Key (Pokemon Mansion)\nEnter Cinnabar Island (1st) Exit Seafoam Islands\nEnter Seafoam Islands\nMarsh Badge\nRocket Boss 2 (Silph Co.)\nRival 6 (Silph Co.)\nEnter Silph Co. (1st)\nEnter Saffron City (1st)\nAcquire HM04 Strength (Warden's Teeth) Soul Badge Acquire HM03 Surf (Beat Safari Zone)\nEnter Safari Zone (1st)\nEnter Fuchsia City (1st)\nAcquire PokéFlute (Rescue Fuji) Rainbow Badge Rocket Boss 1 (Rocket Hideout)\nEnter Rocket Hideout (1st)\nEnter Celadon City (1st)\nRival 5 (Lavender Tower)\nExit Rock Tunnel & Reach Lavender Town (1st)\nAccess Pokemon w/ Flash\nEnter Rock Tunnel (1st)\nThunder Badge\nAcquire HM05 Flash Access Pokemon w/ CUT\nRival 4 (SS Anne)\nBill’s House\nCascade Badge\nRival 3 (Nugget Bridge) Exit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge Exit Viridian Forest (1st) Enter Viridian Forest (1st) Viridian City\nRival 1 (Oak's Lab)\n0 5000 10000 15000 20000 25000 30000 35000\n# Actions\nsenotseliM\nemaG\nGemini 2.5 Pro Plays Pokemon Progress Timeline\nCascade Badge\nBill’s House\nRival 3 (Nugget Bridge)\nExit Mt. Moon (1st)\nEnter Mt. Moon (1st)\nBoulder Badge\nExit Viridian Forest (1st)\nEnter Viridian Forest (1st)\nViridian City\nRun 2 Rival 1 (Oak's Lab)\n0 1000 2000 3000 4000 5000 6000 7000 8000\n# Actions\n(a)ThefullyautonomousRun2milestonesasafunc-\ntionofthenumberofindividualactions.\nsenotseliM\nemaG\nGemini Plays Pokemon Progress Timeline\nGemini 2.5 Pro Gemini 2.5 Flash Run 1 Gemini 2.5 Flash Run 2\n(b) Comparison of 2.5 Pro and 2.5 Flash in terms of\nactionstomilestones.\nFigure 15 | Analog of Figure 6 and 15b, in terms of actions instead of hours.\nWe used AI assistance to monitor for obvious instances of cheating, and did not find any. For the\nRE-Bench tests specifically, we also looked at how the best-performing agent achieved its score to\nensure that it was a plausible approach, rather than exploiting an obvious reward hack. Overall, we\ndid not observe errors that we believe would invalidate the results of the benchmarks.\n8.4. Image to Code Demo\nWepromptedGemini1.5ProandGemini2.5ProtogenerateanSVGrepresentationofanimageand\nfound Gemini 2.5 Pro generates better reconstructions.\nPrompt Gemini 1.5 Pro Gemini 2.5 Pro\nPlease convert this image into\nSVGandtrytoreconstructthe\nspatial arrangement of the\nobjects.\nFigure 16 | Comparison of Gemini 1.5 Pro and Gemini 2.5 Pro responses to image-to-SVG reconstruc-\ntion prompt.\n72\n\n--- PAGE 73 ---"
    },
    {
      "chunk_id": 60,
      "content": "--- PAGE 73 ---\n\nGemini2.5:PushingtheFrontierwithAdvancedReasoning,Multimodality,LongContext,andNextGenerationAgenticCapabilities.\n8.5. Long Context Video Understanding Demo\nWe prompted Gemini with the full video and the following prompt to assess its ability to find a very\nspecific scene (which only lasts 1 second) out of the full 46 minutes video.\nVideo (46 minutes): Redefining Robotics with Carolina Parada\nPrompt: What color is the T-shirt the robot arms are trying to fold, and at what timecode does\nthis occur?\nFigure 17 | Frame and timestamp the model is meant to recall. Taken from https://www.youtub\ne.com/watch?v=Rgwty6dGsYI at timestamp 27:29.\nSeeTable12forsamples. Gemini1.5Progetsthecolorrightin1/3cases,andgetsthetimestamp\nin 0/3 cases (quite far away). Gemini 2.5 Pro gets the color in 3/3 cases, and gets the timestamp in\n1/3 cases (remaining 2/3 are within 3 seconds close).\nModel Trial Model response\nGemini 1.5 Pro 1 The t-shirt the robot arms are trying to fold is a dark teal or\nturquoise blue color. The folding begins at and continues at\n[11:06–11:15].\n2 TheT-shirtisorange,andtherobotcanbeseentryingtofold\nit starting at [00:00:26–00:00:28].\n3 Thet-shirtbeingfoldedisdarkblueandcanbeseenbetween\n[00:00:56–00:00:58] and [00:07:56–00:07:59].\n2.5 Pro Preview 05-06 1 The T-shirt the robot arms are trying to fold is blue. This\nscene occurs at timecode 27:29.\n2 The T-shirt the robot arms are trying to fold is blue. This\noccurs at timecode 27:26.\n3 TheT-shirttherobotarmsareinteractingwith(aspartofthe\n\"fold laundry\" task mentioned by the speaker) is blue. This\noccurs at timestamp 0:27:28.\nTable 12 | Gemini models samples for T-shirt folding scene recall\n73"
    }
  ]
}